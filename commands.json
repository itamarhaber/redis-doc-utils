[
    {
        "BITPOS": {
            "body": "Return the position of the first bit set to 1 or 0 in a string.\n\nThe position is returned, thinking of the string as an array of bits from left to\nright, where the first byte's most significant bit is at position 0, the second\nbyte's most significant bit is at position 8, and so forth.\n\nThe same bit position convention is followed by [`GETBIT`](./getbit) and [`SETBIT`](./setbit).\n\nBy default, all the bytes contained in the string are examined.\nIt is possible to look for bits only in a specified interval passing the additional arguments _start_ and _end_ (it is possible to just pass _start_, the operation will assume that the end is the last byte of the string. However there are semantic differences as explained later).\nBy default, the range is interpreted as a range of bytes and not a range of bits, so `start=0` and `end=2` means to look at the first three bytes.\n\nYou can use the optional `BIT` modifier to specify that the range should be interpreted as a range of bits.\nSo `start=0` and `end=2` means to look at the first three bits.\n\nNote that bit positions are returned always as absolute values starting from bit zero even when _start_ and _end_ are used to specify a range.\n\nLike for the [`GETRANGE`](./getrange) command start and end can contain negative values in\norder to index bytes starting from the end of the string, where -1 is the last\nbyte, -2 is the penultimate, and so forth. When `BIT` is specified, -1 is the last\nbit, -2 is the penultimate, and so forth.\n\nNon-existent keys are treated as empty strings.\n\n@examples\n\n```cli\nSET mykey \"\\xff\\xf0\\x00\"\nBITPOS mykey 0\nSET mykey \"\\x00\\xff\\xf0\"\nBITPOS mykey 1 0\nBITPOS mykey 1 2\nBITPOS mykey 1 2 -1 BYTE\nBITPOS mykey 1 7 15 BIT\nset mykey \"\\x00\\x00\\x00\"\nBITPOS mykey 1\nBITPOS mykey 1 7 -3 BIT\n```\n\n",
            "history": [
                [
                    "7.0",
                    "Added the `BYTE|BIT` option."
                ]
            ],
            "": "",
            "return_types": [
                {
                    "type": "integer"
                }
            ],
            "summary": "Find first bit set or clear in a string",
            "complexity": "O(N)",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "name": "bit",
                    "type": "integer",
                    "value": "bit"
                },
                {
                    "optional": true,
                    "name": "index",
                    "type": "block",
                    "value": [
                        {
                            "name": "start",
                            "type": "integer",
                            "value": "start"
                        },
                        {
                            "optional": true,
                            "name": "end_index",
                            "type": "block",
                            "value": [
                                {
                                    "name": "end",
                                    "type": "integer",
                                    "value": "end"
                                },
                                {
                                    "optional": true,
                                    "name": "byte_bit",
                                    "type": "oneof",
                                    "value": [
                                        {
                                            "name": "__TBD__1__",
                                            "token": "BYTE"
                                        },
                                        {
                                            "name": "__TBD__2__",
                                            "token": "BIT"
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                }
            ],
            "since": "2.8.7",
            "group": "bitmap",
            "arity": -3,
            "command_flags": [
                "readonly"
            ],
            "acl_categories": [
                "read",
                "bitmap",
                "slow"
            ],
            "key_specs": [
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "bitposCommand"
        }
    },
    {
        "SCAN": {
            "body": "The `SCAN` command and the closely related commands [`SSCAN`](./sscan), [`HSCAN`](./hscan) and [`ZSCAN`](./zscan) are used in order to incrementally iterate over a collection of elements.\n\n* `SCAN` iterates the set of keys in the currently selected Redis database.\n* [`SSCAN`](./sscan) iterates elements of Sets types.\n* [`HSCAN`](./hscan) iterates fields of Hash types and their associated values.\n* [`ZSCAN`](./zscan) iterates elements of Sorted Set types and their associated scores.\n\nSince these commands allow for incremental iteration, returning only a small number of elements per call, they can be used in production without the downside of commands like [`KEYS`](./keys) or [`SMEMBERS`](./smembers) that may block the server for a long time (even several seconds) when called against big collections of keys or elements.\n\nHowever while blocking commands like [`SMEMBERS`](./smembers) are able to provide all the elements that are part of a Set in a given moment, The SCAN family of commands only offer limited guarantees about the returned elements since the collection that we incrementally iterate can change during the iteration process.\n\nNote that `SCAN`, [`SSCAN`](./sscan), [`HSCAN`](./hscan) and [`ZSCAN`](./zscan) all work very similarly, so this documentation covers all the four commands. However an obvious difference is that in the case of [`SSCAN`](./sscan), [`HSCAN`](./hscan) and [`ZSCAN`](./zscan) the first argument is the name of the key holding the Set, Hash or Sorted Set value. The `SCAN` command does not need any key name argument as it iterates keys in the current database, so the iterated object is the database itself.\n\n## SCAN basic usage\n\nSCAN is a cursor based iterator. This means that at every call of the command, the server returns an updated cursor that the user needs to use as the cursor argument in the next call.\n\nAn iteration starts when the cursor is set to 0, and terminates when the cursor returned by the server is 0. The following is an example of SCAN iteration:\n\n```\nredis 127.0.0.1:6379> scan 0\n1) \"17\"\n2)  1) \"key:12\"\n    2) \"key:8\"\n    3) \"key:4\"\n    4) \"key:14\"\n    5) \"key:16\"\n    6) \"key:17\"\n    7) \"key:15\"\n    8) \"key:10\"\n    9) \"key:3\"\n   10) \"key:7\"\n   11) \"key:1\"\nredis 127.0.0.1:6379> scan 17\n1) \"0\"\n2) 1) \"key:5\"\n   2) \"key:18\"\n   3) \"key:0\"\n   4) \"key:2\"\n   5) \"key:19\"\n   6) \"key:13\"\n   7) \"key:6\"\n   8) \"key:9\"\n   9) \"key:11\"\n```\n\nIn the example above, the first call uses zero as a cursor, to start the iteration. The second call uses the cursor returned by the previous call as the first element of the reply, that is, 17.\n\nAs you can see the **SCAN return value** is an array of two values: the first value is the new cursor to use in the next call, the second value is an array of elements.\n\nSince in the second call the returned cursor is 0, the server signaled to the caller that the iteration finished, and the collection was completely explored. Starting an iteration with a cursor value of 0, and calling `SCAN` until the returned cursor is 0 again is called a **full iteration**.\n\n## Scan guarantees\n\nThe `SCAN` command, and the other commands in the `SCAN` family, are able to provide to the user a set of guarantees associated to full iterations.\n\n* A full iteration always retrieves all the elements that were present in the collection from the start to the end of a full iteration. This means that if a given element is inside the collection when an iteration is started, and is still there when an iteration terminates, then at some point `SCAN` returned it to the user.\n* A full iteration never returns any element that was NOT present in the collection from the start to the end of a full iteration. So if an element was removed before the start of an iteration, and is never added back to the collection for all the time an iteration lasts, `SCAN` ensures that this element will never be returned.\n\nHowever because `SCAN` has very little state associated (just the cursor) it has the following drawbacks:\n\n* A given element may be returned multiple times. It is up to the application to handle the case of duplicated elements, for example only using the returned elements in order to perform operations that are safe when re-applied multiple times.\n* Elements that were not constantly present in the collection during a full iteration, may be returned or not: it is undefined.\n\n## Number of elements returned at every SCAN call\n\n`SCAN` family functions do not guarantee that the number of elements returned per call are in a given range. The commands are also allowed to return zero elements, and the client should not consider the iteration complete as long as the returned cursor is not zero.\n\nHowever the number of returned elements is reasonable, that is, in practical terms SCAN may return a maximum number of elements in the order of a few tens of elements when iterating a large collection, or may return all the elements of the collection in a single call when the iterated collection is small enough to be internally represented as an encoded data structure (this happens for small sets, hashes and sorted sets).\n\nHowever there is a way for the user to tune the order of magnitude of the number of returned elements per call using the **COUNT** option.\n\n## The COUNT option\n\nWhile `SCAN` does not provide guarantees about the number of elements returned at every iteration, it is possible to empirically adjust the behavior of `SCAN` using the **COUNT** option. Basically with COUNT the user specified the *amount of work that should be done at every call in order to retrieve elements from the collection*. This is **just a hint** for the implementation, however generally speaking this is what you could expect most of the times from the implementation.\n\n* The default COUNT value is 10.\n* When iterating the key space, or a Set, Hash or Sorted Set that is big enough to be represented by a hash table, assuming no **MATCH** option is used, the server will usually return *count* or a bit more than *count* elements per call. Please check the *why SCAN may return all the elements at once* section later in this document.\n* When iterating Sets encoded as intsets (small sets composed of just integers), or Hashes and Sorted Sets encoded as ziplists (small hashes and sets composed of small individual values), usually all the elements are returned in the first `SCAN` call regardless of the COUNT value.\n\nImportant: **there is no need to use the same COUNT value** for every iteration. The caller is free to change the count from one iteration to the other as required, as long as the cursor passed in the next call is the one obtained in the previous call to the command.\n\n## The MATCH option\n\nIt is possible to only iterate elements matching a given glob-style pattern, similarly to the behavior of the [`KEYS`](./keys) command that takes a pattern as only argument.\n\nTo do so, just append the `MATCH <pattern>` arguments at the end of the `SCAN` command (it works with all the SCAN family commands).\n\nThis is an example of iteration using **MATCH**:\n\n```\nredis 127.0.0.1:6379> sadd myset 1 2 3 foo foobar feelsgood\n(integer) 6\nredis 127.0.0.1:6379> sscan myset 0 match f*\n1) \"0\"\n2) 1) \"foo\"\n   2) \"feelsgood\"\n   3) \"foobar\"\nredis 127.0.0.1:6379>\n```\n\nIt is important to note that the **MATCH** filter is applied after elements are retrieved from the collection, just before returning data to the client. This means that if the pattern matches very little elements inside the collection, `SCAN` will likely return no elements in most iterations. An example is shown below:\n\n```\nredis 127.0.0.1:6379> scan 0 MATCH *11*\n1) \"288\"\n2) 1) \"key:911\"\nredis 127.0.0.1:6379> scan 288 MATCH *11*\n1) \"224\"\n2) (empty list or set)\nredis 127.0.0.1:6379> scan 224 MATCH *11*\n1) \"80\"\n2) (empty list or set)\nredis 127.0.0.1:6379> scan 80 MATCH *11*\n1) \"176\"\n2) (empty list or set)\nredis 127.0.0.1:6379> scan 176 MATCH *11* COUNT 1000\n1) \"0\"\n2)  1) \"key:611\"\n    2) \"key:711\"\n    3) \"key:118\"\n    4) \"key:117\"\n    5) \"key:311\"\n    6) \"key:112\"\n    7) \"key:111\"\n    8) \"key:110\"\n    9) \"key:113\"\n   10) \"key:211\"\n   11) \"key:411\"\n   12) \"key:115\"\n   13) \"key:116\"\n   14) \"key:114\"\n   15) \"key:119\"\n   16) \"key:811\"\n   17) \"key:511\"\n   18) \"key:11\"\nredis 127.0.0.1:6379>\n```\n\nAs you can see most of the calls returned zero elements, but the last call where a COUNT of 1000 was used in order to force the command to do more scanning for that iteration.\n\n\n## The TYPE option\n\nAs of version 6.0 you can use this option to ask `SCAN` to only return objects that match a given `type`, allowing you to iterate through the database looking for keys of a specific type. The **TYPE** option is only available on the whole-database `SCAN`, not [`HSCAN`](./hscan) or [`ZSCAN`](./zscan) etc.\n\nThe `type` argument is the same string name that the [`TYPE`](./type) command returns. Note a quirk where some Redis types, such as GeoHashes, HyperLogLogs, Bitmaps, and Bitfields, may internally be implemented using other Redis types, such as a string or zset, so can't be distinguished from other keys of that same type by `SCAN`. For example, a ZSET and GEOHASH:\n\n```\nredis 127.0.0.1:6379> GEOADD geokey 0 0 value\n(integer) 1\nredis 127.0.0.1:6379> ZADD zkey 1000 value\n(integer) 1\nredis 127.0.0.1:6379> TYPE geokey\nzset\nredis 127.0.0.1:6379> TYPE zkey\nzset\nredis 127.0.0.1:6379> SCAN 0 TYPE zset\n1) \"0\"\n2) 1) \"geokey\"\n   2) \"zkey\"\n```\n\nIt is important to note that the **TYPE** filter is also applied after elements are retrieved from the database, so the option does not reduce the amount of work the server has to do to complete a full iteration, and for rare types you may receive no elements in many iterations.\n\n## Multiple parallel iterations\n\nIt is possible for an infinite number of clients to iterate the same collection at the same time, as the full state of the iterator is in the cursor, that is obtained and returned to the client at every call. No server side state is taken at all.\n\n## Terminating iterations in the middle\n\nSince there is no state server side, but the full state is captured by the cursor, the caller is free to terminate an iteration half-way without signaling this to the server in any way. An infinite number of iterations can be started and never terminated without any issue.\n\n## Calling SCAN with a corrupted cursor\n\nCalling `SCAN` with a broken, negative, out of range, or otherwise invalid cursor, will result into undefined behavior but never into a crash. What will be undefined is that the guarantees about the returned elements can no longer be ensured by the `SCAN` implementation.\n\nThe only valid cursors to use are:\n\n* The cursor value of 0 when starting an iteration.\n* The cursor returned by the previous call to SCAN in order to continue the iteration.\n\n## Guarantee of termination\n\nThe `SCAN` algorithm is guaranteed to terminate only if the size of the iterated collection remains bounded to a given maximum size, otherwise iterating a collection that always grows may result into `SCAN` to never terminate a full iteration.\n\nThis is easy to see intuitively: if the collection grows there is more and more work to do in order to visit all the possible elements, and the ability to terminate the iteration depends on the number of calls to `SCAN` and its COUNT option value compared with the rate at which the collection grows.\n\n## Why SCAN may return all the items of an aggregate data type in a single call?\n\nIn the `COUNT` option documentation, we state that sometimes this family of commands may return all the elements of a Set, Hash or Sorted Set at once in a single call, regardless of the `COUNT` option value. The reason why this happens is that the cursor-based iterator can be implemented, and is useful, only when the aggregate data type that we are scanning is represented as an hash table. However Redis uses a [memory optimization](/topics/memory-optimization) where small aggregate data types, until they reach a given amount of items or a given max size of single elements, are represented using a compact single-allocation packed encoding. When this is the case, `SCAN` has no meaningful cursor to return, and must iterate the whole data structure at once, so the only sane behavior it has is to return everything in a call.\n\nHowever once the data structures are bigger and are promoted to use real hash tables, the `SCAN` family of commands will resort to the normal behavior. Note that since this special behavior of returning all the elements is true only for small aggregates, it has no effects on the command complexity or latency. However the exact limits to get converted into real hash tables are [user configurable](/topics/memory-optimization), so the maximum number of elements you can see returned in a single call depends on how big an aggregate data type could be and still use the packed representation.\n\nAlso note that this behavior is specific of [`SSCAN`](./sscan), [`HSCAN`](./hscan) and [`ZSCAN`](./zscan). `SCAN` itself never shows this behavior because the key space is always represented by hash tables.\n\n## Return value\n\n`SCAN`, [`SSCAN`](./sscan), [`HSCAN`](./hscan) and [`ZSCAN`](./zscan) return a two elements multi-bulk reply, where the first element is a string representing an unsigned 64 bit number (the cursor), and the second element is a multi-bulk with an array of elements.\n\n* `SCAN` array of elements is a list of keys.\n* [`SSCAN`](./sscan) array of elements is a list of Set members.\n* [`HSCAN`](./hscan) array of elements contain two elements, a field and a value, for every returned element of the Hash.\n* [`ZSCAN`](./zscan) array of elements contain two elements, a member and its associated score, for every returned element of the sorted set.\n\n## Additional examples\n\nIteration of a Hash value.\n\n```\nredis 127.0.0.1:6379> hmset hash name Jack age 33\nOK\nredis 127.0.0.1:6379> hscan hash 0\n1) \"0\"\n2) 1) \"name\"\n   2) \"Jack\"\n   3) \"age\"\n   4) \"33\"\n```\n\n",
            "return_summary": "",
            "summary": "Incrementally iterate the keys space",
            "complexity": "O(1) for every call. O(N) for a complete iteration, including enough command calls for the cursor to return back to 0. N is the number of elements inside the collection.",
            "arguments": [
                {
                    "name": "cursor",
                    "type": "integer",
                    "value": "cursor"
                },
                {
                    "token": "MATCH",
                    "optional": true,
                    "name": "pattern",
                    "type": "pattern",
                    "value": "pattern"
                },
                {
                    "token": "COUNT",
                    "optional": true,
                    "name": "count",
                    "type": "integer",
                    "value": "count"
                },
                {
                    "token": "TYPE",
                    "optional": true,
                    "name": "type",
                    "type": "string",
                    "value": "type"
                }
            ],
            "since": "2.8.0",
            "group": "generic",
            "arity": -2,
            "command_flags": [
                "readonly",
                "random"
            ],
            "acl_categories": [
                "keyspace",
                "read",
                "slow"
            ],
            "function": "scanCommand"
        }
    },
    {
        "LSET": {
            "body": "Sets the list element at `index` to `element`.\nFor more information on the `index` argument, see [`LINDEX`](./lindex).\n\nAn error is returned for out of range indexes.\n\n@examples\n\n```cli\nRPUSH mylist \"one\"\nRPUSH mylist \"two\"\nRPUSH mylist \"three\"\nLSET mylist 0 \"four\"\nLSET mylist -2 \"five\"\nLRANGE mylist 0 -1\n```\n\n",
            "": "",
            "return_types": [
                {
                    "type": "simple-string"
                }
            ],
            "summary": "Set the value of an element in a list by its index",
            "complexity": "O(N) where N is the length of the list. Setting either the first or the last element of the list is O(1).",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "name": "index",
                    "type": "integer",
                    "value": "index"
                },
                {
                    "name": "element",
                    "type": "string",
                    "value": "element"
                }
            ],
            "since": "1.0.0",
            "group": "list",
            "arity": 4,
            "command_flags": [
                "write",
                "denyoom"
            ],
            "acl_categories": [
                "write",
                "list",
                "slow"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "lsetCommand"
        }
    },
    {
        "LINSERT": {
            "body": "Inserts `element` in the list stored at `key` either before or after the reference\nvalue `pivot`.\n\nWhen `key` does not exist, it is considered an empty list and no operation is\nperformed.\n\nAn error is returned when `key` exists but does not hold a list value.\n\n@examples\n\n```cli\nRPUSH mylist \"Hello\"\nRPUSH mylist \"World\"\nLINSERT mylist BEFORE \"World\" \"There\"\nLRANGE mylist 0 -1\n```\n\n",
            "": "",
            "return_types": [
                {
                    "description": "the length of the list after the insert operation, or `-1` when",
                    "type": "integer"
                }
            ],
            "summary": "Insert an element before or after another element in a list",
            "complexity": "O(N) where N is the number of elements to traverse before seeing the value pivot. This means that inserting somewhere on the left end on the list (head) can be considered O(1) and inserting somewhere on the right end (tail) is O(N).",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "name": "before_after",
                    "type": "oneof",
                    "value": [
                        {
                            "name": "__TBD__3__",
                            "token": "BEFORE"
                        },
                        {
                            "name": "__TBD__4__",
                            "token": "AFTER"
                        }
                    ]
                },
                {
                    "name": "pivot",
                    "type": "string",
                    "value": "pivot"
                },
                {
                    "name": "element",
                    "type": "string",
                    "value": "element"
                }
            ],
            "since": "2.2.0",
            "group": "list",
            "arity": 5,
            "command_flags": [
                "write",
                "denyoom"
            ],
            "acl_categories": [
                "write",
                "list",
                "slow"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "linsertCommand"
        }
    },
    {
        "SINTER": {
            "body": "Returns the members of the set resulting from the intersection of all the given\nsets.\n\nFor example:\n\n```\nkey1 = {a,b,c,d}\nkey2 = {c}\nkey3 = {a,c,e}\nSINTER key1 key2 key3 = {c}\n```\n\nKeys that do not exist are considered to be empty sets.\nWith one of the keys being an empty set, the resulting set is also empty (since\nset intersection with an empty set always results in an empty set).\n\n@examples\n\n```cli\nSADD key1 \"a\"\nSADD key1 \"b\"\nSADD key1 \"c\"\nSADD key2 \"c\"\nSADD key2 \"d\"\nSADD key2 \"e\"\nSINTER key1 key2\n```\n\n",
            "": "",
            "return_types": [
                {
                    "description": "list with members of the resulting set.",
                    "type": "array"
                }
            ],
            "summary": "Intersect multiple sets",
            "complexity": "O(N*M) worst case where N is the cardinality of the smallest set and M is the number of sets.",
            "arguments": [
                {
                    "multiple": true,
                    "multiple_token": true,
                    "name": "key",
                    "type": "key",
                    "value": "key"
                }
            ],
            "since": "1.0.0",
            "group": "set",
            "arity": -2,
            "command_flags": [
                "readonly",
                "sort_for_script"
            ],
            "acl_categories": [
                "read",
                "set",
                "slow"
            ],
            "key_specs": [
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": -1,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "sinterCommand"
        }
    },
    {
        "ZDIFFSTORE": {
            "body": "Computes the difference between the first and all successive input sorted sets\nand stores the result in `destination`. The total number of input keys is\nspecified by `numkeys`.\n\nKeys that do not exist are considered to be empty sets.\n\nIf `destination` already exists, it is overwritten.\n\n@examples\n\n```cli\nZADD zset1 1 \"one\"\nZADD zset1 2 \"two\"\nZADD zset1 3 \"three\"\nZADD zset2 1 \"one\"\nZADD zset2 2 \"two\"\nZDIFFSTORE out 2 zset1 zset2\nZRANGE out 0 -1 WITHSCORES\n```\n\n",
            "": "",
            "return_types": [
                {
                    "description": "the number of elements in the resulting sorted set at",
                    "type": "integer"
                }
            ],
            "summary": "Subtract multiple sorted sets and store the resulting sorted set in a new key",
            "complexity": "O(L + (N-K)log(N)) worst case where L is the total number of elements in all the sets, N is the size of the first set, and K is the size of the result set.",
            "arguments": [
                {
                    "name": "destination",
                    "type": "key",
                    "value": "destination"
                },
                {
                    "name": "numkeys",
                    "type": "integer",
                    "value": "numkeys"
                },
                {
                    "multiple": true,
                    "multiple_token": true,
                    "name": "key",
                    "type": "key",
                    "value": "key"
                }
            ],
            "since": "6.2.0",
            "group": "sorted_set",
            "arity": -4,
            "command_flags": [
                "write",
                "denyoom"
            ],
            "acl_categories": [
                "write",
                "sortedset",
                "slow"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                },
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 2
                        }
                    },
                    "find_keys": {
                        "keynum": {
                            "keynumidx": 0,
                            "firstkey": 1,
                            "step": 1
                        }
                    }
                }
            ],
            "function": "zdiffstoreCommand",
            "get_keys_function": "zunionInterDiffStoreGetKeys"
        }
    },
    {
        "GETSET": {
            "body": "Atomically sets `key` to `value` and returns the old value stored at `key`.\nReturns an error when `key` exists but does not hold a string value.  Any \nprevious time to live associated with the key is discarded on successful \n[`SET`](./set) operation.\n\n## Design pattern\n\n`GETSET` can be used together with [`INCR`](./incr) for counting with atomic reset.\nFor example: a process may call [`INCR`](./incr) against the key `mycounter` every time\nsome event occurs, but from time to time we need to get the value of the counter\nand reset it to zero atomically.\nThis can be done using `GETSET mycounter \"0\"`:\n\n```cli\nINCR mycounter\nGETSET mycounter \"0\"\nGET mycounter\n```\n\nAs per Redis 6.2, GETSET is considered deprecated. Please prefer [`SET`](./set) with [`GET`](./get) parameter in new code.\n\n@examples\n\n```cli\nSET mykey \"Hello\"\nGETSET mykey \"World\"\nGET mykey\n```\n\n",
            "deprecated": true,
            "": "",
            "return_types": [
                {
                    "description": "the old value stored at `key`, or `nil` when `key` did not exist.",
                    "type": "bulk-string"
                }
            ],
            "summary": "Set the string value of a key and return its old value",
            "complexity": "O(1)",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "name": "value",
                    "type": "string",
                    "value": "value"
                }
            ],
            "since": "1.0.0",
            "group": "string",
            "arity": 3,
            "command_flags": [
                "write",
                "denyoom",
                "fast"
            ],
            "acl_categories": [
                "write",
                "string",
                "fast"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write",
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "getsetCommand"
        }
    },
    {
        "SMISMEMBER": {
            "body": "Returns whether each `member` is a member of the set stored at `key`.\n\nFor every `member`, `1` is returned if the value is a member of the set, or `0` if the element is not a member of the set or if `key` does not exist.\n\n@examples\n\n```cli\nSADD myset \"one\"\nSADD myset \"one\"\nSMISMEMBER myset \"one\" \"notamember\"\n```\n\n",
            "": "",
            "return_types": [
                {
                    "description": "list representing the membership of the given elements, in the same",
                    "type": "array"
                }
            ],
            "summary": "Returns the membership associated with the given elements for a set",
            "complexity": "O(N) where N is the number of elements being checked for membership",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "multiple": true,
                    "multiple_token": true,
                    "name": "member",
                    "type": "string",
                    "value": "member"
                }
            ],
            "since": "6.2.0",
            "group": "set",
            "arity": -3,
            "command_flags": [
                "readonly",
                "fast"
            ],
            "acl_categories": [
                "read",
                "set",
                "fast"
            ],
            "key_specs": [
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "smismemberCommand"
        }
    },
    {
        "HKEYS": {
            "body": "Returns all field names in the hash stored at `key`.\n\n@examples\n\n```cli\nHSET myhash field1 \"Hello\"\nHSET myhash field2 \"World\"\nHKEYS myhash\n```\n\n",
            "": "",
            "return_types": [
                {
                    "description": "list of fields in the hash, or an empty list when `key` does",
                    "type": "array"
                }
            ],
            "summary": "Get all the fields in a hash",
            "complexity": "O(N) where N is the size of the hash.",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                }
            ],
            "since": "2.0.0",
            "group": "hash",
            "arity": 2,
            "command_flags": [
                "readonly",
                "sort_for_script"
            ],
            "acl_categories": [
                "read",
                "hash",
                "slow"
            ],
            "key_specs": [
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "hkeysCommand"
        }
    },
    {
        "ZREM": {
            "body": "Removes the specified members from the sorted set stored at `key`.\nNon existing members are ignored.\n\nAn error is returned when `key` exists and does not hold a sorted set.\n\n@examples\n\n```cli\nZADD myzset 1 \"one\"\nZADD myzset 2 \"two\"\nZADD myzset 3 \"three\"\nZREM myzset \"two\"\nZRANGE myzset 0 -1 WITHSCORES\n```\n\n",
            "history": [
                [
                    "2.4",
                    "Accepts multiple elements."
                ]
            ],
            "return_summary": "@integer-reply, specifically:\n\n* The number of members removed from the sorted set, not including non existing\n  members.",
            "": "",
            "summary": "Remove one or more members from a sorted set",
            "complexity": "O(M*log(N)) with N being the number of elements in the sorted set and M the number of elements to be removed.",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "multiple": true,
                    "multiple_token": true,
                    "name": "member",
                    "type": "string",
                    "value": "member"
                }
            ],
            "since": "1.2.0",
            "group": "sorted_set",
            "arity": -3,
            "command_flags": [
                "write",
                "fast"
            ],
            "acl_categories": [
                "write",
                "sortedset",
                "fast"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "zremCommand"
        }
    },
    {
        "RPOPLPUSH": {
            "body": "Atomically returns and removes the last element (tail) of the list stored at\n`source`, and pushes the element at the first element (head) of the list stored\nat `destination`.\n\nFor example: consider `source` holding the list `a,b,c`, and `destination`\nholding the list `x,y,z`.\nExecuting `RPOPLPUSH` results in `source` holding `a,b` and `destination`\nholding `c,x,y,z`.\n\nIf `source` does not exist, the value `nil` is returned and no operation is\nperformed.\nIf `source` and `destination` are the same, the operation is equivalent to\nremoving the last element from the list and pushing it as first element of the\nlist, so it can be considered as a list rotation command.\n\nAs per Redis 6.2.0, RPOPLPUSH is considered deprecated. Please prefer [`LMOVE`](./lmove) in\nnew code.\n\n@examples\n\n```cli\nRPUSH mylist \"one\"\nRPUSH mylist \"two\"\nRPUSH mylist \"three\"\nRPOPLPUSH mylist myotherlist\nLRANGE mylist 0 -1\nLRANGE myotherlist 0 -1\n```\n\n## Pattern: Reliable queue\n\nRedis is often used as a messaging server to implement processing of background\njobs or other kinds of messaging tasks.\nA simple form of queue is often obtained pushing values into a list in the\nproducer side, and waiting for this values in the consumer side using [`RPOP`](./rpop)\n(using polling), or [`BRPOP`](./brpop) if the client is better served by a blocking\noperation.\n\nHowever in this context the obtained queue is not _reliable_ as messages can\nbe lost, for example in the case there is a network problem or if the consumer\ncrashes just after the message is received but before it can be processed.\n\n`RPOPLPUSH` (or [`BRPOPLPUSH`](./brpoplpush) for the blocking variant) offers a way to avoid\nthis problem: the consumer fetches the message and at the same time pushes it\ninto a _processing_ list.\nIt will use the [`LREM`](./lrem) command in order to remove the message from the\n_processing_ list once the message has been processed.\n\nAn additional client may monitor the _processing_ list for items that remain\nthere for too much time, pushing timed out items into the queue\nagain if needed.\n\n## Pattern: Circular list\n\nUsing `RPOPLPUSH` with the same source and destination key, a client can visit\nall the elements of an N-elements list, one after the other, in O(N) without\ntransferring the full list from the server to the client using a single [`LRANGE`](./lrange)\noperation.\n\nThe above pattern works even if one or both of the following conditions occur:\n\n* There are multiple clients rotating the list: they'll fetch different \n  elements, until all the elements of the list are visited, and the process \n  restarts.\n* Other clients are actively pushing new items at the end of the list.\n\nThe above makes it very simple to implement a system where a set of items must\nbe processed by N workers continuously as fast as possible.\nAn example is a monitoring system that must check that a set of web sites are\nreachable, with the smallest delay possible, using a number of parallel workers.\n\nNote that this implementation of workers is trivially scalable and reliable,\nbecause even if a message is lost the item is still in the queue and will be\nprocessed at the next iteration.\n\n",
            "deprecated": true,
            "": "",
            "return_types": [
                {
                    "description": "the element being popped and pushed.",
                    "type": "bulk-string"
                }
            ],
            "summary": "Remove the last element in a list, prepend it to another list and return it",
            "complexity": "O(1)",
            "arguments": [
                {
                    "name": "source",
                    "type": "key",
                    "value": "source"
                },
                {
                    "name": "destination",
                    "type": "key",
                    "value": "destination"
                }
            ],
            "since": "1.2.0",
            "group": "list",
            "arity": 3,
            "command_flags": [
                "write",
                "denyoom"
            ],
            "acl_categories": [
                "write",
                "list",
                "slow"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write",
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                },
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 2
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "rpoplpushCommand"
        }
    },
    {
        "RENAMENX": {
            "body": "Renames `key` to `newkey` if `newkey` does not yet exist.\nIt returns an error when `key` does not exist.\n\nIn Cluster mode, both `key` and `newkey` must be in the same **hash slot**, meaning that in practice only keys that have the same hash tag can be reliably renamed in cluster.\n\n\n@examples\n\n```cli\nSET mykey \"Hello\"\nSET myotherkey \"World\"\nRENAMENX mykey myotherkey\nGET myotherkey\n```\n\n",
            "return_summary": "@integer-reply, specifically:\n\n* `1` if `key` was renamed to `newkey`.\n* `0` if `newkey` already exists.",
            "": "",
            "summary": "Rename a key, only if the new key does not exist",
            "complexity": "O(1)",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "name": "newkey",
                    "type": "key",
                    "value": "newkey"
                }
            ],
            "since": "1.0.0",
            "group": "generic",
            "arity": 3,
            "command_flags": [
                "write",
                "fast"
            ],
            "acl_categories": [
                "keyspace",
                "write",
                "fast"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 1,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "renamenxCommand"
        }
    },
    {
        "PUBSUB": {
            "arity": -2,
            "command_flags": [],
            "acl_categories": [
                "slow"
            ],
            "subcommands": [
                {
                    "HELP": {
                        "body": "The `PUBSUB HELP` command returns a helpful text describing the different subcommands.\n\n",
                        "": "",
                        "return_types": [
                            {
                                "description": "a list of subcommands and their descriptions",
                                "type": "array"
                            }
                        ],
                        "summary": "Show helpful text about the different subcommands",
                        "complexity": "O(1)",
                        "since": "6.2.0",
                        "group": "pubsub",
                        "arity": 2,
                        "command_flags": [
                            "loading",
                            "stale"
                        ],
                        "acl_categories": [
                            "slow"
                        ],
                        "function": "pubsubCommand",
                        "container": "PUBSUB"
                    }
                },
                {
                    "NUMSUB": {
                        "body": "Returns the number of subscribers (exclusive of clients subscribed to patterns) for the specified channels.\n\nNote that it is valid to call this command without channels. In this case it will just return an empty list.\n\nCluster note: in a Redis Cluster clients can subscribe to every node, and can also publish to every other node. The cluster will make sure that published messages are forwarded as needed. That said, [`PUBSUB`](./pubsub)'s replies in a cluster only report information from the node's Pub/Sub context, rather than the entire cluster.\n\n",
                        "": "",
                        "return_types": [
                            {
                                "description": "a list of channels and number of subscribers for every channel.",
                                "type": "array"
                            }
                        ],
                        "summary": "Get the count of subscribers for channels",
                        "complexity": "O(N) for the NUMSUB subcommand, where N is the number of requested channels",
                        "since": "2.8.0",
                        "group": "pubsub",
                        "arguments": [
                            {
                                "optional": true,
                                "multiple": true,
                                "multiple_token": true,
                                "name": "channel",
                                "type": "string",
                                "value": "channel"
                            }
                        ],
                        "arity": -2,
                        "command_flags": [
                            "pubsub",
                            "loading",
                            "stale"
                        ],
                        "acl_categories": [
                            "pubsub",
                            "slow"
                        ],
                        "function": "pubsubCommand",
                        "container": "PUBSUB"
                    }
                },
                {
                    "NUMPAT": {
                        "body": "Returns the number of unique patterns that are subscribed to by clients (that are performed using the [`PSUBSCRIBE`](./psubscribe) command).\n\nNote that this isn't the count of clients subscribed to patterns, but the total number of unique patterns all the clients are subscribed to.\n\nCluster note: in a Redis Cluster clients can subscribe to every node, and can also publish to every other node. The cluster will make sure that published messages are forwarded as needed. That said, [`PUBSUB`](./pubsub)'s replies in a cluster only report information from the node's Pub/Sub context, rather than the entire cluster.\n\n",
                        "": "",
                        "return_types": [
                            {
                                "description": "the number of patterns all the clients are subscribed to.",
                                "type": "integer"
                            }
                        ],
                        "summary": "Get the count of unique patterns pattern subscriptions",
                        "complexity": "O(1)",
                        "since": "2.8.0",
                        "group": "pubsub",
                        "arity": 2,
                        "command_flags": [
                            "pubsub",
                            "loading",
                            "stale"
                        ],
                        "acl_categories": [
                            "pubsub",
                            "slow"
                        ],
                        "function": "pubsubCommand",
                        "container": "PUBSUB"
                    }
                },
                {
                    "CHANNELS": {
                        "body": "Lists the currently *active channels*.\n\nAn active channel is a Pub/Sub channel with one or more subscribers (excluding clients subscribed to patterns).\n\nIf no `pattern` is specified, all the channels are listed, otherwise if pattern is specified only channels matching the specified glob-style pattern are listed.\n\nCluster note: in a Redis Cluster clients can subscribe to every node, and can also publish to every other node. The cluster will make sure that published messages are forwarded as needed. That said, [`PUBSUB`](./pubsub)'s replies in a cluster only report information from the node's Pub/Sub context, rather than the entire cluster.\n\n",
                        "": "",
                        "return_types": [
                            {
                                "description": "a list of active channels, optionally matching the specified pattern.",
                                "type": "array"
                            }
                        ],
                        "summary": "List active channels",
                        "complexity": "O(N) where N is the number of active channels, and assuming constant time pattern matching (relatively short channels and patterns)",
                        "since": "2.8.0",
                        "group": "pubsub",
                        "arguments": [
                            {
                                "optional": true,
                                "name": "pattern",
                                "type": "string",
                                "value": "pattern"
                            }
                        ],
                        "arity": -2,
                        "command_flags": [
                            "pubsub",
                            "loading",
                            "stale"
                        ],
                        "acl_categories": [
                            "pubsub",
                            "slow"
                        ],
                        "function": "pubsubCommand",
                        "container": "PUBSUB"
                    }
                }
            ],
            "group": "pubsub",
            "since": "2.8.0"
        }
    },
    {
        "MIGRATE": {
            "body": "Atomically transfer a key from a source Redis instance to a destination Redis\ninstance.\nOn success the key is deleted from the original instance and is guaranteed to\nexist in the target instance.\n\nThe command is atomic and blocks the two instances for the time required to\ntransfer the key, at any given time the key will appear to exist in a given\ninstance or in the other instance, unless a timeout error occurs. In 3.2 and\nabove, multiple keys can be pipelined in a single call to `MIGRATE` by passing\nthe empty string (\"\") as key and adding the [`KEYS`](./keys) clause.\n\nThe command internally uses [`DUMP`](./dump) to generate the serialized version of the key\nvalue, and [`RESTORE`](./restore) in order to synthesize the key in the target instance.\nThe source instance acts as a client for the target instance.\nIf the target instance returns OK to the [`RESTORE`](./restore) command, the source instance\ndeletes the key using [`DEL`](./del).\n\nThe timeout specifies the maximum idle time in any moment of the communication\nwith the destination instance in milliseconds.\nThis means that the operation does not need to be completed within the specified\namount of milliseconds, but that the transfer should make progresses without\nblocking for more than the specified amount of milliseconds.\n\n`MIGRATE` needs to perform I/O operations and to honor the specified timeout.\nWhen there is an I/O error during the transfer or if the timeout is reached the\noperation is aborted and the special error - `IOERR` returned.\nWhen this happens the following two cases are possible:\n\n* The key may be on both the instances.\n* The key may be only in the source instance.\n\nIt is not possible for the key to get lost in the event of a timeout, but the\nclient calling `MIGRATE`, in the event of a timeout error, should check if the\nkey is _also_ present in the target instance and act accordingly.\n\nWhen any other error is returned (starting with `ERR`) `MIGRATE` guarantees that\nthe key is still only present in the originating instance (unless a key with the\nsame name was also _already_ present on the target instance).\n\nIf there are no keys to migrate in the source instance `NOKEY` is returned.\nBecause missing keys are possible in normal conditions, from expiry for example,\n`NOKEY` isn't an error. \n\n## Migrating multiple keys with a single command call\n\nStarting with Redis 3.0.6 `MIGRATE` supports a new bulk-migration mode that\nuses pipelining in order to migrate multiple keys between instances without\nincurring in the round trip time latency and other overheads that there are\nwhen moving each key with a single `MIGRATE` call.\n\nIn order to enable this form, the `KEYS` option is used, and the normal *key*\nargument is set to an empty string. The actual key names will be provided\nafter the `KEYS` argument itself, like in the following example:\n\n    MIGRATE 192.168.1.34 6379 \"\" 0 5000 KEYS key1 key2 key3\n\nWhen this form is used the `NOKEY` status code is only returned when none\nof the keys is present in the instance, otherwise the command is executed, even if\njust a single key exists.\n\n## Options\n\n* `COPY` -- Do not remove the key from the local instance.\n* `REPLACE` -- Replace existing key on the remote instance.\n* `KEYS` -- If the key argument is an empty string, the command will instead migrate all the keys that follow the [`KEYS`](./keys) option (see the above section for more info).\n* `AUTH` -- Authenticate with the given password to the remote instance.\n* `AUTH2` -- Authenticate with the given username and password pair (Redis 6 or greater ACL auth style).\n\n",
            "history": [
                [
                    "3.0.0",
                    "Added the `COPY` and `REPLACE` options."
                ],
                [
                    "3.0.6",
                    "Added the `KEYS` option."
                ],
                [
                    "4.0.7",
                    "Added the `AUTH` option."
                ],
                [
                    "6.0.0",
                    "Added the `AUTH2` option."
                ]
            ],
            "": "",
            "return_types": [
                {
                    "description": "The command returns OK on success, or `NOKEY` if no keys were",
                    "type": "simple-string"
                }
            ],
            "summary": "Atomically transfer a key from a Redis instance to another one.",
            "complexity": "This command actually executes a DUMP+DEL in the source instance, and a RESTORE in the target instance. See the pages of these commands for time complexity. Also an O(N) data transfer between the two instances is performed.",
            "arguments": [
                {
                    "name": "host",
                    "type": "string",
                    "value": "host"
                },
                {
                    "name": "port",
                    "type": "string",
                    "value": "port"
                },
                {
                    "name": "key_\"\"",
                    "type": "oneof",
                    "value": [
                        {
                            "name": "__TBD__5__",
                            "token": "key"
                        },
                        {
                            "name": "__TBD__6__",
                            "token": "\"\""
                        }
                    ]
                },
                {
                    "name": "destination-db",
                    "type": "integer",
                    "value": "destination-db"
                },
                {
                    "name": "timeout",
                    "type": "integer",
                    "value": "timeout"
                },
                {
                    "optional": true,
                    "name": "copy",
                    "token": "COPY"
                },
                {
                    "optional": true,
                    "name": "replace",
                    "token": "REPLACE"
                },
                {
                    "token": "AUTH",
                    "optional": true,
                    "name": "password",
                    "type": "string",
                    "value": "password"
                },
                {
                    "token": "AUTH2",
                    "optional": true,
                    "name": "username_password",
                    "type": "block",
                    "value": [
                        {
                            "name": "username",
                            "type": "string",
                            "value": "username"
                        },
                        {
                            "name": "password",
                            "type": "string",
                            "value": "password"
                        }
                    ]
                },
                {
                    "token": "KEYS",
                    "optional": true,
                    "multiple": true,
                    "name": "key",
                    "type": "key",
                    "value": "key"
                }
            ],
            "since": "2.6.0",
            "group": "generic",
            "arity": -6,
            "command_flags": [
                "write",
                "random"
            ],
            "acl_categories": [
                "keyspace",
                "write",
                "slow",
                "dangerous"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 3
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                },
                {
                    "flags": [
                        "write",
                        "incomplete"
                    ],
                    "begin_search": {
                        "keyword": {
                            "keyword": "KEYS",
                            "startfrom": -2
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": -1,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "migrateCommand",
            "get_keys_function": "migrateGetKeys"
        }
    },
    {
        "ZCARD": {
            "body": "Returns the sorted set cardinality (number of elements) of the sorted set stored\nat `key`.\n\n@examples\n\n```cli\nZADD myzset 1 \"one\"\nZADD myzset 2 \"two\"\nZCARD myzset\n```\n\n",
            "": "",
            "return_types": [
                {
                    "description": "the cardinality (number of elements) of the sorted set, or `0`",
                    "type": "integer"
                }
            ],
            "summary": "Get the number of members in a sorted set",
            "complexity": "O(1)",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                }
            ],
            "since": "1.2.0",
            "group": "sorted_set",
            "arity": 2,
            "command_flags": [
                "readonly",
                "fast"
            ],
            "acl_categories": [
                "read",
                "sortedset",
                "fast"
            ],
            "key_specs": [
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "zcardCommand"
        }
    },
    {
        "ZMSCORE": {
            "body": "Returns the scores associated with the specified `members` in the sorted set stored at `key`.\n\nFor every `member` that does not exist in the sorted set, a `nil` value is returned.\n\n@examples\n\n```cli\nZADD myzset 1 \"one\"\nZADD myzset 2 \"two\"\nZMSCORE myzset \"one\" \"two\" \"nofield\"\n```\n\n",
            "": "",
            "return_types": [
                {
                    "description": "list of scores or `nil` associated with the specified `member` values (a double precision floating point number),",
                    "type": "array"
                }
            ],
            "summary": "Get the score associated with the given members in a sorted set",
            "complexity": "O(N) where N is the number of members being requested.",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "multiple": true,
                    "multiple_token": true,
                    "name": "member",
                    "type": "string",
                    "value": "member"
                }
            ],
            "since": "6.2.0",
            "group": "sorted_set",
            "arity": -3,
            "command_flags": [
                "readonly",
                "fast"
            ],
            "acl_categories": [
                "read",
                "sortedset",
                "fast"
            ],
            "key_specs": [
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "zmscoreCommand"
        }
    },
    {
        "DEL": {
            "body": "Removes the specified keys.\nA key is ignored if it does not exist.\n\n@examples\n\n```cli\nSET key1 \"Hello\"\nSET key2 \"World\"\nDEL key1 key2 key3\n```\n\n",
            "": "",
            "return_types": [
                {
                    "description": "The number of keys that were removed.",
                    "type": "integer"
                }
            ],
            "summary": "Delete a key",
            "complexity": "O(N) where N is the number of keys that will be removed. When a key to remove holds a value other than a string, the individual complexity for this key is O(M) where M is the number of elements in the list, set, sorted set or hash. Removing a single key that holds a string value is O(1).",
            "arguments": [
                {
                    "multiple": true,
                    "multiple_token": true,
                    "name": "key",
                    "type": "key",
                    "value": "key"
                }
            ],
            "since": "1.0.0",
            "group": "generic",
            "arity": -2,
            "command_flags": [
                "write"
            ],
            "acl_categories": [
                "keyspace",
                "write",
                "slow"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": -1,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "delCommand"
        }
    },
    {
        "XDEL": {
            "body": "Removes the specified entries from a stream, and returns the number of entries\ndeleted.  This number may be less than the number of IDs passed to the command in\nthe case where some of the specified IDs do not exist in the stream.\n\nNormally you may think at a Redis stream as an append-only data structure,\nhowever Redis streams are represented in memory, so we are also able to \ndelete entries. This may be useful, for instance, in order to comply with\ncertain privacy policies.\n\n# Understanding the low level details of entries deletion\n\nRedis streams are represented in a way that makes them memory efficient:\na radix tree is used in order to index macro-nodes that pack linearly tens\nof stream entries. Normally what happens when you delete an entry from a stream\nis that the entry is not *really* evicted, it just gets marked as deleted.\n\nEventually if all the entries in a macro-node are marked as deleted, the whole\nnode is destroyed and the memory reclaimed. This means that if you delete\na large amount of entries from a stream, for instance more than 50% of the\nentries appended to the stream, the memory usage per entry may increment, since\nwhat happens is that the stream will become fragmented. However the stream\nperformance will remain the same.\n\nIn future versions of Redis it is possible that we'll trigger a node garbage\ncollection in case a given macro-node reaches a given amount of deleted\nentries. Currently with the usage we anticipate for this data structure, it is\nnot a good idea to add such complexity.\n\n@examples\n\n```\n> XADD mystream * a 1\n1538561698944-0\n> XADD mystream * b 2\n1538561700640-0\n> XADD mystream * c 3\n1538561701744-0\n> XDEL mystream 1538561700640-0\n(integer) 1\n127.0.0.1:6379> XRANGE mystream - +\n1) 1) 1538561698944-0\n   2) 1) \"a\"\n      2) \"1\"\n2) 1) 1538561701744-0\n   2) 1) \"c\"\n      2) \"3\"\n```\n\n",
            "": "",
            "return_types": [
                {
                    "description": "the number of entries actually deleted.",
                    "type": "integer"
                }
            ],
            "summary": "Removes the specified entries from the stream. Returns the number of items actually deleted, that may be different from the number of IDs passed in case certain IDs do not exist.",
            "complexity": "O(1) for each single item to delete in the stream, regardless of the stream size.",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "multiple": true,
                    "multiple_token": true,
                    "name": "ID",
                    "type": "string",
                    "value": "ID"
                }
            ],
            "since": "5.0.0",
            "group": "stream",
            "arity": -3,
            "command_flags": [
                "write",
                "fast"
            ],
            "acl_categories": [
                "write",
                "stream",
                "fast"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "xdelCommand"
        }
    },
    {
        "XADD": {
            "body": "Appends the specified stream entry to the stream at the specified key.\nIf the key does not exist, as a side effect of running this command the\nkey is created with a stream value. The creation of stream's key can be\ndisabled with the `NOMKSTREAM` option.\n\nAn entry is composed of a set of field-value pairs, it is basically a\nsmall dictionary. The field-value pairs are stored in the same order\nthey are given by the user, and commands to read the stream such as\n[`XRANGE`](./xrange) or [`XREAD`](./xread) are guaranteed to return the fields and values\nexactly in the same order they were added by `XADD`.\n\n`XADD` is the *only Redis command* that can add data to a stream, but \nthere are other commands, such as [`XDEL`](./xdel) and [`XTRIM`](./xtrim), that are able to\nremove data from a stream.\n\n## Specifying a Stream ID as an argument\n\nA stream entry ID identifies a given entry inside a stream.\n\nThe `XADD` command will auto-generate a unique ID for you if the ID argument\nspecified is the `*` character (asterisk ASCII character). However, while\nuseful only in very rare cases, it is possible to specify a well-formed ID, so\nthat the new entry will be added exactly with the specified ID.\n\nIDs are specified by two numbers separated by a `-` character:\n\n    1526919030474-55\n\nBoth quantities are 64-bit numbers. When an ID is auto-generated, the\nfirst part is the Unix time in milliseconds of the Redis instance generating\nthe ID. The second part is just a sequence number and is used in order to\ndistinguish IDs generated in the same millisecond.\n\nIDs are guaranteed to be always incremental: If you compare the ID of the\nentry just inserted it will be greater than any other past ID, so entries\nare totally ordered inside a stream. In order to guarantee this property,\nif the current top ID in the stream has a time greater than the current\nlocal time of the instance, the top entry time will be used instead, and\nthe sequence part of the ID incremented. This may happen when, for instance,\nthe local clock jumps backward, or if after a failover the new master has\na different absolute time.\n\nWhen a user specified an explicit ID to `XADD`, the minimum valid ID is\n`0-1`, and the user *must* specify an ID which is greater than any other\nID currently inside the stream, otherwise the command will fail and return an error. Usually\nresorting to specific IDs is useful only if you have another system generating\nunique IDs (for instance an SQL table) and you really want the Redis stream\nIDs to match the one of this other system.\n\n## Capped streams\n\n`XADD` incorporates the same semantics as the [`XTRIM`](./xtrim) command - refer to its documentation page for more information.\nThis allows adding new entries and keeping the stream's size in check with a single call to `XADD`, effectively capping the stream with an arbitrary threshold.\nAlthough exact trimming is possible and is the default, due to the internal representation of steams it is more efficient to add an entry and trim stream with `XADD` using **almost exact** trimming (the `~` argument).\n\nFor example, calling `XADD` in the following form:\n\n    XADD mystream MAXLEN ~ 1000 * ... entry fields here ...\n \nWill add a new entry but will also evict old entries so that the stream will contain only 1000 entries, or at most a few tens more.\n\n## Additional information about streams\n\nFor further information about Redis streams please check our\n[introduction to Redis Streams document](/topics/streams-intro).\n\n@examples\n\n```cli\nXADD mystream * name Sara surname OConnor\nXADD mystream * field1 value1 field2 value2 field3 value3\nXLEN mystream\nXRANGE mystream - +\n```\n\n",
            "history": [
                [
                    "6.2",
                    "Added the `NOMKSTREAM` option, `MINID` trimming strategy and the `LIMIT` option."
                ]
            ],
            "return_summary": "@bulk-string-reply, specifically:\n\nThe command returns the ID of the added entry. The ID is the one auto-generated\nif `*` is passed as ID argument, otherwise the command just returns the same ID\nspecified by the user during insertion.\n\nThe command returns a @nil-reply when used with the `NOMKSTREAM` option and the\nkey doesn't exist.",
            "": "",
            "summary": "Appends a new entry to a stream",
            "complexity": "O(1) when adding a new entry, O(N) when trimming where N being the number of entires evicted.",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "token": "NOMKSTREAM",
                    "optional": true,
                    "name": "nomkstream"
                },
                {
                    "optional": true,
                    "name": "trim",
                    "type": "block",
                    "value": [
                        {
                            "name": "maxlen_minid",
                            "type": "oneof",
                            "value": [
                                {
                                    "name": "__TBD__7__",
                                    "token": "MAXLEN"
                                },
                                {
                                    "name": "__TBD__8__",
                                    "token": "MINID"
                                }
                            ]
                        },
                        {
                            "optional": true,
                            "name": "=_~",
                            "type": "oneof",
                            "value": [
                                {
                                    "name": "__TBD__9__",
                                    "token": "="
                                },
                                {
                                    "name": "__TBD__10__",
                                    "token": "~"
                                }
                            ]
                        },
                        {
                            "name": "threshold",
                            "type": "string",
                            "value": "threshold"
                        },
                        {
                            "token": "LIMIT",
                            "optional": true,
                            "name": "count",
                            "type": "integer",
                            "value": "count"
                        }
                    ]
                },
                {
                    "name": "*_id",
                    "type": "oneof",
                    "value": [
                        {
                            "name": "__TBD__11__",
                            "token": "*"
                        },
                        {
                            "name": "id",
                            "type": "__TBD__12__",
                            "value": "id"
                        }
                    ]
                },
                {
                    "multiple": true,
                    "multiple_token": true,
                    "name": "field_value",
                    "type": "block",
                    "value": [
                        {
                            "name": "field",
                            "type": "string",
                            "value": "field"
                        },
                        {
                            "name": "value",
                            "type": "string",
                            "value": "value"
                        }
                    ]
                }
            ],
            "since": "5.0.0",
            "group": "stream",
            "arity": -5,
            "command_flags": [
                "write",
                "denyoom",
                "random",
                "fast"
            ],
            "acl_categories": [
                "write",
                "stream",
                "fast"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "xaddCommand"
        }
    },
    {
        "HDEL": {
            "body": "Removes the specified fields from the hash stored at `key`.\nSpecified fields that do not exist within this hash are ignored.\nIf `key` does not exist, it is treated as an empty hash and this command returns\n`0`.\n\n@examples\n\n```cli\nHSET myhash field1 \"foo\"\nHDEL myhash field1\nHDEL myhash field2\n```\n\n",
            "": "",
            "return_types": [
                {
                    "description": "the number of fields that were removed from the hash, not",
                    "type": "integer"
                }
            ],
            "summary": "Delete one or more hash fields",
            "complexity": "O(N) where N is the number of fields to be removed.",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "multiple": true,
                    "multiple_token": true,
                    "name": "field",
                    "type": "string",
                    "value": "field"
                }
            ],
            "since": "2.0.0",
            "group": "hash",
            "arity": -3,
            "command_flags": [
                "write",
                "fast"
            ],
            "acl_categories": [
                "write",
                "hash",
                "fast"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "hdelCommand"
        }
    },
    {
        "INCRBY": {
            "body": "Increments the number stored at `key` by `increment`.\nIf the key does not exist, it is set to `0` before performing the operation.\nAn error is returned if the key contains a value of the wrong type or contains a\nstring that can not be represented as integer.\nThis operation is limited to 64 bit signed integers.\n\nSee [`INCR`](./incr) for extra information on increment/decrement operations.\n\n@examples\n\n```cli\nSET mykey \"10\"\nINCRBY mykey 5\n```\n\n",
            "": "",
            "return_types": [
                {
                    "description": "the value of `key` after the increment",
                    "type": "integer"
                }
            ],
            "summary": "Increment the integer value of a key by the given amount",
            "complexity": "O(1)",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "name": "increment",
                    "type": "integer",
                    "value": "increment"
                }
            ],
            "since": "1.0.0",
            "group": "string",
            "arity": 3,
            "command_flags": [
                "write",
                "denyoom",
                "fast"
            ],
            "acl_categories": [
                "write",
                "string",
                "fast"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "incrbyCommand"
        }
    },
    {
        "HELLO": {
            "body": "Switch to a different protocol, optionally authenticating and setting the\nconnection's name, or provide a contextual client report.\n\nRedis version 6 and above supports two protocols: the old protocol, RESP2, and\na new one introduced with Redis 6, RESP3. RESP3 has certain advantages since\nwhen the connection is in this mode, Redis is able to reply with more semantical\nreplies: for instance, [`HGETALL`](./hgetall) will return a *map type*, so a client library\nimplementation no longer requires to know in advance to translate the array into\na hash before returning it to the caller. For a full coverage of RESP3, please\n[check this repository](https://github.com/antirez/resp3).\n\nIn Redis 6 connections start in RESP2 mode, so clients implementing RESP2 do\nnot need to updated or changed. There are no short term plans to drop support for\nRESP2, although future version may default to RESP3.\n\n`HELLO` always replies with a list of current server and connection properties,\nsuch as: versions, modules loaded, client ID, replication role and so forth.\nWhen called without any arguments in Redis 6.2 and its default use of RESP2\nprotocol, the reply looks like this:\n\n    > HELLO\n     1) \"server\"\n     2) \"redis\"\n     3) \"version\"\n     4) \"255.255.255\"\n     5) \"proto\"\n     6) (integer) 2\n     7) \"id\"\n     8) (integer) 5\n     9) \"mode\"\n    10) \"standalone\"\n    11) \"role\"\n    12) \"master\"\n    13) \"modules\"\n    14) (empty array)\n\nClients that want to handshake using the RESP3 mode need to call the `HELLO`\ncommand and specify the value \"3\" as the `protover` argument, like so:\n\n    > HELLO 3\n    1# \"server\" => \"redis\"\n    2# \"version\" => \"6.0.0\"\n    3# \"proto\" => (integer) 3\n    4# \"id\" => (integer) 10\n    5# \"mode\" => \"standalone\"\n    6# \"role\" => \"master\"\n    7# \"modules\" => (empty array)\n\nBecause `HELLO` replies with useful information, and given that `protover` is\noptional or can be set to \"2\", client library authors may consider using this\ncommand instead of the canonical [`PING`](./ping) when setting up the connection.\n\nWhen called with the optional `protover` argument, this command switches the\nprotocol to the specified version and also accepts the following options:\n\n* `AUTH <username> <password>`: directly authenticate the connection in addition to switching to the specified protocol version. This makes calling [`AUTH`](./auth) before `HELLO` unnecessary when setting up a new connection. Note that the `username` can be set to \"default\" to authenticate against a server that does not use ACLs, but rather the simpler `requirepass` mechanism of Redis prior to version 6.\n* `SETNAME <clientname>`: this is the equivalent of calling `CLIENT SETNAME`.\n\n",
            "history": [
                [
                    "6.2",
                    "`protover` made optional; when called without arguments the command reports the current connection's context."
                ]
            ],
            "": "",
            "return_types": [
                {
                    "description": "a list of server properties. The reply is a map instead of an array when RESP3 is selected. The command returns an error if the `protover` requested does not exist.",
                    "type": "array"
                }
            ],
            "summary": "Handshake with Redis",
            "complexity": "O(1)",
            "arguments": [
                {
                    "optional": true,
                    "name": "arguments",
                    "type": "block",
                    "value": [
                        {
                            "name": "protover",
                            "type": "integer",
                            "value": "protover"
                        },
                        {
                            "token": "AUTH",
                            "optional": true,
                            "name": "username_password",
                            "type": "block",
                            "value": [
                                {
                                    "name": "username",
                                    "type": "string",
                                    "value": "username"
                                },
                                {
                                    "name": "password",
                                    "type": "string",
                                    "value": "password"
                                }
                            ]
                        },
                        {
                            "token": "SETNAME",
                            "optional": true,
                            "name": "clientname",
                            "type": "string",
                            "value": "clientname"
                        }
                    ]
                }
            ],
            "since": "6.0.0",
            "group": "connection",
            "arity": -1,
            "command_flags": [
                "noscript",
                "loading",
                "stale",
                "fast",
                "no_auth"
            ],
            "acl_categories": [
                "fast",
                "connection"
            ],
            "function": "helloCommand"
        }
    },
    {
        "RENAME": {
            "body": "Renames `key` to `newkey`.\nIt returns an error when `key` does not exist.\nIf `newkey` already exists it is overwritten, when this happens `RENAME` executes an implicit [`DEL`](./del) operation, so if the deleted key contains a very big value it may cause high latency even if `RENAME` itself is usually a constant-time operation.\n\nIn Cluster mode, both `key` and `newkey` must be in the same **hash slot**, meaning that in practice only keys that have the same hash tag can be reliably renamed in cluster.\n\n@examples\n\n```cli\nSET mykey \"Hello\"\nRENAME mykey myotherkey\nGET myotherkey\n```\n\n",
            "": "",
            "return_types": [
                {
                    "type": "simple-string"
                }
            ],
            "summary": "Rename a key",
            "complexity": "O(1)",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "name": "newkey",
                    "type": "key",
                    "value": "newkey"
                }
            ],
            "since": "1.0.0",
            "group": "generic",
            "arity": 3,
            "command_flags": [
                "write"
            ],
            "acl_categories": [
                "keyspace",
                "write",
                "slow"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 1,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "renameCommand"
        }
    },
    {
        "BITFIELD": {
            "body": "The command treats a Redis string as a array of bits, and is capable of addressing specific integer fields of varying bit widths and arbitrary non (necessary) aligned offset. In practical terms using this command you can set, for example, a signed 5 bits integer at bit offset 1234 to a specific value, retrieve a 31 bit unsigned integer from offset 4567. Similarly the command handles increments and decrements of the specified integers, providing guaranteed and well specified overflow and underflow behavior that the user can configure.\n\n`BITFIELD` is able to operate with multiple bit fields in the same command call. It takes a list of operations to perform, and returns an array of replies, where each array matches the corresponding operation in the list of arguments.\n\nFor example the following command increments an 5 bit signed integer at bit offset 100, and gets the value of the 4 bit unsigned integer at bit offset 0:\n\n    > BITFIELD mykey INCRBY i5 100 1 GET u4 0\n    1) (integer) 1\n    2) (integer) 0\n\nNote that:\n\n1. Addressing with `GET` bits outside the current string length (including the case the key does not exist at all), results in the operation to be performed like the missing part all consists of bits set to 0.\n2. Addressing with `SET` or `INCRBY` bits outside the current string length will enlarge the string, zero-padding it, as needed, for the minimal length needed, according to the most far bit touched.\n\n## Supported subcommands and integer types\n\nThe following is the list of supported commands.\n\n* **GET** `<type>` `<offset>` -- Returns the specified bit field.\n* **SET** `<type>` `<offset>` `<value>` -- Set the specified bit field and returns its old value.\n* **INCRBY** `<type>` `<offset>` `<increment>` -- Increments or decrements (if a negative increment is given) the specified bit field and returns the new value.\n\nThere is another subcommand that only changes the behavior of successive\n`INCRBY` and `SET` subcommands calls by setting the overflow behavior:\n\n* **OVERFLOW** `[WRAP|SAT|FAIL]`\n\nWhere an integer type is expected, it can be composed by prefixing with `i` for signed integers and `u` for unsigned integers with the number of bits of our integer type. So for example `u8` is an unsigned integer of 8 bits and `i16` is a\nsigned integer of 16 bits.\n\nThe supported types are up to 64 bits for signed integers, and up to 63 bits for\nunsigned integers. This limitation with unsigned integers is due to the fact\nthat currently the Redis protocol is unable to return 64 bit unsigned integers\nas replies.\n\n## Bits and positional offsets\n\nThere are two ways in order to specify offsets in the bitfield command.\nIf a number without any prefix is specified, it is used just as a zero based\nbit offset inside the string.\n\nHowever if the offset is prefixed with a `#` character, the specified offset\nis multiplied by the integer type width, so for example:\n\n    BITFIELD mystring SET i8 #0 100 SET i8 #1 200\n\nWill set the first i8 integer at offset 0 and the second at offset 8.\nThis way you don't have to do the math yourself inside your client if what\nyou want is a plain array of integers of a given size.\n\n## Overflow control\n\nUsing the `OVERFLOW` command the user is able to fine-tune the behavior of\nthe increment or decrement overflow (or underflow) by specifying one of\nthe following behaviors:\n\n* **WRAP**: wrap around, both with signed and unsigned integers. In the case of unsigned integers, wrapping is like performing the operation modulo the maximum value the integer can contain (the C standard behavior). With signed integers instead wrapping means that overflows restart towards the most negative value and underflows towards the most positive ones, so for example if an `i8` integer is set to the value 127, incrementing it by 1 will yield `-128`.\n* **SAT**: uses saturation arithmetic, that is, on underflows the value is set to the minimum integer value, and on overflows to the maximum integer value. For example incrementing an `i8` integer starting from value 120 with an increment of 10, will result into the value 127, and further increments will always keep the value at 127. The same happens on underflows, but towards the value is blocked at the most negative value.\n* **FAIL**: in this mode no operation is performed on overflows or underflows detected. The corresponding return value is set to NULL to signal the condition to the caller.\n\nNote that each `OVERFLOW` statement only affects the `INCRBY` and `SET`\ncommands that follow it in the list of subcommands, up to the next `OVERFLOW`\nstatement.\n\nBy default, **WRAP** is used if not otherwise specified.\n\n    > BITFIELD mykey incrby u2 100 1 OVERFLOW SAT incrby u2 102 1\n    1) (integer) 1\n    2) (integer) 1\n    > BITFIELD mykey incrby u2 100 1 OVERFLOW SAT incrby u2 102 1\n    1) (integer) 2\n    2) (integer) 2\n    > BITFIELD mykey incrby u2 100 1 OVERFLOW SAT incrby u2 102 1\n    1) (integer) 3\n    2) (integer) 3\n    > BITFIELD mykey incrby u2 100 1 OVERFLOW SAT incrby u2 102 1\n    1) (integer) 0\n    2) (integer) 3\n\n## Return value\n\nThe command returns an array with each entry being the corresponding result of\nthe sub command given at the same position. `OVERFLOW` subcommands don't count\nas generating a reply.\n\nThe following is an example of `OVERFLOW FAIL` returning NULL.\n\n    > BITFIELD mykey OVERFLOW FAIL incrby u2 102 1\n    1) (nil)\n\n## Motivations\n\nThe motivation for this command is that the ability to store many small integers\nas a single large bitmap (or segmented over a few keys to avoid having huge keys) is extremely memory efficient, and opens new use cases for Redis to be applied, especially in the field of real time analytics. This use cases are supported by the ability to specify the overflow in a controlled way.\n\nFun fact: Reddit's 2017 April fools' project [r/place](https://reddit.com/r/place) was [built using the Redis BITFIELD command](https://redditblog.com/2017/04/13/how-we-built-rplace/) in order to take an in-memory representation of the collaborative canvas.\n\n## Performance considerations\n\nUsually `BITFIELD` is a fast command, however note that addressing far bits of currently short strings will trigger an allocation that may be more costly than executing the command on bits already existing.\n\n## Orders of bits\n\nThe representation used by `BITFIELD` considers the bitmap as having the\nbit number 0 to be the most significant bit of the first byte, and so forth, so\nfor example setting a 5 bits unsigned integer to value 23 at offset 7 into a\nbitmap previously set to all zeroes, will produce the following representation:\n\n    +--------+--------+\n    |00000001|01110000|\n    +--------+--------+\n\nWhen offsets and integer sizes are aligned to bytes boundaries, this is the\nsame as big endian, however when such alignment does not exist, its important\nto also understand how the bits inside a byte are ordered.\n\n",
            "return_summary": "",
            "summary": "Perform arbitrary bitfield integer operations on strings",
            "complexity": "O(1) for each subcommand specified",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "token": "GET",
                    "optional": true,
                    "name": "type_offset",
                    "type": "block",
                    "value": [
                        {
                            "name": "type",
                            "type": "type",
                            "value": "type"
                        },
                        {
                            "name": "offset",
                            "type": "integer",
                            "value": "offset"
                        }
                    ]
                },
                {
                    "token": "SET",
                    "optional": true,
                    "name": "type_offset_value",
                    "type": "block",
                    "value": [
                        {
                            "name": "type",
                            "type": "type",
                            "value": "type"
                        },
                        {
                            "name": "offset",
                            "type": "integer",
                            "value": "offset"
                        },
                        {
                            "name": "value",
                            "type": "integer",
                            "value": "value"
                        }
                    ]
                },
                {
                    "token": "INCRBY",
                    "optional": true,
                    "name": "type_offset_increment",
                    "type": "block",
                    "value": [
                        {
                            "name": "type",
                            "type": "type",
                            "value": "type"
                        },
                        {
                            "name": "offset",
                            "type": "integer",
                            "value": "offset"
                        },
                        {
                            "name": "increment",
                            "type": "integer",
                            "value": "increment"
                        }
                    ]
                },
                {
                    "token": "OVERFLOW",
                    "optional": true,
                    "name": "wrap_sat_fail",
                    "type": "oneof",
                    "value": [
                        {
                            "name": "__TBD__13__",
                            "token": "WRAP"
                        },
                        {
                            "name": "__TBD__14__",
                            "token": "SAT"
                        },
                        {
                            "name": "__TBD__15__",
                            "token": "FAIL"
                        }
                    ]
                }
            ],
            "since": "3.2.0",
            "group": "bitmap",
            "arity": -2,
            "command_flags": [
                "write",
                "denyoom"
            ],
            "acl_categories": [
                "write",
                "bitmap",
                "slow"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "bitfieldCommand"
        }
    },
    {
        "PFCOUNT": {
            "body": "When called with a single key, returns the approximated cardinality computed by the HyperLogLog data structure stored at the specified variable, which is 0 if the variable does not exist.\n\nWhen called with multiple keys, returns the approximated cardinality of the union of the HyperLogLogs passed, by internally merging the HyperLogLogs stored at the provided keys into a temporary HyperLogLog.\n\nThe HyperLogLog data structure can be used in order to count **unique** elements in a set using just a small constant amount of memory, specifically 12k bytes for every HyperLogLog (plus a few bytes for the key itself).\n\nThe returned cardinality of the observed set is not exact, but approximated with a standard error of 0.81%.\n\nFor example in order to take the count of all the unique search queries performed in a day, a program needs to call [`PFADD`](./pfadd) every time a query is processed. The estimated number of unique queries can be retrieved with `PFCOUNT` at any time.\n\nNote: as a side effect of calling this function, it is possible that the HyperLogLog is modified, since the last 8 bytes encode the latest computed cardinality\nfor caching purposes. So `PFCOUNT` is technically a write command.\n\n@examples\n\n```cli\nPFADD hll foo bar zap\nPFADD hll zap zap zap\nPFADD hll foo bar\nPFCOUNT hll\nPFADD some-other-hll 1 2 3\nPFCOUNT hll some-other-hll\n```\n\nPerformances\n---\n\nWhen `PFCOUNT` is called with a single key, performances are excellent even if\nin theory constant times to process a dense HyperLogLog are high. This is\npossible because the `PFCOUNT` uses caching in order to remember the cardinality\npreviously computed, that rarely changes because most [`PFADD`](./pfadd) operations will\nnot update any register. Hundreds of operations per second are possible.\n\nWhen `PFCOUNT` is called with multiple keys, an on-the-fly merge of the\nHyperLogLogs is performed, which is slow, moreover the cardinality of the union\ncan't be cached, so when used with multiple keys `PFCOUNT` may take a time in\nthe order of magnitude of the millisecond, and should be not abused.\n\nThe user should take in mind that single-key and multiple-keys executions of\nthis command are semantically different and have different performances.\n\nHyperLogLog representation\n---\n\nRedis HyperLogLogs are represented using a double representation: the *sparse* representation suitable for HLLs counting a small number of elements (resulting in a small number of registers set to non-zero value), and a *dense* representation suitable for higher cardinalities. Redis automatically switches from the sparse to the dense representation when needed.\n\nThe sparse representation uses a run-length encoding optimized to store efficiently a big number of registers set to zero. The dense representation is a Redis string of 12288 bytes in order to store 16384 6-bit counters. The need for the double representation comes from the fact that using 12k (which is the dense representation memory requirement) to encode just a few registers for smaller cardinalities is extremely suboptimal.\n\nBoth representations are prefixed with a 16 bytes header, that includes a magic, an encoding / version field, and the cached cardinality estimation computed, stored in little endian format (the most significant bit is 1 if the estimation is invalid since the HyperLogLog was updated since the cardinality was computed).\n\nThe HyperLogLog, being a Redis string, can be retrieved with [`GET`](./get) and restored with [`SET`](./set). Calling [`PFADD`](./pfadd), `PFCOUNT` or [`PFMERGE`](./pfmerge) commands with a corrupted HyperLogLog is never a problem, it may return random values but does not affect the stability of the server. Most of the times when corrupting a sparse representation, the server recognizes the corruption and returns an error.\n\nThe representation is neutral from the point of view of the processor word size and endianness, so the same representation is used by 32 bit and 64 bit processor, big endian or little endian.\n\nMore details about the Redis HyperLogLog implementation can be found in [this blog post](http://antirez.com/news/75). The source code of the implementation in the `hyperloglog.c` file is also easy to read and understand, and includes a full specification for the exact encoding used for the sparse and dense representations.\n\n",
            "return_summary": "@integer-reply, specifically:\n\n* The approximated number of unique elements observed via [`PFADD`](./pfadd).",
            "": "",
            "summary": "Return the approximated cardinality of the set(s) observed by the HyperLogLog at key(s).",
            "complexity": "O(1) with a very small average constant time when called with a single key. O(N) with N being the number of keys, and much bigger constant times, when called with multiple keys.",
            "arguments": [
                {
                    "multiple": true,
                    "multiple_token": true,
                    "name": "key",
                    "type": "key",
                    "value": "key"
                }
            ],
            "since": "2.8.9",
            "group": "hyperloglog",
            "arity": -2,
            "command_flags": [
                "readonly",
                "may_replicate"
            ],
            "acl_categories": [
                "read",
                "hyperloglog",
                "slow"
            ],
            "key_specs": [
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": -1,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "pfcountCommand"
        }
    },
    {
        "HMSET": {
            "body": "Sets the specified fields to their respective values in the hash stored at\n`key`.\nThis command overwrites any specified fields already existing in the hash.\nIf `key` does not exist, a new key holding a hash is created.\n\nAs per Redis 4.0.0, HMSET is considered deprecated. Please prefer [`HSET`](./hset) in new code.\n\n@examples\n\n```cli\nHMSET myhash field1 \"Hello\" field2 \"World\"\nHGET myhash field1\nHGET myhash field2\n```\n\n",
            "deprecated": true,
            "": "",
            "return_types": [
                {
                    "type": "simple-string"
                }
            ],
            "summary": "Set multiple hash fields to multiple values",
            "complexity": "O(N) where N is the number of fields being set.",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "multiple": true,
                    "multiple_token": true,
                    "name": "field_value",
                    "type": "block",
                    "value": [
                        {
                            "name": "field",
                            "type": "string",
                            "value": "field"
                        },
                        {
                            "name": "value",
                            "type": "string",
                            "value": "value"
                        }
                    ]
                }
            ],
            "since": "2.0.0",
            "group": "hash",
            "arity": -4,
            "command_flags": [
                "write",
                "denyoom",
                "fast"
            ],
            "acl_categories": [
                "write",
                "hash",
                "fast"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "hsetCommand"
        }
    },
    {
        "SPOP": {
            "body": "Removes and returns one or more random members from the set value store at `key`.\n\nThis operation is similar to [`SRANDMEMBER`](./srandmember), that returns one or more random elements from a set but does not remove it.\n\nBy default, the command pops a single member from the set. When provided with\nthe optional `count` argument, the reply will consist of up to `count` members,\ndepending on the set's cardinality.\n\n@examples\n\n```cli\nSADD myset \"one\"\nSADD myset \"two\"\nSADD myset \"three\"\nSPOP myset\nSMEMBERS myset\nSADD myset \"four\"\nSADD myset \"five\"\nSPOP myset 3\nSMEMBERS myset\n```\n## Distribution of returned elements\n\nNote that this command is not suitable when you need a guaranteed uniform distribution of the returned elements. For more information about the algorithms used for `SPOP`, look up both the Knuth sampling and Floyd sampling algorithms.\n\n",
            "history": [
                [
                    "3.2",
                    "Added the `count` argument."
                ]
            ],
            "return_summary": "When called without the `count` argument:\n\n@bulk-string-reply: the removed member, or `nil` when `key` does not exist.\n\nWhen called with the `count` argument:\n\n@array-reply: the removed members, or an empty array when `key` does not exist.",
            "": "",
            "summary": "Remove and return one or multiple random members from a set",
            "complexity": "Without the count argument O(1), otherwise O(N) where N is the value of the passed count.",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "optional": true,
                    "name": "count",
                    "type": "integer",
                    "value": "count"
                }
            ],
            "since": "1.0.0",
            "group": "set",
            "arity": -2,
            "command_flags": [
                "write",
                "random",
                "fast"
            ],
            "acl_categories": [
                "write",
                "set",
                "fast"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "spopCommand"
        }
    },
    {
        "STRALGO": {
            "body": "The STRALGO implements complex algorithms that operate on strings.\nRight now the only algorithm implemented is the LCS algorithm (longest common\nsubstring). However new algorithms could be implemented in the future.\nThe goal of this command is to provide to Redis users algorithms that need\nfast implementations and are normally not provided in the standard library of\nmost programming languages.\n\nThe first argument of the command selects the algorithm to use, right now\nthe argument must be \"LCS\", since this is the only implemented one.\n\n## LCS algorithm\n\n```\nSTRALGO LCS STRINGS <string_a> <string_b> | KEYS <key_a> <key_b> [LEN] [IDX] [MINMATCHLEN <len>] [WITHMATCHLEN]\n```\n\nThe LCS subcommand implements the longest common subsequence algorithm. Note that this is different than the longest common string algorithm, since matching characters in the string does not need to be contiguous.\n\nFor instance the LCS between \"foo\" and \"fao\" is \"fo\", since scanning the two strings from left to right, the longest common set of characters is composed of the first \"f\" and then the \"o\".\n\nLCS is very useful in order to evaluate how similar two strings are. Strings can represent many things. For instance if two strings are DNA sequences, the LCS will provide a measure of similarity between the two DNA sequences. If the strings represent some text edited by some user, the LCS could represent how different the new text is compared to the old one, and so forth.\n\nNote that this algorithm runs in `O(N*M)` time, where N is the length of the first string and M is the length of the second string. So either spin a different Redis instance in order to run this algorithm, or make sure to run it against very small strings.\n\nThe basic usage is the following:\n\n```\n> STRALGO LCS STRINGS ohmytext mynewtext\n\"mytext\"\n```\n\nIt is also possible to compute the LCS between the content of two keys:\n\n```\n> MSET key1 ohmytext key2 mynewtext\nOK\n> STRALGO LCS KEYS key1 key2\n\"mytext\"\n```\n\nSometimes we need just the length of the match:\n\n```\n> STRALGO LCS STRINGS ohmytext mynewtext LEN\n6\n```\n\nHowever what is often very useful, is to know the match position in each strings:\n\n```\n> STRALGO LCS KEYS key1 key2 IDX\n1) \"matches\"\n2) 1) 1) 1) (integer) 4\n         2) (integer) 7\n      2) 1) (integer) 5\n         2) (integer) 8\n   2) 1) 1) (integer) 2\n         2) (integer) 3\n      2) 1) (integer) 0\n         2) (integer) 1\n3) \"len\"\n4) (integer) 6\n```\n\nMatches are produced from the last one to the first one, since this is how\nthe algorithm works, and it more efficient to emit things in the same order.\nThe above array means that the first match (second element of the array)\nis between positions 2-3 of the first string and 0-1 of the second.\nThen there is another match between 4-7 and 5-8.\n\nTo restrict the list of matches to the ones of a given minimal length:\n\n```\n> STRALGO LCS KEYS key1 key2 IDX MINMATCHLEN 4\n1) \"matches\"\n2) 1) 1) 1) (integer) 4\n         2) (integer) 7\n      2) 1) (integer) 5\n         2) (integer) 8\n3) \"len\"\n4) (integer) 6\n```\n\nFinally to also have the match len:\n\n```\n> STRALGO LCS KEYS key1 key2 IDX MINMATCHLEN 4 WITHMATCHLEN\n1) \"matches\"\n2) 1) 1) 1) (integer) 4\n         2) (integer) 7\n      2) 1) (integer) 5\n         2) (integer) 8\n      3) (integer) 4\n3) \"len\"\n4) (integer) 6\n```\n\n",
            "return_summary": "For the LCS algorithm:\n\n* Without modifiers the string representing the longest common substring is returned.\n* When `LEN` is given the command returns the length of the longest common substring.\n* When `IDX` is given the command returns an array with the LCS length and all the ranges in both the strings, start and end offset for each string, where there are matches. When `WITHMATCHLEN` is given each array representing a match will also have the length of the match (see examples).",
            "": "",
            "summary": "Run algorithms (currently LCS) against strings",
            "complexity": "For LCS O(strlen(s1)*strlen(s2))",
            "arguments": [
                {
                    "name": "algorithm",
                    "token": "LCS"
                },
                {
                    "multiple": true,
                    "multiple_token": true,
                    "name": "algo-specific-argument",
                    "type": "string",
                    "value": "algo-specific-argument"
                }
            ],
            "since": "6.0.0",
            "group": "string",
            "arity": -2,
            "command_flags": [],
            "acl_categories": [
                "slow"
            ],
            "subcommands": [
                {
                    "HELP": {
                        "arity": 2,
                        "command_flags": [
                            "loading",
                            "stale"
                        ],
                        "acl_categories": [
                            "string",
                            "slow"
                        ],
                        "function": "stralgoCommand",
                        "container": "STRALGO",
                        "group": "string"
                    }
                },
                {
                    "LCS": {
                        "arity": -5,
                        "command_flags": [
                            "readonly"
                        ],
                        "acl_categories": [
                            "read",
                            "string",
                            "slow"
                        ],
                        "key_specs": [
                            {
                                "flags": [
                                    "read",
                                    "incomplete"
                                ],
                                "begin_search": {
                                    "unknown": null
                                },
                                "find_keys": {
                                    "unknown": null
                                }
                            }
                        ],
                        "function": "stralgoCommand",
                        "get_keys_function": "lcsGetKeys",
                        "container": "STRALGO",
                        "group": "string"
                    }
                }
            ]
        }
    },
    {
        "MULTI": {
            "body": "Marks the start of a [transaction][tt] block.\nSubsequent commands will be queued for atomic execution using [`EXEC`](./exec).\n\n[tt]: /topics/transactions\n\n",
            "": "",
            "return_types": [
                {
                    "description": "always `OK`.",
                    "type": "simple-string"
                }
            ],
            "summary": "Mark the start of a transaction block",
            "since": "1.2.0",
            "group": "transactions",
            "arity": 1,
            "command_flags": [
                "noscript",
                "loading",
                "stale",
                "fast"
            ],
            "acl_categories": [
                "fast",
                "transaction"
            ],
            "function": "multiCommand"
        }
    },
    {
        "ZREMRANGEBYRANK": {
            "body": "Removes all elements in the sorted set stored at `key` with rank between `start`\nand `stop`.\nBoth `start` and `stop` are `0` -based indexes with `0` being the element with\nthe lowest score.\nThese indexes can be negative numbers, where they indicate offsets starting at\nthe element with the highest score.\nFor example: `-1` is the element with the highest score, `-2` the element with\nthe second highest score and so forth.\n\n@examples\n\n```cli\nZADD myzset 1 \"one\"\nZADD myzset 2 \"two\"\nZADD myzset 3 \"three\"\nZREMRANGEBYRANK myzset 0 1\nZRANGE myzset 0 -1 WITHSCORES\n```\n\n",
            "": "",
            "return_types": [
                {
                    "description": "the number of elements removed.",
                    "type": "integer"
                }
            ],
            "summary": "Remove all members in a sorted set within the given indexes",
            "complexity": "O(log(N)+M) with N being the number of elements in the sorted set and M the number of elements removed by the operation.",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "name": "start",
                    "type": "integer",
                    "value": "start"
                },
                {
                    "name": "stop",
                    "type": "integer",
                    "value": "stop"
                }
            ],
            "since": "2.0.0",
            "group": "sorted_set",
            "arity": 4,
            "command_flags": [
                "write"
            ],
            "acl_categories": [
                "write",
                "sortedset",
                "slow"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "zremrangebyrankCommand"
        }
    },
    {
        "HINCRBYFLOAT": {
            "body": "Increment the specified `field` of a hash stored at `key`, and representing a\nfloating point number, by the specified `increment`. If the increment value\nis negative, the result is to have the hash field value **decremented** instead of incremented.\nIf the field does not exist, it is set to `0` before performing the operation.\nAn error is returned if one of the following conditions occur:\n\n* The field contains a value of the wrong type (not a string).\n* The current field content or the specified increment are not parsable as a\n  double precision floating point number.\n\nThe exact behavior of this command is identical to the one of the [`INCRBYFLOAT`](./incrbyfloat)\ncommand, please refer to the documentation of [`INCRBYFLOAT`](./incrbyfloat) for further\ninformation.\n\n@examples\n\n```cli\nHSET mykey field 10.50\nHINCRBYFLOAT mykey field 0.1\nHINCRBYFLOAT mykey field -5\nHSET mykey field 5.0e3\nHINCRBYFLOAT mykey field 2.0e2\n```\n\n## Implementation details\n\nThe command is always propagated in the replication link and the Append Only\nFile as a [`HSET`](./hset) operation, so that differences in the underlying floating point\nmath implementation will not be sources of inconsistency.\n\n",
            "": "",
            "return_types": [
                {
                    "description": "the value of `field` after the increment.",
                    "type": "bulk-string"
                }
            ],
            "summary": "Increment the float value of a hash field by the given amount",
            "complexity": "O(1)",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "name": "field",
                    "type": "string",
                    "value": "field"
                },
                {
                    "name": "increment",
                    "type": "double",
                    "value": "increment"
                }
            ],
            "since": "2.6.0",
            "group": "hash",
            "arity": 4,
            "command_flags": [
                "write",
                "denyoom",
                "fast"
            ],
            "acl_categories": [
                "write",
                "hash",
                "fast"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "hincrbyfloatCommand"
        }
    },
    {
        "SINTERSTORE": {
            "body": "This command is equal to [`SINTER`](./sinter), but instead of returning the resulting set,\nit is stored in `destination`.\n\nIf `destination` already exists, it is overwritten.\n\n@examples\n\n```cli\nSADD key1 \"a\"\nSADD key1 \"b\"\nSADD key1 \"c\"\nSADD key2 \"c\"\nSADD key2 \"d\"\nSADD key2 \"e\"\nSINTERSTORE key key1 key2\nSMEMBERS key\n```\n\n",
            "": "",
            "return_types": [
                {
                    "description": "the number of elements in the resulting set.",
                    "type": "integer"
                }
            ],
            "summary": "Intersect multiple sets and store the resulting set in a key",
            "complexity": "O(N*M) worst case where N is the cardinality of the smallest set and M is the number of sets.",
            "arguments": [
                {
                    "name": "destination",
                    "type": "key",
                    "value": "destination"
                },
                {
                    "multiple": true,
                    "multiple_token": true,
                    "name": "key",
                    "type": "key",
                    "value": "key"
                }
            ],
            "since": "1.0.0",
            "group": "set",
            "arity": -3,
            "command_flags": [
                "write",
                "denyoom"
            ],
            "acl_categories": [
                "write",
                "set",
                "slow"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                },
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 2
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": -1,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "sinterstoreCommand"
        }
    },
    {
        "UNLINK": {
            "body": "This command is very similar to [`DEL`](./del): it removes the specified keys.\nJust like [`DEL`](./del) a key is ignored if it does not exist. However the command\nperforms the actual memory reclaiming in a different thread, so it is not\nblocking, while [`DEL`](./del) is. This is where the command name comes from: the\ncommand just **unlinks** the keys from the keyspace. The actual removal\nwill happen later asynchronously.\n\n@examples\n\n```cli\nSET key1 \"Hello\"\nSET key2 \"World\"\nUNLINK key1 key2 key3\n```\n\n",
            "": "",
            "return_types": [
                {
                    "description": "The number of keys that were unlinked.",
                    "type": "integer"
                }
            ],
            "summary": "Delete a key asynchronously in another thread. Otherwise it is just as DEL, but non blocking.",
            "complexity": "O(1) for each key removed regardless of its size. Then the command does O(N) work in a different thread in order to reclaim memory, where N is the number of allocations the deleted objects where composed of.",
            "arguments": [
                {
                    "multiple": true,
                    "multiple_token": true,
                    "name": "key",
                    "type": "key",
                    "value": "key"
                }
            ],
            "since": "4.0.0",
            "group": "generic",
            "arity": -2,
            "command_flags": [
                "write",
                "fast"
            ],
            "acl_categories": [
                "keyspace",
                "write",
                "fast"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": -1,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "unlinkCommand"
        }
    },
    {
        "XACK": {
            "body": "The `XACK` command removes one or multiple messages from the\n*Pending Entries List* (PEL) of a stream consumer group. A message is pending,\nand as such stored inside the PEL, when it was delivered to some consumer,\nnormally as a side effect of calling [`XREADGROUP`](./xreadgroup), or when a consumer took\nownership of a message calling [`XCLAIM`](./xclaim). The pending message was delivered to\nsome consumer but the server is yet not sure it was processed at least once.\nSo new calls to [`XREADGROUP`](./xreadgroup) to grab the messages history for a consumer\n(for instance using an ID of 0), will return such message.\nSimilarly the pending message will be listed by the [`XPENDING`](./xpending) command,\nthat inspects the PEL.\n\nOnce a consumer *successfully* processes a message, it should call `XACK`\nso that such message does not get processed again, and as a side effect,\nthe PEL entry about this message is also purged, releasing memory from the\nRedis server.\n\n@examples\n\n```\nredis> XACK mystream mygroup 1526569495631-0\n(integer) 1\n```\n\n",
            "return_summary": "@integer-reply, specifically:\n\nThe command returns the number of messages successfully acknowledged.\nCertain message IDs may no longer be part of the PEL (for example because\nthey have already been acknowledged), and XACK will not count them as\nsuccessfully acknowledged.",
            "": "",
            "summary": "Marks a pending message as correctly processed, effectively removing it from the pending entries list of the consumer group. Return value of the command is the number of messages successfully acknowledged, that is, the IDs we were actually able to resolve in the PEL.",
            "complexity": "O(1) for each message ID processed.",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "name": "group",
                    "type": "string",
                    "value": "group"
                },
                {
                    "multiple": true,
                    "multiple_token": true,
                    "name": "ID",
                    "type": "string",
                    "value": "ID"
                }
            ],
            "since": "5.0.0",
            "group": "stream",
            "arity": -4,
            "command_flags": [
                "write",
                "random",
                "fast"
            ],
            "acl_categories": [
                "write",
                "stream",
                "fast"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "xackCommand"
        }
    },
    {
        "GEOSEARCH": {
            "body": "Return the members of a sorted set populated with geospatial information using [`GEOADD`](./geoadd), which are within the borders of the area specified by a given shape. This command extends the [`GEORADIUS`](./georadius) command, so in addition to searching within circular areas, it supports searching within rectangular areas.\n\nThis command should be used in place of the deprecated [`GEORADIUS`](./georadius) and [`GEORADIUSBYMEMBER`](./georadiusbymember) commands.\n\nThe query's center point is provided by one of these mandatory options:\n\n* `FROMMEMBER`: Use the position of the given existing `<member>` in the sorted set.\n* `FROMLONLAT`: Use the given `<longitude>` and `<latitude>` position.\n\nThe query's shape is provided by one of these mandatory options:\n\n* `BYRADIUS`: Similar to [`GEORADIUS`](./georadius), search inside circular area according to given `<radius>`.\n* `BYBOX`: Search inside an axis-aligned rectangle, determined by `<height>` and `<width>`.\n\nThe command optionally returns additional information using the following options:\n\n* `WITHDIST`: Also return the distance of the returned items from the specified center point. The distance is returned in the same unit as specified for the radius or height and width arguments.\n* `WITHCOORD`: Also return the longitude and latitude of the matching items.\n* `WITHHASH`: Also return the raw geohash-encoded sorted set score of the item, in the form of a 52 bit unsigned integer. This is only useful for low level hacks or debugging and is otherwise of little interest for the general user.\n\nMatching items are returned unsorted by default. To sort them, use one of the following two options:\n\n* `ASC`: Sort returned items from the nearest to the farthest, relative to the center point.\n* `DESC`: Sort returned items from the farthest to the nearest, relative to the center point.\n\nAll matching items are returned by default. To limit the results to the first N matching items, use the **COUNT `<count>`** option.\nWhen the `ANY` option is used, the command returns as soon as enough matches are found.  This means that the results returned may not be the ones closest to the specified point, but the effort invested by the server to generate them is significantly less.\nWhen `ANY` is not provided, the command will perform an effort that is proportional to the number of items matching the specified area and sort them,\nso to query very large areas with a very small `COUNT` option may be slow even if just a few results are returned.\n\n@examples\n\n```cli\nGEOADD Sicily 13.361389 38.115556 \"Palermo\" 15.087269 37.502669 \"Catania\"\nGEOADD Sicily 12.758489 38.788135 \"edge1\"   17.241510 38.788135 \"edge2\" \nGEOSEARCH Sicily FROMLONLAT 15 37 BYRADIUS 200 km ASC\nGEOSEARCH Sicily FROMLONLAT 15 37 BYBOX 400 400 km ASC WITHCOORD WITHDIST\n```\n\n",
            "return_summary": "@array-reply, specifically:\n\n* Without any `WITH` option specified, the command just returns a linear array like [\"New York\",\"Milan\",\"Paris\"].\n* If `WITHCOORD`, `WITHDIST` or `WITHHASH` options are specified, the command returns an array of arrays, where each sub-array represents a single item.\n\nWhen additional information is returned as an array of arrays for each item, the first item in the sub-array is always the name of the returned item. The other information is returned in the following order as successive elements of the sub-array.\n\n1. The distance from the center as a floating point number, in the same unit specified in the shape.\n2. The geohash integer.\n3. The coordinates as a two items x,y array (longitude,latitude).",
            "deprecated": true,
            "": "",
            "summary": "Query a sorted set representing a geospatial index to fetch members inside an area of a box or a circle.",
            "complexity": "O(N+log(M)) where N is the number of elements in the grid-aligned bounding box area around the shape provided as the filter and M is the number of items inside the shape",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "token": "FROMMEMBER",
                    "optional": true,
                    "name": "member",
                    "type": "string",
                    "value": "member"
                },
                {
                    "token": "FROMLONLAT",
                    "optional": true,
                    "name": "longitude_latitude",
                    "type": "block",
                    "value": [
                        {
                            "name": "longitude",
                            "type": "double",
                            "value": "longitude"
                        },
                        {
                            "name": "latitude",
                            "type": "double",
                            "value": "latitude"
                        }
                    ]
                },
                {
                    "optional": true,
                    "name": "circle",
                    "type": "block",
                    "value": [
                        {
                            "token": "BYRADIUS",
                            "name": "radius",
                            "type": "double",
                            "value": "radius"
                        },
                        {
                            "name": "m_km_ft_mi",
                            "type": "oneof",
                            "value": [
                                {
                                    "name": "__TBD__16__",
                                    "token": "m"
                                },
                                {
                                    "name": "__TBD__17__",
                                    "token": "km"
                                },
                                {
                                    "name": "__TBD__18__",
                                    "token": "ft"
                                },
                                {
                                    "name": "__TBD__19__",
                                    "token": "mi"
                                }
                            ]
                        }
                    ]
                },
                {
                    "optional": true,
                    "name": "box",
                    "type": "block",
                    "value": [
                        {
                            "token": "BYBOX",
                            "name": "width",
                            "type": "double",
                            "value": "width"
                        },
                        {
                            "name": "height",
                            "type": "double",
                            "value": "height"
                        },
                        {
                            "name": "m_km_ft_mi",
                            "type": "oneof",
                            "value": [
                                {
                                    "name": "__TBD__20__",
                                    "token": "m"
                                },
                                {
                                    "name": "__TBD__21__",
                                    "token": "km"
                                },
                                {
                                    "name": "__TBD__22__",
                                    "token": "ft"
                                },
                                {
                                    "name": "__TBD__23__",
                                    "token": "mi"
                                }
                            ]
                        }
                    ]
                },
                {
                    "optional": true,
                    "name": "asc_desc",
                    "type": "oneof",
                    "value": [
                        {
                            "name": "__TBD__24__",
                            "token": "ASC"
                        },
                        {
                            "name": "__TBD__25__",
                            "token": "DESC"
                        }
                    ]
                },
                {
                    "optional": true,
                    "name": "count",
                    "type": "block",
                    "value": [
                        {
                            "token": "COUNT",
                            "name": "count",
                            "type": "integer",
                            "value": "count"
                        },
                        {
                            "optional": true,
                            "name": "any",
                            "token": "ANY"
                        }
                    ]
                },
                {
                    "optional": true,
                    "name": "withcoord",
                    "token": "WITHCOORD"
                },
                {
                    "optional": true,
                    "name": "withdist",
                    "token": "WITHDIST"
                },
                {
                    "optional": true,
                    "name": "withhash",
                    "token": "WITHHASH"
                }
            ],
            "since": "6.2",
            "group": "geo",
            "arity": -7,
            "command_flags": [
                "readonly"
            ],
            "acl_categories": [
                "read",
                "geo",
                "slow"
            ],
            "key_specs": [
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "geosearchCommand"
        }
    },
    {
        "LMOVE": {
            "body": "Atomically returns and removes the first/last element (head/tail depending on\nthe `wherefrom` argument) of the list stored at `source`, and pushes the\nelement at the first/last element (head/tail depending on the `whereto`\nargument) of the list stored at `destination`.\n\nFor example: consider `source` holding the list `a,b,c`, and `destination`\nholding the list `x,y,z`.\nExecuting `LMOVE source destination RIGHT LEFT` results in `source` holding\n`a,b` and `destination` holding `c,x,y,z`.\n\nIf `source` does not exist, the value `nil` is returned and no operation is\nperformed.\nIf `source` and `destination` are the same, the operation is equivalent to\nremoving the first/last element from the list and pushing it as first/last\nelement of the list, so it can be considered as a list rotation command (or a\nno-op if `wherefrom` is the same as `whereto`).\n\nThis command comes in place of the now deprecated [`RPOPLPUSH`](./rpoplpush). Doing\n`LMOVE RIGHT LEFT` is equivalent.\n\n@examples\n\n```cli\nRPUSH mylist \"one\"\nRPUSH mylist \"two\"\nRPUSH mylist \"three\"\nLMOVE mylist myotherlist RIGHT LEFT\nLMOVE mylist myotherlist LEFT RIGHT\nLRANGE mylist 0 -1\nLRANGE myotherlist 0 -1\n```\n\n## Pattern: Reliable queue\n\nRedis is often used as a messaging server to implement processing of background\njobs or other kinds of messaging tasks.\nA simple form of queue is often obtained pushing values into a list in the\nproducer side, and waiting for this values in the consumer side using [`RPOP`](./rpop)\n(using polling), or [`BRPOP`](./brpop) if the client is better served by a blocking\noperation.\n\nHowever in this context the obtained queue is not _reliable_ as messages can\nbe lost, for example in the case there is a network problem or if the consumer\ncrashes just after the message is received but it is still to process.\n\n`LMOVE` (or [`BLMOVE`](./blmove) for the blocking variant) offers a way to avoid\nthis problem: the consumer fetches the message and at the same time pushes it\ninto a _processing_ list.\nIt will use the [`LREM`](./lrem) command in order to remove the message from the\n_processing_ list once the message has been processed.\n\nAn additional client may monitor the _processing_ list for items that remain\nthere for too much time, and will push those timed out items into the queue\nagain if needed.\n\n## Pattern: Circular list\n\nUsing `LMOVE` with the same source and destination key, a client can visit\nall the elements of an N-elements list, one after the other, in O(N) without\ntransferring the full list from the server to the client using a single [`LRANGE`](./lrange)\noperation.\n\nThe above pattern works even if the following two conditions:\n\n* There are multiple clients rotating the list: they'll fetch different\n  elements, until all the elements of the list are visited, and the process\n  restarts.\n* Even if other clients are actively pushing new items at the end of the list.\n\nThe above makes it very simple to implement a system where a set of items must\nbe processed by N workers continuously as fast as possible.\nAn example is a monitoring system that must check that a set of web sites are\nreachable, with the smallest delay possible, using a number of parallel workers.\n\nNote that this implementation of workers is trivially scalable and reliable,\nbecause even if a message is lost the item is still in the queue and will be\nprocessed at the next iteration.\n\n",
            "deprecated": true,
            "": "",
            "return_types": [
                {
                    "description": "the element being popped and pushed.",
                    "type": "bulk-string"
                }
            ],
            "summary": "Pop an element from a list, push it to another list and return it",
            "complexity": "O(1)",
            "arguments": [
                {
                    "name": "source",
                    "type": "key",
                    "value": "source"
                },
                {
                    "name": "destination",
                    "type": "key",
                    "value": "destination"
                },
                {
                    "name": "left_right",
                    "type": "oneof",
                    "value": [
                        {
                            "name": "__TBD__26__",
                            "token": "LEFT"
                        },
                        {
                            "name": "__TBD__27__",
                            "token": "RIGHT"
                        }
                    ]
                },
                {
                    "name": "left_right",
                    "type": "oneof",
                    "value": [
                        {
                            "name": "__TBD__28__",
                            "token": "LEFT"
                        },
                        {
                            "name": "__TBD__29__",
                            "token": "RIGHT"
                        }
                    ]
                }
            ],
            "since": "6.2.0",
            "group": "list",
            "arity": 5,
            "command_flags": [
                "write",
                "denyoom"
            ],
            "acl_categories": [
                "write",
                "list",
                "slow"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write",
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                },
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 2
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "lmoveCommand"
        }
    },
    {
        "INCRBYFLOAT": {
            "body": "Increment the string representing a floating point number stored at `key` by the\nspecified `increment`. By using a negative `increment` value, the result is\nthat the value stored at the key is decremented (by the obvious properties\nof addition).\nIf the key does not exist, it is set to `0` before performing the operation.\nAn error is returned if one of the following conditions occur:\n\n* The key contains a value of the wrong type (not a string).\n* The current key content or the specified increment are not parsable as a\n  double precision floating point number.\n\nIf the command is successful the new incremented value is stored as the new\nvalue of the key (replacing the old one), and returned to the caller as a\nstring.\n\nBoth the value already contained in the string key and the increment argument\ncan be optionally provided in exponential notation, however the value computed\nafter the increment is stored consistently in the same format, that is, an\ninteger number followed (if needed) by a dot, and a variable number of digits\nrepresenting the decimal part of the number.\nTrailing zeroes are always removed.\n\nThe precision of the output is fixed at 17 digits after the decimal point\nregardless of the actual internal precision of the computation.\n\n@examples\n\n```cli\nSET mykey 10.50\nINCRBYFLOAT mykey 0.1\nINCRBYFLOAT mykey -5\nSET mykey 5.0e3\nINCRBYFLOAT mykey 2.0e2\n```\n\n## Implementation details\n\nThe command is always propagated in the replication link and the Append Only\nFile as a [`SET`](./set) operation, so that differences in the underlying floating point\nmath implementation will not be sources of inconsistency.\n\n",
            "": "",
            "return_types": [
                {
                    "description": "the value of `key` after the increment.",
                    "type": "bulk-string"
                }
            ],
            "summary": "Increment the float value of a key by the given amount",
            "complexity": "O(1)",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "name": "increment",
                    "type": "double",
                    "value": "increment"
                }
            ],
            "since": "2.6.0",
            "group": "string",
            "arity": 3,
            "command_flags": [
                "write",
                "denyoom",
                "fast"
            ],
            "acl_categories": [
                "write",
                "string",
                "fast"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "incrbyfloatCommand"
        }
    },
    {
        "ZSCORE": {
            "body": "Returns the score of `member` in the sorted set at `key`.\n\nIf `member` does not exist in the sorted set, or `key` does not exist, `nil` is\nreturned.\n\n@examples\n\n```cli\nZADD myzset 1 \"one\"\nZSCORE myzset \"one\"\n```\n\n",
            "": "",
            "return_types": [
                {
                    "description": "the score of `member` (a double precision floating point number),",
                    "type": "bulk-string"
                }
            ],
            "summary": "Get the score associated with the given member in a sorted set",
            "complexity": "O(1)",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "name": "member",
                    "type": "string",
                    "value": "member"
                }
            ],
            "since": "1.2.0",
            "group": "sorted_set",
            "arity": 3,
            "command_flags": [
                "readonly",
                "fast"
            ],
            "acl_categories": [
                "read",
                "sortedset",
                "fast"
            ],
            "key_specs": [
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "zscoreCommand"
        }
    },
    {
        "PSETEX": {
            "body": "`PSETEX` works exactly like [`SETEX`](./setex) with the sole difference that the expire\ntime is specified in milliseconds instead of seconds.\n\n@examples\n\n```cli\nPSETEX mykey 1000 \"Hello\"\nPTTL mykey\nGET mykey\n```\n\n",
            "return_summary": "",
            "summary": "Set the value and expiration in milliseconds of a key",
            "complexity": "O(1)",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "name": "milliseconds",
                    "type": "integer",
                    "value": "milliseconds"
                },
                {
                    "name": "value",
                    "type": "string",
                    "value": "value"
                }
            ],
            "since": "2.6.0",
            "group": "string",
            "arity": 4,
            "command_flags": [
                "write",
                "denyoom"
            ],
            "acl_categories": [
                "write",
                "string",
                "slow"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "psetexCommand"
        }
    },
    {
        "LPOP": {
            "body": "Removes and returns the first elements of the list stored at `key`.\n\nBy default, the command pops a single element from the beginning of the list.\nWhen provided with the optional `count` argument, the reply will consist of up\nto `count` elements, depending on the list's length.\n\n@examples\n\n```cli\nRPUSH mylist \"one\" \"two\" \"three\" \"four\" \"five\"\nLPOP mylist\nLPOP mylist 2\nLRANGE mylist 0 -1\n```\n\n",
            "history": [
                [
                    "6.2",
                    "Added the `count` argument."
                ]
            ],
            "return_summary": "When called without the `count` argument:\n\n@bulk-string-reply: the value of the first element, or `nil` when `key` does not exist.\n\nWhen called with the `count` argument:\n\n@array-reply: list of popped elements, or `nil` when `key` does not exist.",
            "": "",
            "summary": "Remove and get the first elements in a list",
            "complexity": "O(N) where N is the number of elements returned",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "optional": true,
                    "name": "count",
                    "type": "integer",
                    "value": "count"
                }
            ],
            "since": "1.0.0",
            "group": "list",
            "arity": -2,
            "command_flags": [
                "write",
                "fast"
            ],
            "acl_categories": [
                "write",
                "list",
                "fast"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "lpopCommand"
        }
    },
    {
        "LMPOP": {
            "body": "Pops one or more elements from the first non-empty list key from the list of provided key names.\n\nLMPOP and BLMPOP are similar to the following, more limited, commands:\n\n- [`LPOP`](./lpop) or [`RPOP`](./rpop) which take only one key, and can return multiple elements.\n- [`BLPOP`](./blpop) or [`BRPOP`](./brpop) which take multiple keys, but return only one element from just one key.\n\nSee [`BLMPOP`](./blmpop) for the blocking variant of this command.\n\nElements are popped from either the left or right of the first non-empty list based on the passed argument.\nThe number of returned elements is limited to the lower between the non-empty list's length, and the count argument (which defaults to 1).\n\n@examples\n\n```cli\nLMPOP 2 non1 non2 LEFT COUNT 10\nLPUSH mylist \"one\" \"two\" \"three\" \"four\" \"five\"\nLMPOP 1 mylist LEFT\nLRANGE mylist 0 -1\nLMPOP 1 mylist RIGHT COUNT 10\nLPUSH mylist \"one\" \"two\" \"three\" \"four\" \"five\"\nLPUSH mylist2 \"a\" \"b\" \"c\" \"d\" \"e\"\nLMPOP 2 mylist mylist2 right count 3\nLRANGE mylist 0 -1\nLMPOP 2 mylist mylist2 right count 5\nLMPOP 2 mylist mylist2 right count 10\nEXISTS mylist mylist2\n```\n\n",
            "": "",
            "return_types": [
                {
                    "description": "specifically:",
                    "type": "array"
                }
            ],
            "summary": "Pop elements from a list",
            "complexity": "O(N+M) where N is the number of provided keys and M is the number of elements returned.",
            "arguments": [
                {
                    "name": "numkeys",
                    "type": "integer",
                    "value": "numkeys"
                },
                {
                    "multiple": true,
                    "multiple_token": true,
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "name": "left_right",
                    "type": "oneof",
                    "value": [
                        {
                            "name": "__TBD__30__",
                            "token": "LEFT"
                        },
                        {
                            "name": "__TBD__31__",
                            "token": "RIGHT"
                        }
                    ]
                },
                {
                    "token": "COUNT",
                    "optional": true,
                    "name": "count",
                    "type": "integer",
                    "value": "count"
                }
            ],
            "since": "7.0.0",
            "group": "list",
            "arity": -4,
            "command_flags": [
                "write"
            ],
            "acl_categories": [
                "write",
                "list",
                "slow"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "keynum": {
                            "keynumidx": 0,
                            "firstkey": 1,
                            "step": 1
                        }
                    }
                }
            ],
            "function": "lmpopCommand",
            "get_keys_function": "lmpopGetKeys"
        }
    },
    {
        "DBSIZE": {
            "body": "Return the number of keys in the currently-selected database.\n\n",
            "": "",
            "return_types": [
                {
                    "type": "integer"
                }
            ],
            "summary": "Return the number of keys in the selected database",
            "since": "1.0.0",
            "group": "server",
            "arity": 1,
            "command_flags": [
                "readonly",
                "fast"
            ],
            "acl_categories": [
                "keyspace",
                "read",
                "fast"
            ],
            "function": "dbsizeCommand"
        }
    },
    {
        "PFMERGE": {
            "body": "Merge multiple HyperLogLog values into an unique value that will approximate\nthe cardinality of the union of the observed Sets of the source HyperLogLog\nstructures.\n\nThe computed merged HyperLogLog is set to the destination variable, which is\ncreated if does not exist (defaulting to an empty HyperLogLog).\n\nIf the destination variable exists, it is treated as one of the source sets \nand its cardinality will be included in the cardinality of the computed\nHyperLogLog.\n\n@examples\n\n```cli\nPFADD hll1 foo bar zap a\nPFADD hll2 a b c foo\nPFMERGE hll3 hll1 hll2\nPFCOUNT hll3\n```\n\n",
            "": "",
            "return_types": [
                {
                    "description": "The command just returns `OK`.",
                    "type": "simple-string"
                }
            ],
            "summary": "Merge N different HyperLogLogs into a single one.",
            "complexity": "O(N) to merge N HyperLogLogs, but with high constant times.",
            "arguments": [
                {
                    "name": "destkey",
                    "type": "key",
                    "value": "destkey"
                },
                {
                    "multiple": true,
                    "multiple_token": true,
                    "name": "sourcekey",
                    "type": "key",
                    "value": "sourcekey"
                }
            ],
            "since": "2.8.9",
            "group": "hyperloglog",
            "arity": -2,
            "command_flags": [
                "write",
                "denyoom"
            ],
            "acl_categories": [
                "write",
                "hyperloglog",
                "slow"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write",
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                },
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 2
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": -1,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "pfmergeCommand"
        }
    },
    {
        "COPY": {
            "body": "This command copies the value stored at the `source` key to the `destination`\nkey.\n\nBy default, the `destination` key is created in the logical database used by the\nconnection. The `DB` option allows specifying an alternative logical database\nindex for the destination key.\n\nThe command returns an error when the `destination` key already exists. The\n`REPLACE` option removes the `destination` key before copying the value to it.\n\n@examples\n\n```\nSET dolly \"sheep\"\nCOPY dolly clone\nGET clone\n```\n",
            "return_summary": "@integer-reply, specifically:\n\n* `1` if `source` was copied.\n* `0` if `source` was not copied.",
            "": "",
            "summary": "Copy a key",
            "complexity": "O(N) worst case for collections, where N is the number of nested items. O(1) for string values.",
            "since": "6.2.0",
            "arguments": [
                {
                    "name": "source",
                    "type": "key",
                    "value": "source"
                },
                {
                    "name": "destination",
                    "type": "key",
                    "value": "destination"
                },
                {
                    "token": "DB",
                    "optional": true,
                    "name": "destination-db",
                    "type": "integer",
                    "value": "destination-db"
                },
                {
                    "optional": true,
                    "name": "replace",
                    "token": "REPLACE"
                }
            ],
            "group": "generic",
            "arity": -3,
            "command_flags": [
                "write",
                "denyoom"
            ],
            "acl_categories": [
                "keyspace",
                "write",
                "slow"
            ],
            "key_specs": [
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                },
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 2
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "copyCommand"
        }
    },
    {
        "LOLWUT": {
            "body": "The LOLWUT command displays the Redis version: however as a side effect of\ndoing so, it also creates a piece of generative computer art that is different\nwith each version of Redis. The command was introduced in Redis 5 and announced\nwith this [blog post](http://antirez.com/news/123).\n\nBy default the `LOLWUT` command will display the piece corresponding to the\ncurrent Redis version, however it is possible to display a specific version\nusing the following form:\n\n    LOLWUT VERSION 5 ... other optional arguments ...\n\nOf course the \"5\" above is an example. Each LOLWUT version takes a different\nset of arguments in order to change the output. The user is encouraged to\nplay with it to discover how the output changes adding more numerical\narguments.\n\nLOLWUT wants to be a reminder that there is more in programming than just\nputting some code together in order to create something useful. Every\nLOLWUT version should have the following properties:\n\n1. It should display some computer art. There are no limits as long as the output works well in a normal terminal display. However the output should not be limited to graphics (like LOLWUT 5 and 6 actually do), but can be generative poetry and other non graphical things.\n2. LOLWUT output should be completely useless. Displaying some useful Redis internal metrics does not count as a valid LOLWUT.\n3. LOLWUT output should be fast to generate so that the command can be called in production instances without issues. It should remain fast even when the user experiments with odd parameters.\n4. LOLWUT implementations should be safe and carefully checked for security, and resist to untrusted inputs if they take arguments.\n5. LOLWUT must always display the Redis version at the end.\n\n",
            "return_summary": "@bulk-string-reply (or verbatim reply when using the RESP3 protocol): the string containing the generative computer art, and a text with the Redis version.",
            "": "",
            "summary": "Display some computer art and the Redis version",
            "arguments": [
                {
                    "token": "VERSION",
                    "optional": true,
                    "name": "version",
                    "type": "integer",
                    "value": "version"
                }
            ],
            "since": "5.0.0",
            "group": "server",
            "arity": -1,
            "command_flags": [
                "readonly",
                "fast"
            ],
            "acl_categories": [
                "read",
                "fast"
            ],
            "function": "lolwutCommand"
        }
    },
    {
        "ZRANGE": {
            "body": "Returns the specified range of elements in the sorted set stored at `<key>`.\n\n`ZRANGE` can perform different types of range queries: by index (rank), by the score, or by lexicographical order.\n\nStarting with Redis 6.2.0, this command can replace the following commands: [`ZREVRANGE`](./zrevrange), [`ZRANGEBYSCORE`](./zrangebyscore), [`ZREVRANGEBYSCORE`](./zrevrangebyscore), [`ZRANGEBYLEX`](./zrangebylex) and [`ZREVRANGEBYLEX`](./zrevrangebylex).\n\n## Common behavior and options\n\nThe order of elements is from the lowest to the highest score. Elements with the same score are ordered lexicographically.\n\nThe optional `REV` argument reverses the ordering, so elements are ordered from highest to lowest score, and score ties are resolved by reverse lexicographical ordering.\n\nThe optional `LIMIT` argument can be used to obtain a sub-range from the matching elements (similar to _SELECT LIMIT offset, count_ in SQL).\nA negative `<count>` returns all elements from the `<offset>`. Keep in mind that if `<offset>` is large, the sorted set needs to be traversed for `<offset>` elements before getting to the elements to return, which can add up to O(N) time complexity.\n\nThe optional `WITHSCORES` argument supplements the command's reply with the scores of elements returned. The returned list contains `value1,score1,...,valueN,scoreN` instead of `value1,...,valueN`. Client libraries are free to return a more appropriate data type (suggestion: an array with (value, score) arrays/tuples).\n\n## Index ranges\n\nBy default, the command performs an index range query. The `<min>` and `<max>` arguments represent zero-based indexes, where `0` is the first element, `1` is the next element, and so on. These arguments specify an **inclusive range**, so for example, `ZRANGE myzset 0 1` will return both the first and the second element of the sorted set.\n\nThe indexes can also be negative numbers indicating offsets from the end of the sorted set, with `-1` being the last element of the sorted set, `-2` the penultimate element, and so on.\n\nOut of range indexes do not produce an error.\n\nIf `<min>` is greater than either the end index of the sorted set or `<max>`, an empty list is returned.\n\nIf `<max>` is greater than the end index of the sorted set, Redis will use the last element of the sorted set.\n\n## Score ranges\n\nWhen the `BYSCORE` option is provided, the command behaves like [`ZRANGEBYSCORE`](./zrangebyscore) and returns the range of elements from the sorted set having scores equal or between `<min>` and `<max>`.\n\n`<min>` and `<max>` can be `-inf` and `+inf`, denoting the negative and positive infinities, respectively. This means that you are not required to know the highest or lowest score in the sorted set to get all elements from or up to a certain score.\n\nBy default, the score intervals specified by `<min>` and `<max>` are closed (inclusive).\nIt is possible to specify an open interval (exclusive) by prefixing the score\nwith the character `(`.\n\nFor example:\n\n```\nZRANGE zset (1 5 BYSCORE\n```\n\nWill return all elements with `1 < score <= 5` while:\n\n```\nZRANGE zset (5 (10 BYSCORE\n```\n\nWill return all the elements with `5 < score < 10` (5 and 10 excluded).\n\n## Lexicographical ranges\n\nWhen the `BYLEX` option is used, the command behaves like [`ZRANGEBYLEX`](./zrangebylex) and returns the range of elements from the sorted set between the `<min>` and `<max>` lexicographical closed range intervals.\n\nNote that lexicographical ordering relies on all elements having the same score. The reply is unspecified when the elements have different scores.\n\nValid `<min>` and `<max>` must start with `(` or `[`, in order to specify\nwhether the range interval is exclusive or inclusive, respectively.\n\nThe special values of `+` or `-` `<min>` and `<max>` mean positive and negative infinite strings, respectively, so for instance the command **ZRANGEBYLEX myzset - +** is guaranteed to return all the elements in the sorted set, providing that all the elements have the same score.\n\n### Lexicographical comparison of strings\n\nStrings are compared as a binary array of bytes. Because of how the ASCII character set is specified, this means that usually this also have the effect of comparing normal ASCII characters in an obvious dictionary way. However, this is not true if non-plain ASCII strings are used (for example, utf8 strings).\n\nHowever, the user can apply a transformation to the encoded string so that the first part of the element inserted in the sorted set will compare as the user requires for the specific application. For example, if I want to\nadd strings that will be compared in a case-insensitive way, but I still\nwant to retrieve the real case when querying, I can add strings in the\nfollowing way:\n\n    ZADD autocomplete 0 foo:Foo 0 bar:BAR 0 zap:zap\n\nBecause of the first *normalized* part in every element (before the colon character), we are forcing a given comparison. However, after the range is queried using `ZRANGE ... BYLEX`, the application can display to the user the second part of the string, after the colon.\n\nThe binary nature of the comparison allows to use sorted sets as a general purpose index, for example, the first part of the element can be a 64-bit big-endian number. Since big-endian numbers have the most significant bytes in the initial positions, the binary comparison will match the numerical comparison of the numbers. This can be used in order to implement range queries on 64-bit values. As in the example below, after the first 8 bytes, we can store the value of the element we are indexing.\n\n@examples\n\n```cli\nZADD myzset 1 \"one\"\nZADD myzset 2 \"two\"\nZADD myzset 3 \"three\"\nZRANGE myzset 0 -1\nZRANGE myzset 2 3\nZRANGE myzset -2 -1\n```\n\nThe following example using `WITHSCORES` shows how the command returns always an array, but this time, populated with *element_1*, *score_1*, *element_2*, *score_2*, ..., *element_N*, *score_N*.\n\n```cli\nZRANGE myzset 0 1 WITHSCORES\n```\n\nThis example shows how to query the sorted set by score, excluding the value `1` and up to infinity, returning only the second element of the result:\n\n```cli\nZRANGE myzset (1 +inf BYSCORE LIMIT 1 1\n```\n",
            "history": [
                [
                    "6.2",
                    "Added the `REV`, `BYSCORE`, `BYLEX` and `LIMIT` options."
                ]
            ],
            "": "",
            "return_types": [
                {
                    "description": "list of elements in the specified range (optionally with",
                    "type": "array"
                }
            ],
            "summary": "Return a range of members in a sorted set",
            "complexity": "O(log(N)+M) with N being the number of elements in the sorted set and M the number of elements returned.",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "name": "min",
                    "type": "string",
                    "value": "min"
                },
                {
                    "name": "max",
                    "type": "string",
                    "value": "max"
                },
                {
                    "optional": true,
                    "name": "byscore_bylex",
                    "type": "oneof",
                    "value": [
                        {
                            "name": "__TBD__32__",
                            "token": "BYSCORE"
                        },
                        {
                            "name": "__TBD__33__",
                            "token": "BYLEX"
                        }
                    ]
                },
                {
                    "optional": true,
                    "name": "rev",
                    "token": "REV"
                },
                {
                    "token": "LIMIT",
                    "optional": true,
                    "name": "offset_count",
                    "type": "block",
                    "value": [
                        {
                            "name": "offset",
                            "type": "integer",
                            "value": "offset"
                        },
                        {
                            "name": "count",
                            "type": "integer",
                            "value": "count"
                        }
                    ]
                },
                {
                    "optional": true,
                    "name": "withscores",
                    "token": "WITHSCORES"
                }
            ],
            "since": "1.2.0",
            "group": "sorted_set",
            "arity": -4,
            "command_flags": [
                "readonly"
            ],
            "acl_categories": [
                "read",
                "sortedset",
                "slow"
            ],
            "key_specs": [
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "zrangeCommand"
        }
    },
    {
        "SUNIONSTORE": {
            "body": "This command is equal to [`SUNION`](./sunion), but instead of returning the resulting set,\nit is stored in `destination`.\n\nIf `destination` already exists, it is overwritten.\n\n@examples\n\n```cli\nSADD key1 \"a\"\nSADD key1 \"b\"\nSADD key1 \"c\"\nSADD key2 \"c\"\nSADD key2 \"d\"\nSADD key2 \"e\"\nSUNIONSTORE key key1 key2\nSMEMBERS key\n```\n\n",
            "": "",
            "return_types": [
                {
                    "description": "the number of elements in the resulting set.",
                    "type": "integer"
                }
            ],
            "summary": "Add multiple sets and store the resulting set in a key",
            "complexity": "O(N) where N is the total number of elements in all given sets.",
            "arguments": [
                {
                    "name": "destination",
                    "type": "key",
                    "value": "destination"
                },
                {
                    "multiple": true,
                    "multiple_token": true,
                    "name": "key",
                    "type": "key",
                    "value": "key"
                }
            ],
            "since": "1.0.0",
            "group": "set",
            "arity": -3,
            "command_flags": [
                "write",
                "denyoom"
            ],
            "acl_categories": [
                "write",
                "set",
                "slow"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                },
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 2
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": -1,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "sunionstoreCommand"
        }
    },
    {
        "CLUSTER": {
            "arity": -2,
            "command_flags": [],
            "acl_categories": [
                "slow"
            ],
            "subcommands": [
                {
                    "INFO": {
                        "body": "`CLUSTER INFO` provides [`INFO`](./info) style information about Redis Cluster\nvital parameters. The following is a sample output, followed by the\ndescription of each field reported.\n\n```\ncluster_state:ok\ncluster_slots_assigned:16384\ncluster_slots_ok:16384\ncluster_slots_pfail:0\ncluster_slots_fail:0\ncluster_known_nodes:6\ncluster_size:3\ncluster_current_epoch:6\ncluster_my_epoch:2\ncluster_stats_messages_sent:1483972\ncluster_stats_messages_received:1483968\n```\n\n* `cluster_state`: State is `ok` if the node is able to receive queries. `fail` if there is at least one hash slot which is unbound (no node associated), in error state (node serving it is flagged with FAIL flag), or if the majority of masters can't be reached by this node.\n* `cluster_slots_assigned`: Number of slots which are associated to some node (not unbound). This number should be 16384 for the node to work properly, which means that each hash slot should be mapped to a node.\n* `cluster_slots_ok`: Number of hash slots mapping to a node not in `FAIL` or `PFAIL` state.\n* `cluster_slots_pfail`: Number of hash slots mapping to a node in `PFAIL` state. Note that those hash slots still work correctly, as long as the `PFAIL` state is not promoted to `FAIL` by the failure detection algorithm. `PFAIL` only means that we are currently not able to talk with the node, but may be just a transient error.\n* `cluster_slots_fail`: Number of hash slots mapping to a node in `FAIL` state. If this number is not zero the node is not able to serve queries unless `cluster-require-full-coverage` is set to `no` in the configuration.\n* `cluster_known_nodes`: The total number of known nodes in the cluster, including nodes in `HANDSHAKE` state that may not currently be proper members of the cluster.\n* `cluster_size`: The number of master nodes serving at least one hash slot in the cluster.\n* `cluster_current_epoch`: The local `Current Epoch` variable. This is used in order to create unique increasing version numbers during fail overs.\n* `cluster_my_epoch`: The `Config Epoch` of the node we are talking with. This is the current configuration version assigned to this node.\n* `cluster_stats_messages_sent`: Number of messages sent via the cluster node-to-node binary bus.\n* `cluster_stats_messages_received`: Number of messages received via the cluster node-to-node binary bus.\n\nMore information about the Current Epoch and Config Epoch variables are available in the Redis Cluster specification document.\n\n",
                        "": "",
                        "return_types": [
                            {
                                "description": "A map between named fields and values in the form of `<field>:<value>` lines separated by newlines composed by the two bytes `CRLF`.",
                                "type": "bulk-string"
                            }
                        ],
                        "summary": "Provides info about Redis Cluster node state",
                        "complexity": "O(1)",
                        "since": "3.0.0",
                        "group": "cluster",
                        "arity": 2,
                        "command_flags": [
                            "random",
                            "stale"
                        ],
                        "acl_categories": [
                            "slow"
                        ],
                        "function": "clusterCommand",
                        "container": "CLUSTER"
                    }
                },
                {
                    "KEYSLOT": {
                        "body": "Returns an integer identifying the hash slot the specified key hashes to.\nThis command is mainly useful for debugging and testing, since it exposes\nvia an API the underlying Redis implementation of the hashing algorithm.\nExample use cases for this command:\n\n1. Client libraries may use Redis in order to test their own hashing algorithm, generating random keys and hashing them with both their local implementation and using Redis `CLUSTER KEYSLOT` command, then checking if the result is the same.\n2. Humans may use this command in order to check what is the hash slot, and then the associated Redis Cluster node, responsible for a given key.\n\n## Example\n\n```\n> CLUSTER KEYSLOT somekey\n11058\n> CLUSTER KEYSLOT foo{hash_tag}\n(integer) 2515\n> CLUSTER KEYSLOT bar{hash_tag}\n(integer) 2515\n```\n\nNote that the command implements the full hashing algorithm, including support for **hash tags**, that is the special property of Redis Cluster key hashing algorithm, of hashing just what is between `{` and `}` if such a pattern is found inside the key name, in order to force multiple keys to be handled by the same node.\n\n",
                        "": "",
                        "return_types": [
                            {
                                "description": "The hash slot number.",
                                "type": "integer"
                            }
                        ],
                        "summary": "Returns the hash slot of the specified key",
                        "complexity": "O(N) where N is the number of bytes in the key",
                        "arguments": [
                            {
                                "name": "key",
                                "type": "string",
                                "value": "key"
                            }
                        ],
                        "since": "3.0.0",
                        "group": "cluster",
                        "arity": 3,
                        "command_flags": [
                            "random",
                            "stale"
                        ],
                        "acl_categories": [
                            "slow"
                        ],
                        "function": "clusterCommand",
                        "container": "CLUSTER"
                    }
                },
                {
                    "BUMPEPOCH": {
                        "body": "Advances the cluster config epoch.\n\nThe `CLUSTER BUMPEPOCH` command triggers an increment to the cluster's config epoch from the connected node. The epoch will be incremented if the node's config epoch is zero, or if it is less than the cluster's greatest epoch.\n\n**Note:** config epoch management is performed internally by the cluster, and relies on obtaining a consensus of nodes. The `CLUSTER BUMPEPOCH` attempts to increment the config epoch **WITHOUT** getting the consensus, so using it may violate the \"last failover wins\" rule. Use it with caution.\n\n",
                        "": "",
                        "return_types": [
                            {
                                "description": "`BUMPED` if the epoch was incremented, or `STILL` if the node already has the greatest config epoch in the cluster.",
                                "type": "simple-string"
                            }
                        ],
                        "summary": "Advance the cluster config epoch",
                        "complexity": "O(1)",
                        "since": "3.0.0",
                        "group": "cluster",
                        "arity": 2,
                        "command_flags": [
                            "admin",
                            "random",
                            "stale"
                        ],
                        "acl_categories": [
                            "admin",
                            "slow",
                            "dangerous"
                        ],
                        "function": "clusterCommand",
                        "container": "CLUSTER"
                    }
                },
                {
                    "ADDSLOTSRANGE": {
                        "arity": -4,
                        "command_flags": [
                            "admin",
                            "random",
                            "stale"
                        ],
                        "acl_categories": [
                            "admin",
                            "slow",
                            "dangerous"
                        ],
                        "function": "clusterCommand",
                        "container": "CLUSTER",
                        "group": "cluster"
                    }
                },
                {
                    "FLUSHSLOTS": {
                        "body": "Deletes all slots from a node.\n\nThe `CLUSTER FLUSHSLOTS` deletes all information about slots from the connected node. It can only be called when the database is empty.\n\n",
                        "": "",
                        "return_types": [
                            {
                                "description": "`OK`",
                                "type": "simple-string"
                            }
                        ],
                        "summary": "Delete a node's own slots information",
                        "complexity": "O(1)",
                        "since": "3.0.0",
                        "group": "cluster",
                        "arity": 2,
                        "command_flags": [
                            "admin",
                            "random",
                            "stale"
                        ],
                        "acl_categories": [
                            "admin",
                            "slow",
                            "dangerous"
                        ],
                        "function": "clusterCommand",
                        "container": "CLUSTER"
                    }
                },
                {
                    "FORGET": {
                        "body": "The command is used in order to remove a node, specified via its node ID,\nfrom the set of *known nodes* of the Redis Cluster node receiving the command.\nIn other words the specified node is removed from the *nodes table* of the\nnode receiving the command.\n\nBecause when a given node is part of the cluster, all the other nodes\nparticipating in the cluster knows about it, in order for a node to be\ncompletely removed from a cluster, the `CLUSTER FORGET` command must be\nsent to all the remaining nodes, regardless of the fact they are masters\nor replicas.\n\nHowever the command cannot simply drop the node from the internal node\ntable of the node receiving the command, it also implements a ban-list, not\nallowing the same node to be added again as a side effect of processing the\n*gossip section* of the heartbeat packets received from other nodes.\n\n## Details on why the ban-list is needed\n\nIn the following example we'll show why the command must not just remove\na given node from the nodes table, but also prevent it for being re-inserted\nagain for some time.\n\nLet's assume we have four nodes, A, B, C and D. In order to\nend with just a three nodes cluster A, B, C we may follow these steps:\n\n1. Reshard all the hash slots from D to nodes A, B, C.\n2. D is now empty, but still listed in the nodes table of A, B and C.\n3. We contact A, and send `CLUSTER FORGET D`.\n4. B sends node A a heartbeat packet, where node D is listed.\n5. A does no longer known node D (see step 3), so it starts an handshake with D.\n6. D ends re-added in the nodes table of A.\n\nAs you can see in this way removing a node is fragile, we need to send\n`CLUSTER FORGET` commands to all the nodes ASAP hoping there are no\ngossip sections processing in the meantime. Because of this problem the\ncommand implements a ban-list with an expire time for each entry.\n\nSo what the command really does is:\n\n1. The specified node gets removed from the nodes table.\n2. The node ID of the removed node gets added to the ban-list, for 1 minute.\n3. The node will skip all the node IDs listed in the ban-list when processing gossip sections received in heartbeat packets from other nodes.\n\nThis way we have a 60 second window to inform all the nodes in the cluster that\nwe want to remove a node.\n\n## Special conditions not allowing the command execution\n\nThe command does not succeed and returns an error in the following cases:\n\n1. The specified node ID is not found in the nodes table.\n2. The node receiving the command is a replica, and the specified node ID identifies its current master.\n3. The node ID identifies the same node we are sending the command to.\n\n",
                        "": "",
                        "return_types": [
                            {
                                "description": "`OK` if the command was executed successfully, otherwise an error is returned.",
                                "type": "simple-string"
                            }
                        ],
                        "summary": "Remove a node from the nodes table",
                        "complexity": "O(1)",
                        "arguments": [
                            {
                                "name": "node-id",
                                "type": "string",
                                "value": "node-id"
                            }
                        ],
                        "since": "3.0.0",
                        "group": "cluster",
                        "arity": 3,
                        "command_flags": [
                            "admin",
                            "random",
                            "stale"
                        ],
                        "acl_categories": [
                            "admin",
                            "slow",
                            "dangerous"
                        ],
                        "function": "clusterCommand",
                        "container": "CLUSTER"
                    }
                },
                {
                    "NODES": {
                        "body": "Each node in a Redis Cluster has its view of the current cluster configuration,\ngiven by the set of known nodes, the state of the connection we have with such\nnodes, their flags, properties and assigned slots, and so forth.\n\n`CLUSTER NODES` provides all this information, that is, the current cluster\nconfiguration of the node we are contacting, in a serialization format which\nhappens to be exactly the same as the one used by Redis Cluster itself in\norder to store on disk the cluster state (however the on disk cluster state\nhas a few additional info appended at the end).\n\nNote that normally clients willing to fetch the map between Cluster\nhash slots and node addresses should use `CLUSTER SLOTS` instead.\n`CLUSTER NODES`, that provides more information, should be used for\nadministrative tasks, debugging, and configuration inspections.\nIt is also used by `redis-cli` in order to manage a cluster.\n\n## Serialization format\n\nThe output of the command is just a space-separated CSV string, where\neach line represents a node in the cluster. The following is an example\nof output:\n\n```\n07c37dfeb235213a872192d90877d0cd55635b91 127.0.0.1:30004@31004 slave e7d1eecce10fd6bb5eb35b9f99a514335d9ba9ca 0 1426238317239 4 connected\n67ed2db8d677e59ec4a4cefb06858cf2a1a89fa1 127.0.0.1:30002@31002 master - 0 1426238316232 2 connected 5461-10922\n292f8b365bb7edb5e285caf0b7e6ddc7265d2f4f 127.0.0.1:30003@31003 master - 0 1426238318243 3 connected 10923-16383\n6ec23923021cf3ffec47632106199cb7f496ce01 127.0.0.1:30005@31005 slave 67ed2db8d677e59ec4a4cefb06858cf2a1a89fa1 0 1426238316232 5 connected\n824fe116063bc5fcf9f4ffd895bc17aee7731ac3 127.0.0.1:30006@31006 slave 292f8b365bb7edb5e285caf0b7e6ddc7265d2f4f 0 1426238317741 6 connected\ne7d1eecce10fd6bb5eb35b9f99a514335d9ba9ca 127.0.0.1:30001@31001 myself,master - 0 0 1 connected 0-5460\n```\n\nEach line is composed of the following fields:\n\n```\n<id> <ip:port@cport> <flags> <master> <ping-sent> <pong-recv> <config-epoch> <link-state> <slot> <slot> ... <slot>\n```\n\nThe meaning of each filed is the following:\n\n1. `id`: The node ID, a 40 characters random string generated when a node is created and never changed again (unless `CLUSTER RESET HARD` is used).\n2. `ip:port@cport`: The node address where clients should contact the node to run queries.\n3. `flags`: A list of comma separated flags: `myself`, `master`, `slave`, `fail?`, `fail`, `handshake`, `noaddr`, `nofailover`, `noflags`. Flags are explained in detail in the next section.\n4. `master`: If the node is a replica, and the master is known, the master node ID, otherwise the \"-\" character.\n5. `ping-sent`: Milliseconds unix time at which the currently active ping was sent, or zero if there are no pending pings.\n6. `pong-recv`: Milliseconds unix time the last pong was received.\n7. `config-epoch`: The configuration epoch (or version) of the current node (or of the current master if the node is a replica). Each time there is a failover, a new, unique, monotonically increasing configuration epoch is created. If multiple nodes claim to serve the same hash slots, the one with higher configuration epoch wins.\n8. `link-state`: The state of the link used for the node-to-node cluster bus. We use this link to communicate with the node. Can be `connected` or `disconnected`.\n9. `slot`: A hash slot number or range. Starting from argument number 9, but there may be up to 16384 entries in total (limit never reached). This is the list of hash slots served by this node. If the entry is just a number, is parsed as such. If it is a range, it is in the form `start-end`, and means that the node is responsible for all the hash slots from `start` to `end` including the start and end values.\n\nMeaning of the flags (field number 3):\n\n* `myself`: The node you are contacting.\n* `master`: Node is a master.\n* `slave`: Node is a replica.\n* `fail?`: Node is in `PFAIL` state. Not reachable for the node you are contacting, but still logically reachable (not in `FAIL` state).\n* `fail`: Node is in `FAIL` state. It was not reachable for multiple nodes that promoted the `PFAIL` state to `FAIL`.\n* `handshake`: Untrusted node, we are handshaking.\n* `noaddr`: No address known for this node.\n* `nofailover`: Replica will not try to failover.\n* `noflags`: No flags at all.\n\n## Notes on published config epochs\n\nReplicas broadcast their master's config epochs (in order to get an `UPDATE`\nmessage if they are found to be stale), so the real config epoch of the\nreplica (which is meaningless more or less, since they don't serve hash slots)\ncan be only obtained checking the node flagged as `myself`, which is the entry\nof the node we are asking to generate `CLUSTER NODES` output. The other\nreplicas epochs reflect what they publish in heartbeat packets, which is, the\nconfiguration epoch of the masters they are currently replicating.\n\n## Special slot entries\n\nNormally hash slots associated to a given node are in one of the following formats,\nas already explained above:\n\n1. Single number: 3894\n2. Range: 3900-4000\n\nHowever node hash slots can be in a special state, used in order to communicate errors after a node restart (mismatch between the keys in the AOF/RDB file, and the node hash slots configuration), or when there is a resharding operation in progress. This two states are **importing** and **migrating**.\n\nThe meaning of the two states is explained in the Redis Specification, however the gist of the two states is the following:\n\n* **Importing** slots are yet not part of the nodes hash slot, there is a migration in progress. The node will accept queries about these slots only if the `ASK` command is used.\n* **Migrating** slots are assigned to the node, but are being migrated to some other node. The node will accept queries if all the keys in the command exist already, otherwise it will emit what is called an **ASK redirection**, to force new keys creation directly in the importing node.\n\nImporting and migrating slots are emitted in the `CLUSTER NODES` output as follows:\n\n* **Importing slot:** `[slot_number-<-importing_from_node_id]`\n* **Migrating slot:** `[slot_number->-migrating_to_node_id]`\n\nThe following are a few examples of importing and migrating slots:\n\n* `[93-<-292f8b365bb7edb5e285caf0b7e6ddc7265d2f4f]`\n* `[1002-<-67ed2db8d677e59ec4a4cefb06858cf2a1a89fa1]`\n* `[77->-e7d1eecce10fd6bb5eb35b9f99a514335d9ba9ca]`\n* `[16311->-292f8b365bb7edb5e285caf0b7e6ddc7265d2f4f]`\n\nNote that the format does not have any space, so `CLUSTER NODES` output format is plain CSV with space as separator even when this special slots are emitted. However a complete parser for the format should be able to handle them.\n\nNote that:\n\n1. Migration and importing slots are only added to the node flagged as `myself`. This information is local to a node, for its own slots.\n2. Importing and migrating slots are provided as **additional info**. If the node has a given hash slot assigned, it will be also a plain number in the list of hash slots, so clients that don't have a clue about hash slots migrations can just skip this special fields.\n\n",
                        "": "",
                        "return_types": [
                            {
                                "description": "The serialized cluster configuration.",
                                "type": "bulk-string"
                            }
                        ],
                        "summary": "Get Cluster config for the node",
                        "complexity": "O(N) where N is the total number of Cluster nodes",
                        "since": "3.0.0",
                        "group": "cluster",
                        "arity": 2,
                        "command_flags": [
                            "random",
                            "stale"
                        ],
                        "acl_categories": [
                            "slow"
                        ],
                        "function": "clusterCommand",
                        "container": "CLUSTER"
                    }
                },
                {
                    "GETKEYSINSLOT": {
                        "body": "The command returns an array of keys names stored in the contacted node and\nhashing to the specified hash slot. The maximum number of keys to return\nis specified via the `count` argument, so that it is possible for the user\nof this API to batch-processing keys.\n\nThe main usage of this command is during rehashing of cluster slots from one\nnode to another. The way the rehashing is performed is exposed in the Redis\nCluster specification, or in a more simple to digest form, as an appendix\nof the `CLUSTER SETSLOT` command documentation.\n\n```\n> CLUSTER GETKEYSINSLOT 7000 3\n\"47344|273766|70329104160040|key_39015\"\n\"47344|273766|70329104160040|key_89793\"\n\"47344|273766|70329104160040|key_92937\"\n```\n\n",
                        "": "",
                        "return_types": [
                            {
                                "description": "From 0 to *count* key names in a Redis array reply.",
                                "type": "array"
                            }
                        ],
                        "summary": "Return local key names in the specified hash slot",
                        "complexity": "O(log(N)) where N is the number of requested keys",
                        "arguments": [
                            {
                                "name": "slot",
                                "type": "integer",
                                "value": "slot"
                            },
                            {
                                "name": "count",
                                "type": "integer",
                                "value": "count"
                            }
                        ],
                        "since": "3.0.0",
                        "group": "cluster",
                        "arity": 4,
                        "command_flags": [
                            "random",
                            "stale"
                        ],
                        "acl_categories": [
                            "slow"
                        ],
                        "function": "clusterCommand",
                        "container": "CLUSTER"
                    }
                },
                {
                    "ADDSLOTS": {
                        "body": "This command is useful in order to modify a node's view of the cluster\nconfiguration. Specifically it assigns a set of hash slots to the node\nreceiving the command. If the command is successful, the node will map\nthe specified hash slots to itself, and will start broadcasting the new\nconfiguration.\n\nHowever note that:\n\n1. The command only works if all the specified slots are, from the point of view of the node receiving the command, currently not assigned. A node will refuse to take ownership for slots that already belong to some other node (including itself).\n2. The command fails if the same slot is specified multiple times.\n3. As a side effect of the command execution, if a slot among the ones specified as argument is set as `importing`, this state gets cleared once the node assigns the (previously unbound) slot to itself.\n\n## Example\n\nFor example the following command assigns slots 1 2 3 to the node receiving\nthe command:\n\n    > CLUSTER ADDSLOTS 1 2 3\n    OK\n\nHowever trying to execute it again results into an error since the slots\nare already assigned:\n\n    > CLUSTER ADDSLOTS 1 2 3\n    ERR Slot 1 is already busy\n\n## Usage in Redis Cluster\n\nThis command only works in cluster mode and is useful in the following\nRedis Cluster operations:\n\n1. To create a new cluster ADDSLOTS is used in order to initially setup master nodes splitting the available hash slots among them.\n2. In order to fix a broken cluster where certain slots are unassigned.\n\n## Information about slots propagation and warnings\n\nNote that once a node assigns a set of slots to itself, it will start\npropagating this information in heartbeat packet headers. However the\nother nodes will accept the information only if they have the slot as\nnot already bound with another node, or if the configuration epoch of the\nnode advertising the new hash slot, is greater than the node currently listed\nin the table.\n\nThis means that this command should be used with care only by applications\norchestrating Redis Cluster, like `redis-cli`, and the command if used\nout of the right context can leave the cluster in a wrong state or cause\ndata loss.\n\n",
                        "": "",
                        "return_types": [
                            {
                                "description": "`OK` if the command was successful. Otherwise an error is returned.",
                                "type": "simple-string"
                            }
                        ],
                        "summary": "Assign new hash slots to receiving node",
                        "complexity": "O(N) where N is the total number of hash slot arguments",
                        "arguments": [
                            {
                                "multiple": true,
                                "multiple_token": true,
                                "name": "slot",
                                "type": "integer",
                                "value": "slot"
                            }
                        ],
                        "since": "3.0.0",
                        "group": "cluster",
                        "arity": -3,
                        "command_flags": [
                            "admin",
                            "random",
                            "stale"
                        ],
                        "acl_categories": [
                            "admin",
                            "slow",
                            "dangerous"
                        ],
                        "function": "clusterCommand",
                        "container": "CLUSTER"
                    }
                },
                {
                    "FAILOVER": {
                        "body": "This command, that can only be sent to a Redis Cluster replica node, forces\nthe replica to start a manual failover of its master instance.\n\nA manual failover is a special kind of failover that is usually executed when\nthere are no actual failures, but we wish to swap the current master with one\nof its replicas (which is the node we send the command to), in a safe way,\nwithout any window for data loss. It works in the following way:\n\n1. The replica tells the master to stop processing queries from clients.\n2. The master replies to the replica with the current *replication offset*.\n3. The replica waits for the replication offset to match on its side, to make sure it processed all the data from the master before it continues.\n4. The replica starts a failover, obtains a new configuration epoch from the majority of the masters, and broadcasts the new configuration.\n5. The old master receives the configuration update: unblocks its clients and starts replying with redirection messages so that they'll continue the chat with the new master.\n\nThis way clients are moved away from the old master to the new master\natomically and only when the replica that is turning into the new master\nhas processed all of the replication stream from the old master.\n\n## FORCE option: manual failover when the master is down\n\nThe command behavior can be modified by two options: **FORCE** and **TAKEOVER**.\n\nIf the **FORCE** option is given, the replica does not perform any handshake\nwith the master, that may be not reachable, but instead just starts a\nfailover ASAP starting from point 4. This is useful when we want to start\na manual failover while the master is no longer reachable.\n\nHowever using **FORCE** we still need the majority of masters to be available\nin order to authorize the failover and generate a new configuration epoch\nfor the replica that is going to become master.\n\n## TAKEOVER option: manual failover without cluster consensus\n\nThere are situations where this is not enough, and we want a replica to failover\nwithout any agreement with the rest of the cluster. A real world use case\nfor this is to mass promote replicas in a different data center to masters\nin order to perform a data center switch, while all the masters are down\nor partitioned away.\n\nThe **TAKEOVER** option implies everything **FORCE** implies, but also does\nnot uses any cluster authorization in order to failover. A replica receiving\n`CLUSTER FAILOVER TAKEOVER` will instead:\n\n1. Generate a new `configEpoch` unilaterally, just taking the current greatest epoch available and incrementing it if its local configuration epoch is not already the greatest.\n2. Assign itself all the hash slots of its master, and propagate the new configuration to every node which is reachable ASAP, and eventually to every other node.\n\nNote that **TAKEOVER violates the last-failover-wins principle** of Redis Cluster, since the configuration epoch generated by the replica violates the normal generation of configuration epochs in several ways:\n\n1. There is no guarantee that it is actually the higher configuration epoch, since, for example, we can use the **TAKEOVER** option within a minority, nor any message exchange is performed to generate the new configuration epoch.\n2. If we generate a configuration epoch which happens to collide with another instance, eventually our configuration epoch, or the one of another instance with our same epoch, will be moved away using the *configuration epoch collision resolution algorithm*.\n\nBecause of this the **TAKEOVER** option should be used with care.\n\n## Implementation details and notes\n\n* `CLUSTER FAILOVER`, unless the **TAKEOVER** option is specified, does not execute a failover synchronously.\n  It only *schedules* a manual failover, bypassing the failure detection stage.\n* An `OK` reply is no guarantee that the failover will succeed.\n* A replica can only be promoted to a master if it is known as a replica by a majority of the masters in the cluster.\n  If the replica is a new node that has just been added to the cluster (for example after upgrading it), it may not yet be known to all the masters in the cluster.\n  To check that the masters are aware of a new replica, you can send `CLUSTER NODES` or `CLUSTER REPLICAS` to each of the master nodes and check that it appears as a replica, before sending `CLUSTER FAILOVER` to the replica.\n* To check that the failover has actually happened you can use [`ROLE`](./role), `INFO REPLICATION` (which indicates \"role:master\" after successful failover), or `CLUSTER NODES` to verify that the state of the cluster has changed sometime after the command was sent.\n* To check if the failover has failed, check the replica's log for \"Manual failover timed out\", which is logged if the replica has given up after a few seconds.\n\n",
                        "": "",
                        "return_types": [
                            {
                                "description": "`OK` if the command was accepted and a manual failover is going to be attempted. An error if the operation cannot be executed, for example if we are talking with a node which is already a master.",
                                "type": "simple-string"
                            }
                        ],
                        "summary": "Forces a replica to perform a manual failover of its master.",
                        "complexity": "O(1)",
                        "arguments": [
                            {
                                "optional": true,
                                "name": "force_takeover",
                                "type": "oneof",
                                "value": [
                                    {
                                        "name": "__TBD__34__",
                                        "token": "FORCE"
                                    },
                                    {
                                        "name": "__TBD__35__",
                                        "token": "TAKEOVER"
                                    }
                                ]
                            }
                        ],
                        "since": "3.0.0",
                        "group": "cluster",
                        "arity": -2,
                        "command_flags": [
                            "admin",
                            "random",
                            "stale"
                        ],
                        "acl_categories": [
                            "admin",
                            "slow",
                            "dangerous"
                        ],
                        "function": "clusterCommand",
                        "container": "CLUSTER"
                    }
                },
                {
                    "SLOTS": {
                        "body": "`CLUSTER SLOTS` returns details about which cluster slots map to which\nRedis instances. The command is suitable to be used by Redis Cluster client\nlibraries implementations in order to retrieve (or update when a redirection\nis received) the map associating cluster *hash slots* with actual nodes\nnetwork coordinates (composed of an IP address, a TCP port, and the node ID), so that when\na command is received, it can be sent to what is likely the right instance\nfor the keys specified in the command.\n\n## Nested Result Array\nEach nested result is:\n\n  - Start slot range\n  - End slot range\n  - Master for slot range represented as nested IP/Port/ID array\n  - First replica of master for slot range\n  - Second replica\n  - ...continues until all replicas for this master are returned.\n\nEach result includes all active replicas of the master instance\nfor the listed slot range.  Failed replicas are not returned.\n\nThe third nested reply is guaranteed to be the IP/Port/ID array of\nthe master instance for the slot range.\nAll IP/Port/ID arrays after the third nested reply are replicas\nof the master.\n\nIf a cluster instance has non-contiguous slots (e.g. 1-400,900,1800-6000) then\nmaster and replica IP/Port/ID results will be duplicated for each top-level\nslot range reply.\n\n@examples\n\n```\n> CLUSTER SLOTS\n1) 1) (integer) 0\n   2) (integer) 5460\n   3) 1) \"127.0.0.1\"\n      2) (integer) 30001\n      3) \"09dbe9720cda62f7865eabc5fd8857c5d2678366\"\n   4) 1) \"127.0.0.1\"\n      2) (integer) 30004\n      3) \"821d8ca00d7ccf931ed3ffc7e3db0599d2271abf\"\n2) 1) (integer) 5461\n   2) (integer) 10922\n   3) 1) \"127.0.0.1\"\n      2) (integer) 30002\n      3) \"c9d93d9f2c0c524ff34cc11838c2003d8c29e013\"\n   4) 1) \"127.0.0.1\"\n      2) (integer) 30005\n      3) \"faadb3eb99009de4ab72ad6b6ed87634c7ee410f\"\n3) 1) (integer) 10923\n   2) (integer) 16383\n   3) 1) \"127.0.0.1\"\n      2) (integer) 30003\n      3) \"044ec91f325b7595e76dbcb18cc688b6a5b434a1\"\n   4) 1) \"127.0.0.1\"\n      2) (integer) 30006\n      3) \"58e6e48d41228013e5d9c1c37c5060693925e97e\"\n```\n\n",
                        "history": [
                            [
                                "4.0",
                                "Added node IDs."
                            ]
                        ],
                        "": "",
                        "return_types": [
                            {
                                "description": "nested list of slot ranges with IP/Port/ID mappings.",
                                "type": "array"
                            }
                        ],
                        "summary": "Get array of Cluster slot to node mappings",
                        "complexity": "O(N) where N is the total number of Cluster nodes",
                        "since": "3.0.0",
                        "group": "cluster",
                        "arity": 2,
                        "command_flags": [
                            "random",
                            "stale"
                        ],
                        "acl_categories": [
                            "slow"
                        ],
                        "function": "clusterCommand",
                        "container": "CLUSTER"
                    }
                },
                {
                    "COUNT-FAILURE-REPORTS": {
                        "body": "The command returns the number of *failure reports* for the specified node.\nFailure reports are the way Redis Cluster uses in order to promote a\n`PFAIL` state, that means a node is not reachable, to a `FAIL` state,\nthat means that the majority of masters in the cluster agreed within\na window of time that the node is not reachable.\n\nA few more details:\n\n* A node flags another node with `PFAIL` when the node is not reachable for a time greater than the configured *node timeout*, which is a fundamental configuration parameter of a Redis Cluster.\n* Nodes in `PFAIL` state are provided in gossip sections of heartbeat packets.\n* Every time a node processes gossip packets from other nodes, it creates (and refreshes the TTL if needed) **failure reports**, remembering that a given node said another given node is in `PFAIL` condition.\n* Each failure report has a time to live of two times the *node timeout* time.\n* If at a given time a node has another node flagged with `PFAIL`, and at the same time collected the majority of other master nodes *failure reports* about this node (including itself if it is a master), then it elevates the failure state of the node from `PFAIL` to `FAIL`, and broadcasts a message forcing all the nodes that can be reached to flag the node as `FAIL`.\n\nThis command returns the number of failure reports for the current node which are currently not expired (so received within two times the *node timeout* time). The count does not include what the node we are asking this count believes about the node ID we pass as argument, the count *only* includes the failure reports the node received from other nodes.\n\nThis command is mainly useful for debugging, when the failure detector of\nRedis Cluster is not operating as we believe it should.\n\n",
                        "": "",
                        "return_types": [
                            {
                                "description": "the number of active failure reports for the node.",
                                "type": "integer"
                            }
                        ],
                        "summary": "Return the number of failure reports active for a given node",
                        "complexity": "O(N) where N is the number of failure reports",
                        "arguments": [
                            {
                                "name": "node-id",
                                "type": "string",
                                "value": "node-id"
                            }
                        ],
                        "since": "3.0.0",
                        "group": "cluster",
                        "arity": 3,
                        "command_flags": [
                            "admin",
                            "random",
                            "stale"
                        ],
                        "acl_categories": [
                            "admin",
                            "slow",
                            "dangerous"
                        ],
                        "function": "clusterCommand",
                        "container": "CLUSTER"
                    }
                },
                {
                    "SET-CONFIG-EPOCH": {
                        "body": "This command sets a specific *config epoch* in a fresh node. It only works when:\n\n1. The nodes table of the node is empty.\n2. The node current *config epoch* is zero.\n\nThese prerequisites are needed since usually, manually altering the\nconfiguration epoch of a node is unsafe, we want to be sure that the node with\nthe higher configuration epoch value (that is the last that failed over) wins\nover other nodes in claiming the hash slots ownership.\n\nHowever there is an exception to this rule, and it is when a new\ncluster is created from scratch. Redis Cluster *config epoch collision\nresolution* algorithm can deal with new nodes all configured with the\nsame configuration at startup, but this process is slow and should be\nthe exception, only to make sure that whatever happens, two more\nnodes eventually always move away from the state of having the same\nconfiguration epoch.\n\nSo, using `CONFIG SET-CONFIG-EPOCH`, when a new cluster is created, we can\nassign a different progressive configuration epoch to each node before\njoining the cluster together.\n\n",
                        "": "",
                        "return_types": [
                            {
                                "description": "`OK` if the command was executed successfully, otherwise an error is returned.",
                                "type": "simple-string"
                            }
                        ],
                        "summary": "Set the configuration epoch in a new node",
                        "complexity": "O(1)",
                        "arguments": [
                            {
                                "name": "config-epoch",
                                "type": "integer",
                                "value": "config-epoch"
                            }
                        ],
                        "since": "3.0.0",
                        "group": "cluster",
                        "arity": 3,
                        "command_flags": [
                            "admin",
                            "random",
                            "stale"
                        ],
                        "acl_categories": [
                            "admin",
                            "slow",
                            "dangerous"
                        ],
                        "function": "clusterCommand",
                        "container": "CLUSTER"
                    }
                },
                {
                    "RESET": {
                        "body": "Reset a Redis Cluster node, in a more or less drastic way depending on the\nreset type, that can be **hard** or **soft**. Note that this command\n**does not work for masters if they hold one or more keys**, in that case\nto completely reset a master node keys must be removed first, e.g. by using [`FLUSHALL`](./flushall) first,\nand then `CLUSTER RESET`.\n\nEffects on the node:\n\n1. All the other nodes in the cluster are forgotten.\n2. All the assigned / open slots are reset, so the slots-to-nodes mapping is totally cleared.\n3. If the node is a replica it is turned into an (empty) master. Its dataset is flushed, so at the end the node will be an empty master.\n4. **Hard reset only**: a new Node ID is generated.\n5. **Hard reset only**: `currentEpoch` and `configEpoch` vars are set to 0.\n6. The new configuration is persisted on disk in the node cluster configuration file.\n\nThis command is mainly useful to re-provision a Redis Cluster node\nin order to be used in the context of a new, different cluster. The command\nis also extensively used by the Redis Cluster testing framework in order to\nreset the state of the cluster every time a new test unit is executed.\n\nIf no reset type is specified, the default is **soft**.\n\n",
                        "": "",
                        "return_types": [
                            {
                                "description": "`OK` if the command was successful. Otherwise an error is returned.",
                                "type": "simple-string"
                            }
                        ],
                        "summary": "Reset a Redis Cluster node",
                        "complexity": "O(N) where N is the number of known nodes. The command may execute a FLUSHALL as a side effect.",
                        "arguments": [
                            {
                                "optional": true,
                                "name": "hard_soft",
                                "type": "oneof",
                                "value": [
                                    {
                                        "name": "__TBD__36__",
                                        "token": "HARD"
                                    },
                                    {
                                        "name": "__TBD__37__",
                                        "token": "SOFT"
                                    }
                                ]
                            }
                        ],
                        "since": "3.0.0",
                        "group": "cluster",
                        "arity": 3,
                        "command_flags": [
                            "admin",
                            "random",
                            "stale"
                        ],
                        "acl_categories": [
                            "admin",
                            "slow",
                            "dangerous"
                        ],
                        "function": "clusterCommand",
                        "container": "CLUSTER"
                    }
                },
                {
                    "REPLICAS": {
                        "body": "The command provides a list of replica nodes replicating from the specified\nmaster node. The list is provided in the same format used by `CLUSTER NODES` (please refer to its documentation for the specification of the format).\n\nThe command will fail if the specified node is not known or if it is not\na master according to the node table of the node receiving the command.\n\nNote that if a replica is added, moved, or removed from a given master node,\nand we ask `CLUSTER REPLICAS` to a node that has not yet received the\nconfiguration update, it may show stale information. However eventually\n(in a matter of seconds if there are no network partitions) all the nodes\nwill agree about the set of nodes associated with a given master.\n\n",
                        "return_summary": "The command returns data in the same format as `CLUSTER NODES`.",
                        "": "",
                        "summary": "List replica nodes of the specified master node",
                        "complexity": "O(1)",
                        "arguments": [
                            {
                                "name": "node-id",
                                "type": "string",
                                "value": "node-id"
                            }
                        ],
                        "since": "5.0.0",
                        "group": "cluster",
                        "arity": 3,
                        "command_flags": [
                            "admin",
                            "random",
                            "stale"
                        ],
                        "acl_categories": [
                            "admin",
                            "slow",
                            "dangerous"
                        ],
                        "function": "clusterCommand",
                        "container": "CLUSTER"
                    }
                },
                {
                    "DELSLOTSRANGE": {
                        "arity": -4,
                        "command_flags": [
                            "admin",
                            "random",
                            "stale"
                        ],
                        "acl_categories": [
                            "admin",
                            "slow",
                            "dangerous"
                        ],
                        "function": "clusterCommand",
                        "container": "CLUSTER",
                        "group": "cluster"
                    }
                },
                {
                    "MEET": {
                        "body": "`CLUSTER MEET` is used in order to connect different Redis nodes with cluster\nsupport enabled, into a working cluster.\n\nThe basic idea is that nodes by default don't trust each other, and are\nconsidered unknown, so that it is unlikely that different cluster nodes will\nmix into a single one because of system administration errors or network\naddresses modifications.\n\nSo in order for a given node to accept another one into the list of nodes\ncomposing a Redis Cluster, there are only two ways:\n\n1. The system administrator sends a `CLUSTER MEET` command to force a node to meet another one.\n2. An already known node sends a list of nodes in the gossip section that we are not aware of. If the receiving node trusts the sending node as a known node, it will process the gossip section and send an handshake to the nodes that are still not known.\n\nNote that Redis Cluster needs to form a full mesh (each node is connected with each other node), but in order to create a cluster, there is no need to send all the `CLUSTER MEET` commands needed to form the full mesh. What matter is to send enough `CLUSTER MEET` messages so that each node can reach each other node through a *chain of known nodes*. Thanks to the exchange of gossip information in heartbeat packets, the missing links will be created.\n\nSo, if we link node A with node B via `CLUSTER MEET`, and B with C, A and C will find their ways to handshake and create a link.\n\nAnother example: if we imagine a cluster formed of the following four nodes called A, B, C and D, we may send just the following set of commands to A:\n\n1. `CLUSTER MEET B-ip B-port`\n2. `CLUSTER MEET C-ip C-port`\n3. `CLUSTER MEET D-ip D-port`\n\nAs a side effect of `A` knowing and being known by all the other nodes, it will send gossip sections in the heartbeat packets that will allow each other node to create a link with each other one, forming a full mesh in a matter of seconds, even if the cluster is large.\n\nMoreover `CLUSTER MEET` does not need to be reciprocal. If I send the command to A in order to join B, I don't need to also send it to B in order to join A.\n\n## Implementation details: MEET and PING packets\n\nWhen a given node receives a `CLUSTER MEET` message, the node specified in the\ncommand still does not know the node we sent the command to. So in order for\nthe node to force the receiver to accept it as a trusted node, it sends a\n`MEET` packet instead of a [`PING`](./ping) packet. The two packets have exactly the\nsame format, but the former forces the receiver to acknowledge the node as\ntrusted.\n\n",
                        "": "",
                        "return_types": [
                            {
                                "description": "`OK` if the command was successful. If the address or port specified are invalid an error is returned.",
                                "type": "simple-string"
                            }
                        ],
                        "summary": "Force a node cluster to handshake with another node",
                        "complexity": "O(1)",
                        "arguments": [
                            {
                                "name": "ip",
                                "type": "string",
                                "value": "ip"
                            },
                            {
                                "name": "port",
                                "type": "integer",
                                "value": "port"
                            }
                        ],
                        "since": "3.0.0",
                        "group": "cluster",
                        "arity": -4,
                        "command_flags": [
                            "admin",
                            "random",
                            "stale"
                        ],
                        "acl_categories": [
                            "admin",
                            "slow",
                            "dangerous"
                        ],
                        "function": "clusterCommand",
                        "container": "CLUSTER"
                    }
                },
                {
                    "REPLICATE": {
                        "body": "The command reconfigures a node as a replica of the specified master.\nIf the node receiving the command is an *empty master*, as a side effect\nof the command, the node role is changed from master to replica.\n\nOnce a node is turned into the replica of another master node, there is no need\nto inform the other cluster nodes about the change: heartbeat packets exchanged\nbetween nodes will propagate the new configuration automatically.\n\nA replica will always accept the command, assuming that:\n\n1. The specified node ID exists in its nodes table.\n2. The specified node ID does not identify the instance we are sending the command to.\n3. The specified node ID is a master.\n\nIf the node receiving the command is not already a replica, but is a master,\nthe command will only succeed, and the node will be converted into a replica,\nonly if the following additional conditions are met:\n\n1. The node is not serving any hash slots.\n2. The node is empty, no keys are stored at all in the key space.\n\nIf the command succeeds the new replica will immediately try to contact its master in order to replicate from it.\n\n",
                        "": "",
                        "return_types": [
                            {
                                "description": "`OK` if the command was executed successfully, otherwise an error is returned.",
                                "type": "simple-string"
                            }
                        ],
                        "summary": "Reconfigure a node as a replica of the specified master node",
                        "complexity": "O(1)",
                        "arguments": [
                            {
                                "name": "node-id",
                                "type": "string",
                                "value": "node-id"
                            }
                        ],
                        "since": "3.0.0",
                        "group": "cluster",
                        "arity": 3,
                        "command_flags": [
                            "admin",
                            "random",
                            "stale"
                        ],
                        "acl_categories": [
                            "admin",
                            "slow",
                            "dangerous"
                        ],
                        "function": "clusterCommand",
                        "container": "CLUSTER"
                    }
                },
                {
                    "HELP": {
                        "arity": 2,
                        "command_flags": [
                            "loading",
                            "stale"
                        ],
                        "acl_categories": [
                            "slow"
                        ],
                        "function": "clusterCommand",
                        "container": "CLUSTER",
                        "group": "cluster"
                    }
                },
                {
                    "MYID": {
                        "body": "Returns the node's id.\n\nThe `CLUSTER MYID` command returns the unique, auto-generated identifier that is associated with the connected cluster node.\n\n",
                        "": "",
                        "return_types": [
                            {
                                "description": "The node id.",
                                "type": "bulk-string"
                            }
                        ],
                        "summary": "Return the node id",
                        "complexity": "O(1)",
                        "since": "3.0.0",
                        "group": "cluster",
                        "arity": 2,
                        "command_flags": [
                            "random",
                            "stale"
                        ],
                        "acl_categories": [
                            "slow"
                        ],
                        "function": "clusterCommand",
                        "container": "CLUSTER"
                    }
                },
                {
                    "SETSLOT": {
                        "body": "`CLUSTER SETSLOT` is responsible of changing the state of a hash slot in the receiving node in different ways. It can, depending on the subcommand used:\n\n1. `MIGRATING` subcommand: Set a hash slot in *migrating* state.\n2. `IMPORTING` subcommand: Set a hash slot in *importing* state.\n3. `STABLE` subcommand: Clear any importing / migrating state from hash slot.\n4. `NODE` subcommand: Bind the hash slot to a different node.\n\nThe command with its set of subcommands is useful in order to start and end cluster live resharding operations, which are accomplished by setting a hash slot in migrating state in the source node, and importing state in the destination node.\n\nEach subcommand is documented below. At the end you'll find a description of\nhow live resharding is performed using this command and other related commands.\n\n## CLUSTER SETSLOT `<slot>` MIGRATING `<destination-node-id>`\n\nThis subcommand sets a slot to *migrating* state. In order to set a slot\nin this state, the node receiving the command must be the hash slot owner,\notherwise an error is returned.\n\nWhen a slot is set in migrating state, the node changes behavior in the\nfollowing way:\n\n1. If a command is received about an existing key, the command is processed as usually.\n2. If a command is received about a key that does not exists, an `ASK` redirection is emitted by the node, asking the client to retry only that specific query into `destination-node`. In this case the client should not update its hash slot to node mapping.\n3. If the command contains multiple keys, in case none exist, the behavior is the same as point 2, if all exist, it is the same as point 1, however if only a partial number of keys exist, the command emits a `TRYAGAIN` error in order for the keys interested to finish being migrated to the target node, so that the multi keys command can be executed.\n\n## CLUSTER SETSLOT `<slot>` IMPORTING `<source-node-id>`\n\nThis subcommand is the reverse of `MIGRATING`, and prepares the destination\nnode to import keys from the specified source node. The command only works if\nthe node is not already owner of the specified hash slot.\n\nWhen a slot is set in importing state, the node changes behavior in the following way:\n\n1. Commands about this hash slot are refused and a `MOVED` redirection is generated as usually, but in the case the command follows an [`ASKING`](./asking) command, in this case the command is executed.\n\nIn this way when a node in migrating state generates an `ASK` redirection, the client contacts the target node, sends [`ASKING`](./asking), and immediately after sends the command. This way commands about non-existing keys in the old node or keys already migrated to the target node are executed in the target node, so that:\n\n1. New keys are always created in the target node. During a hash slot migration we'll have to move only old keys, not new ones.\n2. Commands about keys already migrated are correctly processed in the context of the node which is the target of the migration, the new hash slot owner, in order to guarantee consistency.\n3. Without [`ASKING`](./asking) the behavior is the same as usually. This guarantees that clients with a broken hash slots mapping will not write for error in the target node, creating a new version of a key that has yet to be migrated.\n\n## CLUSTER SETSLOT `<slot>` STABLE\n\nThis subcommand just clears migrating / importing state from the slot. It is\nmainly used to fix a cluster stuck in a wrong state by `redis-cli --cluster fix`.\nNormally the two states are cleared automatically at the end of the migration\nusing the `SETSLOT ... NODE ...` subcommand as explained in the next section.\n\n## CLUSTER SETSLOT `<slot>` NODE `<node-id>`\n\nThe `NODE` subcommand is the one with the most complex semantics. It\nassociates the hash slot with the specified node, however the command works\nonly in specific situations and has different side effects depending on the\nslot state. The following is the set of pre-conditions and side effects of the\ncommand:\n\n1. If the current hash slot owner is the node receiving the command, but for effect of the command the slot would be assigned to a different node, the command will return an error if there are still keys for that hash slot in the node receiving the command.\n2. If the slot is in *migrating* state, the state gets cleared when the slot is assigned to another node.\n3. If the slot was in *importing* state in the node receiving the command, and the command assigns the slot to this node (which happens in the target node at the end of the resharding of a hash slot from one node to another), the command has the following side effects: A) the *importing* state is cleared. B) If the node config epoch is not already the greatest of the cluster, it generates a new one and assigns the new config epoch to itself. This way its new hash slot ownership will win over any past configuration created by previous failovers or slot migrations.\n\nIt is important to note that step 3 is the only time when a Redis Cluster node will create a new config epoch without agreement from other nodes. This only happens when a manual configuration is operated. However it is impossible that this creates a non-transient setup where two nodes have the same config epoch, since Redis Cluster uses a config epoch collision resolution algorithm.\n\n## Redis Cluster live resharding explained\n\nThe `CLUSTER SETSLOT` command is an important piece used by Redis Cluster in order to migrate all the keys contained in one hash slot from one node to another. This is how the migration is orchestrated, with the help of other commands as well. We'll call the node that has the current ownership of the hash slot the `source` node, and the node where we want to migrate the `destination` node.\n\n1. Set the destination node slot to *importing* state using `CLUSTER SETSLOT <slot> IMPORTING <source-node-id>`.\n2. Set the source node slot to *migrating* state using `CLUSTER SETSLOT <slot> MIGRATING <destination-node-id>`.\n3. Get keys from the source node with `CLUSTER GETKEYSINSLOT` command and move them into the destination node using the [`MIGRATE`](./migrate) command.\n4. Use `CLUSTER SETSLOT <slot> NODE <destination-node-id>` in the source or destination.\n\nNotes:\n\n* The order of step 1 and 2 is important. We want the destination node to be ready to accept `ASK` redirections when the source node is configured to redirect.\n* Step 4 does not technically need to use `SETSLOT` in the nodes not involved in the resharding, since the configuration will eventually propagate itself, however it is a good idea to do so in order to stop nodes from pointing to the wrong node for the hash slot moved as soon as possible, resulting in less redirections to find the right node.\n\n",
                        "": "",
                        "return_types": [
                            {
                                "description": "All the subcommands return `OK` if the command was successful. Otherwise an error is returned.",
                                "type": "simple-string"
                            }
                        ],
                        "summary": "Bind a hash slot to a specific node",
                        "complexity": "O(1)",
                        "arguments": [
                            {
                                "name": "slot",
                                "type": "integer",
                                "value": "slot"
                            },
                            {
                                "name": "importing_migrating_stable_node",
                                "type": "oneof",
                                "value": [
                                    {
                                        "name": "__TBD__38__",
                                        "token": "IMPORTING"
                                    },
                                    {
                                        "name": "__TBD__39__",
                                        "token": "MIGRATING"
                                    },
                                    {
                                        "name": "__TBD__40__",
                                        "token": "STABLE"
                                    },
                                    {
                                        "name": "__TBD__41__",
                                        "token": "NODE"
                                    }
                                ]
                            },
                            {
                                "optional": true,
                                "name": "node-id",
                                "type": "string",
                                "value": "node-id"
                            }
                        ],
                        "since": "3.0.0",
                        "group": "cluster",
                        "arity": -4,
                        "command_flags": [
                            "admin",
                            "random",
                            "stale"
                        ],
                        "acl_categories": [
                            "admin",
                            "slow",
                            "dangerous"
                        ],
                        "function": "clusterCommand",
                        "container": "CLUSTER"
                    }
                },
                {
                    "COUNTKEYSINSLOT": {
                        "body": "Returns the number of keys in the specified Redis Cluster hash slot. The\ncommand only queries the local data set, so contacting a node\nthat is not serving the specified hash slot will always result in a count of\nzero being returned.\n\n```\n> CLUSTER COUNTKEYSINSLOT 7000\n(integer) 50341\n```\n\n",
                        "": "",
                        "return_types": [
                            {
                                "description": "The number of keys in the specified hash slot, or an error if the hash slot is invalid.",
                                "type": "integer"
                            }
                        ],
                        "summary": "Return the number of local keys in the specified hash slot",
                        "complexity": "O(1)",
                        "arguments": [
                            {
                                "name": "slot",
                                "type": "integer",
                                "value": "slot"
                            }
                        ],
                        "since": "3.0.0",
                        "group": "cluster",
                        "arity": 3,
                        "command_flags": [
                            "random",
                            "stale"
                        ],
                        "acl_categories": [
                            "slow"
                        ],
                        "function": "clusterCommand",
                        "container": "CLUSTER"
                    }
                },
                {
                    "DELSLOTS": {
                        "body": "In Redis Cluster, each node keeps track of which master is serving\na particular hash slot.\n\nThe `DELSLOTS` command asks a particular Redis Cluster node to\nforget which master is serving the hash slots specified as arguments.\n\nIn the context of a node that has received a `DELSLOTS` command and\nhas consequently removed the associations for the passed hash slots,\nwe say those hash slots are *unbound*. Note that the existence of\nunbound hash slots occurs naturally when a node has not been\nconfigured to handle them (something that can be done with the\n`ADDSLOTS` command) and if it has not received any information about\nwho owns those hash slots (something that it can learn from heartbeat\nor update messages).\n\nIf a node with unbound hash slots receives a heartbeat packet from\nanother node that claims to be the owner of some of those hash\nslots, the association is established instantly. Moreover, if a\nheartbeat or update message is received with a configuration epoch\ngreater than the node's own, the association is re-established.\n\nHowever, note that:\n\n1. The command only works if all the specified slots are already\nassociated with some node.\n2. The command fails if the same slot is specified multiple times.\n3. As a side effect of the command execution, the node may go into\n*down* state because not all hash slots are covered.\n\n## Example\n\nThe following command removes the association for slots 5000 and\n5001 from the node receiving the command:\n\n    > CLUSTER DELSLOTS 5000 5001\n    OK\n\n## Usage in Redis Cluster\n\nThis command only works in cluster mode and may be useful for\ndebugging and in order to manually orchestrate a cluster configuration\nwhen a new cluster is created. It is currently not used by `redis-cli`,\nand mainly exists for API completeness.\n\n",
                        "": "",
                        "return_types": [
                            {
                                "description": "`OK` if the command was successful. Otherwise",
                                "type": "simple-string"
                            }
                        ],
                        "summary": "Set hash slots as unbound in receiving node",
                        "complexity": "O(N) where N is the total number of hash slot arguments",
                        "arguments": [
                            {
                                "multiple": true,
                                "multiple_token": true,
                                "name": "slot",
                                "type": "integer",
                                "value": "slot"
                            }
                        ],
                        "since": "3.0.0",
                        "group": "cluster",
                        "arity": -3,
                        "command_flags": [
                            "admin",
                            "random",
                            "stale"
                        ],
                        "acl_categories": [
                            "admin",
                            "slow",
                            "dangerous"
                        ],
                        "function": "clusterCommand",
                        "container": "CLUSTER"
                    }
                },
                {
                    "SAVECONFIG": {
                        "body": "Forces a node to save the `nodes.conf` configuration on disk. Before to return\nthe command calls `fsync(2)` in order to make sure the configuration is\nflushed on the computer disk.\n\nThis command is mainly used in the event a `nodes.conf` node state file\ngets lost / deleted for some reason, and we want to generate it again from\nscratch. It can also be useful in case of mundane alterations of a node cluster\nconfiguration via the [`CLUSTER`](./cluster) command in order to ensure the new configuration\nis persisted on disk, however all the commands should normally be able to\nauto schedule to persist the configuration on disk when it is important\nto do so for the correctness of the system in the event of a restart.\n\n",
                        "": "",
                        "return_types": [
                            {
                                "description": "`OK` or an error if the operation fails.",
                                "type": "simple-string"
                            }
                        ],
                        "summary": "Forces the node to save cluster state on disk",
                        "complexity": "O(1)",
                        "since": "3.0.0",
                        "group": "cluster",
                        "arity": 2,
                        "command_flags": [
                            "admin",
                            "random",
                            "stale"
                        ],
                        "acl_categories": [
                            "admin",
                            "slow",
                            "dangerous"
                        ],
                        "function": "clusterCommand",
                        "container": "CLUSTER"
                    }
                }
            ],
            "group": "cluster",
            "since": "3.0.0"
        }
    },
    {
        "SET": {
            "body": "Set `key` to hold the string `value`.\nIf `key` already holds a value, it is overwritten, regardless of its type.\nAny previous time to live associated with the key is discarded on successful `SET` operation.\n\n## Options\n\nThe `SET` command supports a set of options that modify its behavior:\n\n* `EX` *seconds* -- Set the specified expire time, in seconds.\n* `PX` *milliseconds* -- Set the specified expire time, in milliseconds.\n* `EXAT` *timestamp-seconds* -- Set the specified Unix time at which the key will expire, in seconds.\n* `PXAT` *timestamp-milliseconds* -- Set the specified Unix time at which the key will expire, in milliseconds.\n* `NX` -- Only set the key if it does not already exist.\n* `XX` -- Only set the key if it already exist.\n* `KEEPTTL` -- Retain the time to live associated with the key.\n* `GET` -- Return the old string stored at key, or nil if key did not exist. An error is returned and `SET` aborted if the value stored at key is not a string.\n\nNote: Since the `SET` command options can replace [`SETNX`](./setnx), [`SETEX`](./setex), [`PSETEX`](./psetex), [`GETSET`](./getset), it is possible that in future versions of Redis these commands will be deprecated and finally removed.\n\n@examples\n\n```cli\nSET mykey \"Hello\"\nGET mykey\n\nSET anotherkey \"will expire in a minute\" EX 60\n```\n\n## Patterns\n\n**Note:** The following pattern is discouraged in favor of [the Redlock algorithm](https://redis.io/topics/distlock) which is only a bit more complex to implement, but offers better guarantees and is fault tolerant.\n\nThe command `SET resource-name anystring NX EX max-lock-time` is a simple way to implement a locking system with Redis.\n\nA client can acquire the lock if the above command returns `OK` (or retry after some time if the command returns Nil), and remove the lock just using [`DEL`](./del).\n\nThe lock will be auto-released after the expire time is reached.\n\nIt is possible to make this system more robust modifying the unlock schema as follows:\n\n* Instead of setting a fixed string, set a non-guessable large random string, called token.\n* Instead of releasing the lock with [`DEL`](./del), send a script that only removes the key if the value matches.\n\nThis avoids that a client will try to release the lock after the expire time deleting the key created by another client that acquired the lock later.\n\nAn example of unlock script would be similar to the following:\n\n    if redis.call(\"get\",KEYS[1]) == ARGV[1]\n    then\n        return redis.call(\"del\",KEYS[1])\n    else\n        return 0\n    end\n\nThe script should be called with `EVAL ...script... 1 resource-name token-value`\n\n",
            "history": [
                [
                    "2.6.12",
                    "Added the `EX`, `PX`, `NX` and `XX` options."
                ],
                [
                    "6.0",
                    "Added the `KEEPTTL` option."
                ],
                [
                    "6.2",
                    "Added the `GET`, `EXAT` and `PXAT` option."
                ],
                [
                    "7.0",
                    "Allowed the `NX` and `GET` options to be used together."
                ]
            ],
            "return_summary": "@simple-string-reply: `OK` if `SET` was executed correctly.\n\n@nil-reply: `(nil)` if the `SET` operation was not performed because the user specified the `NX` or `XX` option but the condition was not met.\n\nIf the command is issued with the `GET` option, the above does not apply. It will instead reply as follows, regardless if the `SET` was actually performed:\n\n@bulk-string-reply: the old string value stored at key.\n\n@nil-reply: `(nil)` if the key did not exist.",
            "deprecated": true,
            "": "",
            "summary": "Set the string value of a key",
            "complexity": "O(1)",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "name": "value",
                    "type": "string",
                    "value": "value"
                },
                {
                    "optional": true,
                    "name": "ex seconds_px milliseconds_exat timestamp_pxat milliseconds-timestamp_keepttl",
                    "type": "oneof",
                    "value": [
                        {
                            "name": "__TBD__42__",
                            "token": "EX seconds"
                        },
                        {
                            "name": "__TBD__43__",
                            "token": "PX milliseconds"
                        },
                        {
                            "name": "__TBD__44__",
                            "token": "EXAT timestamp"
                        },
                        {
                            "name": "__TBD__45__",
                            "token": "PXAT milliseconds-timestamp"
                        },
                        {
                            "name": "__TBD__46__",
                            "token": "KEEPTTL"
                        }
                    ]
                },
                {
                    "optional": true,
                    "name": "nx_xx",
                    "type": "oneof",
                    "value": [
                        {
                            "name": "__TBD__47__",
                            "token": "NX"
                        },
                        {
                            "name": "__TBD__48__",
                            "token": "XX"
                        }
                    ]
                },
                {
                    "optional": true,
                    "name": "get",
                    "token": "GET"
                }
            ],
            "since": "1.0.0",
            "group": "string",
            "arity": -3,
            "command_flags": [
                "write",
                "denyoom"
            ],
            "acl_categories": [
                "write",
                "string",
                "slow"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write",
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "setCommand"
        }
    },
    {
        "PSYNC": {
            "body": "Initiates a replication stream from the master.\n\nThe `PSYNC` command is called by Redis replicas for initiating a replication\nstream from the master.\n\nFor more information about replication in Redis please check the\n[replication page][tr].\n\n[tr]: /topics/replication\n\n",
            "return_summary": "**Non standard return value**, a bulk transfer of the data followed by [`PING`](./ping) and write requests from the master.",
            "": "",
            "summary": "Internal command used for replication",
            "arguments": [
                {
                    "name": "replicationid",
                    "type": "integer",
                    "value": "replicationid"
                },
                {
                    "name": "offset",
                    "type": "integer",
                    "value": "offset"
                }
            ],
            "since": "2.8.0",
            "group": "server",
            "arity": -3,
            "command_flags": [
                "admin",
                "noscript"
            ],
            "acl_categories": [
                "admin",
                "slow",
                "dangerous"
            ],
            "function": "syncCommand"
        }
    },
    {
        "ZRANGESTORE": {
            "body": "This command is like [`ZRANGE`](./zrange), but stores the result in the `<dst>` destination key.\n\n@examples\n\n```cli\nZADD srczset 1 \"one\" 2 \"two\" 3 \"three\" 4 \"four\"\nZRANGESTORE dstzset srczset 2 -1\nZRANGE dstzset 0 -1\n```\n\n",
            "": "",
            "return_types": [
                {
                    "description": "the number of elements in the resulting sorted set.",
                    "type": "integer"
                }
            ],
            "summary": "Store a range of members from sorted set into another key",
            "complexity": "O(log(N)+M) with N being the number of elements in the sorted set and M the number of elements stored into the destination key.",
            "arguments": [
                {
                    "name": "dst",
                    "type": "key",
                    "value": "dst"
                },
                {
                    "name": "src",
                    "type": "key",
                    "value": "src"
                },
                {
                    "name": "min",
                    "type": "string",
                    "value": "min"
                },
                {
                    "name": "max",
                    "type": "string",
                    "value": "max"
                },
                {
                    "optional": true,
                    "name": "byscore_bylex",
                    "type": "oneof",
                    "value": [
                        {
                            "name": "__TBD__49__",
                            "token": "BYSCORE"
                        },
                        {
                            "name": "__TBD__50__",
                            "token": "BYLEX"
                        }
                    ]
                },
                {
                    "optional": true,
                    "name": "rev",
                    "token": "REV"
                },
                {
                    "token": "LIMIT",
                    "optional": true,
                    "name": "offset_count",
                    "type": "block",
                    "value": [
                        {
                            "name": "offset",
                            "type": "integer",
                            "value": "offset"
                        },
                        {
                            "name": "count",
                            "type": "integer",
                            "value": "count"
                        }
                    ]
                }
            ],
            "since": "6.2.0",
            "group": "sorted_set",
            "arity": -5,
            "command_flags": [
                "write",
                "denyoom"
            ],
            "acl_categories": [
                "write",
                "sortedset",
                "slow"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                },
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 2
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "zrangestoreCommand"
        }
    },
    {
        "HMGET": {
            "body": "Returns the values associated with the specified `fields` in the hash stored at\n`key`.\n\nFor every `field` that does not exist in the hash, a `nil` value is returned.\nBecause non-existing keys are treated as empty hashes, running `HMGET` against\na non-existing `key` will return a list of `nil` values.\n\n",
            "": "",
            "return_types": [
                {
                    "description": "list of values associated with the given fields, in the same",
                    "type": "array"
                }
            ],
            "summary": "Get the values of all the given hash fields",
            "complexity": "O(N) where N is the number of fields being requested.",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "multiple": true,
                    "multiple_token": true,
                    "name": "field",
                    "type": "string",
                    "value": "field"
                }
            ],
            "since": "2.0.0",
            "group": "hash",
            "arity": -3,
            "command_flags": [
                "readonly",
                "fast"
            ],
            "acl_categories": [
                "read",
                "hash",
                "fast"
            ],
            "key_specs": [
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "hmgetCommand"
        }
    },
    {
        "RPUSH": {
            "body": "Insert all the specified values at the tail of the list stored at `key`.\nIf `key` does not exist, it is created as empty list before performing the push\noperation.\nWhen `key` holds a value that is not a list, an error is returned.\n\nIt is possible to push multiple elements using a single command call just\nspecifying multiple arguments at the end of the command.\nElements are inserted one after the other to the tail of the list, from the\nleftmost element to the rightmost element.\nSo for instance the command `RPUSH mylist a b c` will result into a list\ncontaining `a` as first element, `b` as second element and `c` as third element.\n\n@examples\n\n```cli\nRPUSH mylist \"hello\"\nRPUSH mylist \"world\"\nLRANGE mylist 0 -1\n```\n\n",
            "history": [
                [
                    "2.4",
                    "Accepts multiple `element` arguments."
                ]
            ],
            "": "",
            "return_types": [
                {
                    "description": "the length of the list after the push operation.",
                    "type": "integer"
                }
            ],
            "summary": "Append one or multiple elements to a list",
            "complexity": "O(1) for each element added, so O(N) to add N elements when the command is called with multiple arguments.",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "multiple": true,
                    "multiple_token": true,
                    "name": "element",
                    "type": "string",
                    "value": "element"
                }
            ],
            "since": "1.0.0",
            "group": "list",
            "arity": -3,
            "command_flags": [
                "write",
                "denyoom",
                "fast"
            ],
            "acl_categories": [
                "write",
                "list",
                "fast"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "rpushCommand"
        }
    },
    {
        "SCRIPT": {
            "arity": -2,
            "command_flags": [],
            "acl_categories": [
                "slow"
            ],
            "subcommands": [
                {
                    "EXISTS": {
                        "body": "Returns information about the existence of the scripts in the script cache.\n\nThis command accepts one or more SHA1 digests and returns a list of ones or\nzeros to signal if the scripts are already defined or not inside the script\ncache.\nThis can be useful before a pipelining operation to ensure that scripts are\nloaded (and if not, to load them using `SCRIPT LOAD`) so that the pipelining\noperation can be performed solely using [`EVALSHA`](./evalsha) instead of [`EVAL`](./eval) to save\nbandwidth.\n\nPlease refer to the [`EVAL`](./eval) documentation for detailed information about Redis\nLua scripting.\n\n",
                        "return_summary": "@array-reply The command returns an array of integers that correspond to\nthe specified SHA1 digest arguments.\nFor every corresponding SHA1 digest of a script that actually exists in the\nscript cache, an 1 is returned, otherwise 0 is returned.",
                        "": "",
                        "summary": "Check existence of scripts in the script cache.",
                        "complexity": "O(N) with N being the number of scripts to check (so checking a single script is an O(1) operation).",
                        "arguments": [
                            {
                                "multiple": true,
                                "multiple_token": true,
                                "name": "sha1",
                                "type": "string",
                                "value": "sha1"
                            }
                        ],
                        "since": "2.6.0",
                        "group": "scripting",
                        "arity": -3,
                        "command_flags": [
                            "noscript"
                        ],
                        "acl_categories": [
                            "slow",
                            "scripting"
                        ],
                        "function": "scriptCommand",
                        "container": "SCRIPT"
                    }
                },
                {
                    "DEBUG": {
                        "body": "Set the debug mode for subsequent scripts executed with [`EVAL`](./eval). Redis includes a\ncomplete Lua debugger, codename LDB, that can be used to make the task of\nwriting complex scripts much simpler. In debug mode Redis acts as a remote\ndebugging server and a client, such as `redis-cli`, can execute scripts step by\nstep, set breakpoints, inspect variables and more - for additional information\nabout LDB refer to the [Redis Lua debugger](/topics/ldb) page.\n\n**Important note:** avoid debugging Lua scripts using your Redis production\nserver. Use a development server instead.\n\nLDB can be enabled in one of two modes: asynchronous or synchronous. In\nasynchronous mode the server creates a forked debugging session that does not\nblock and all changes to the data are **rolled back** after the session\nfinishes, so debugging can be restarted using the same initial state. The\nalternative synchronous debug mode blocks the server while the debugging session\nis active and retains all changes to the data set once it ends.\n\n* `YES`. Enable non-blocking asynchronous debugging of Lua scripts (changes are discarded).\n* `SYNC`. Enable blocking synchronous debugging of Lua scripts (saves changes to data).\n* `NO`. Disables scripts debug mode.\n\n",
                        "": "",
                        "return_types": [
                            {
                                "description": "`OK`.",
                                "type": "simple-string"
                            }
                        ],
                        "summary": "Set the debug mode for executed scripts.",
                        "complexity": "O(1)",
                        "arguments": [
                            {
                                "name": "yes_sync_no",
                                "type": "oneof",
                                "value": [
                                    {
                                        "name": "__TBD__51__",
                                        "token": "YES"
                                    },
                                    {
                                        "name": "__TBD__52__",
                                        "token": "SYNC"
                                    },
                                    {
                                        "name": "__TBD__53__",
                                        "token": "NO"
                                    }
                                ]
                            }
                        ],
                        "since": "3.2.0",
                        "group": "scripting",
                        "arity": 3,
                        "command_flags": [
                            "noscript"
                        ],
                        "acl_categories": [
                            "slow",
                            "scripting"
                        ],
                        "function": "scriptCommand",
                        "container": "SCRIPT"
                    }
                },
                {
                    "FLUSH": {
                        "body": "Flush the Lua scripts cache.\n\nPlease refer to the [`EVAL`](./eval) documentation for detailed information about Redis Lua scripting.\n\nBy default, `SCRIPT FLUSH` will synchronously flush the cache.\nStarting with Redis 6.2, setting the **lazyfree-lazy-user-flush** configuration directive to \"yes\" changes the default flush mode to asynchronous.\n\nIt is possible to use one of the following modifiers to dictate the flushing mode explicitly:\n\n* `ASYNC`: flushes the cache asynchronously\n* `SYNC`: flushes the cache synchronously\n\n",
                        "history": [
                            [
                                "6.2.0",
                                "Added the `ASYNC` and `SYNC` flushing mode modifiers, as well as the  **lazyfree-lazy-user-flush** configuration directive."
                            ]
                        ],
                        "": "",
                        "return_types": [
                            {
                                "type": "simple-string"
                            }
                        ],
                        "summary": "Remove all the scripts from the script cache.",
                        "arguments": [
                            {
                                "optional": true,
                                "name": "async_sync",
                                "type": "oneof",
                                "value": [
                                    {
                                        "name": "__TBD__54__",
                                        "token": "ASYNC"
                                    },
                                    {
                                        "name": "__TBD__55__",
                                        "token": "SYNC"
                                    }
                                ]
                            }
                        ],
                        "complexity": "O(N) with N being the number of scripts in cache",
                        "since": "2.6.0",
                        "group": "scripting",
                        "arity": -2,
                        "command_flags": [
                            "noscript",
                            "may_replicate"
                        ],
                        "acl_categories": [
                            "slow",
                            "scripting"
                        ],
                        "function": "scriptCommand",
                        "container": "SCRIPT"
                    }
                },
                {
                    "KILL": {
                        "body": "Kills the currently executing Lua script, assuming no write operation was yet\nperformed by the script.\n\nThis command is mainly useful to kill a script that is running for too much\ntime(for instance because it entered an infinite loop because of a bug).\nThe script will be killed and the client currently blocked into EVAL will see\nthe command returning with an error.\n\nIf the script already performed write operations it can not be killed in this\nway because it would violate Lua script atomicity contract.\nIn such a case only `SHUTDOWN NOSAVE` is able to kill the script, killing\nthe Redis process in an hard way preventing it to persist with half-written\ninformation.\n\nPlease refer to the [`EVAL`](./eval) documentation for detailed information about Redis\nLua scripting.\n\n",
                        "": "",
                        "return_types": [
                            {
                                "type": "simple-string"
                            }
                        ],
                        "summary": "Kill the script currently in execution.",
                        "complexity": "O(1)",
                        "since": "2.6.0",
                        "group": "scripting",
                        "arity": 2,
                        "command_flags": [
                            "noscript"
                        ],
                        "acl_categories": [
                            "slow",
                            "scripting"
                        ],
                        "function": "scriptCommand",
                        "container": "SCRIPT"
                    }
                },
                {
                    "LOAD": {
                        "body": "Load a script into the scripts cache, without executing it.\nAfter the specified command is loaded into the script cache it will be callable\nusing [`EVALSHA`](./evalsha) with the correct SHA1 digest of the script, exactly like after\nthe first successful invocation of [`EVAL`](./eval).\n\nThe script is guaranteed to stay in the script cache forever (unless `SCRIPT\nFLUSH` is called).\n\nThe command works in the same way even if the script was already present in the\nscript cache.\n\nPlease refer to the [`EVAL`](./eval) documentation for detailed information about Redis\nLua scripting.\n\n",
                        "return_summary": "@bulk-string-reply This command returns the SHA1 digest of the script added into the\nscript cache.",
                        "": "",
                        "summary": "Load the specified Lua script into the script cache.",
                        "complexity": "O(N) with N being the length in bytes of the script body.",
                        "arguments": [
                            {
                                "name": "script",
                                "type": "string",
                                "value": "script"
                            }
                        ],
                        "since": "2.6.0",
                        "group": "scripting",
                        "arity": 3,
                        "command_flags": [
                            "noscript",
                            "may_replicate"
                        ],
                        "acl_categories": [
                            "slow",
                            "scripting"
                        ],
                        "function": "scriptCommand",
                        "container": "SCRIPT"
                    }
                },
                {
                    "HELP": {
                        "arity": 2,
                        "command_flags": [
                            "loading",
                            "stale"
                        ],
                        "acl_categories": [
                            "slow",
                            "scripting"
                        ],
                        "function": "scriptCommand",
                        "container": "SCRIPT",
                        "group": "scripting"
                    }
                }
            ],
            "group": "scripting",
            "since": "2.6.0"
        }
    },
    {
        "MODULE": {
            "arity": -2,
            "command_flags": [],
            "acl_categories": [
                "slow"
            ],
            "subcommands": [
                {
                    "HELP": {
                        "arity": 2,
                        "command_flags": [
                            "loading",
                            "stale"
                        ],
                        "acl_categories": [
                            "slow"
                        ],
                        "function": "moduleCommand",
                        "container": "MODULE",
                        "group": "server"
                    }
                },
                {
                    "UNLOAD": {
                        "body": "Unloads a module.\n\nThis command unloads the module specified by `name`. Note that the module's name\nis reported by the `MODULE LIST` command, and may differ from the dynamic\nlibrary's filename.\n\nKnown limitations:\n\n*   Modules that register custom data types can not be unloaded.\n\n",
                        "": "",
                        "return_types": [
                            {
                                "description": "`OK` if module was unloaded.",
                                "type": "simple-string"
                            }
                        ],
                        "summary": "Unload a module",
                        "complexity": "O(1)",
                        "arguments": [
                            {
                                "name": "name",
                                "type": "string",
                                "value": "name"
                            }
                        ],
                        "since": "4.0.0",
                        "group": "server",
                        "arity": 3,
                        "command_flags": [
                            "admin",
                            "noscript"
                        ],
                        "acl_categories": [
                            "admin",
                            "slow",
                            "dangerous"
                        ],
                        "function": "moduleCommand",
                        "container": "MODULE"
                    }
                },
                {
                    "LOAD": {
                        "body": "Loads a module from a dynamic library at runtime.\n\nThis command loads and initializes the Redis module from the dynamic library\nspecified by the `path` argument. The `path` should be the absolute path of the\nlibrary, including the full filename. Any additional arguments are passed\nunmodified to the module.\n\n**Note**: modules can also be loaded at server startup with `loadmodule`\nconfiguration directive in `redis.conf`.\n\n",
                        "": "",
                        "return_types": [
                            {
                                "description": "`OK` if module was loaded.",
                                "type": "simple-string"
                            }
                        ],
                        "summary": "Load a module",
                        "complexity": "O(1)",
                        "arguments": [
                            {
                                "name": "path",
                                "type": "string",
                                "value": "path"
                            },
                            {
                                "optional": true,
                                "multiple": true,
                                "name": "arg",
                                "type": "string",
                                "value": "arg"
                            }
                        ],
                        "since": "4.0.0",
                        "group": "server",
                        "arity": -3,
                        "command_flags": [
                            "admin",
                            "noscript"
                        ],
                        "acl_categories": [
                            "admin",
                            "slow",
                            "dangerous"
                        ],
                        "function": "moduleCommand",
                        "container": "MODULE"
                    }
                },
                {
                    "LIST": {
                        "body": "Returns information about the modules loaded to the server.\n\n",
                        "": "",
                        "return_types": [
                            {
                                "description": "list of loaded modules. Each element in the list represents a",
                                "type": "array"
                            }
                        ],
                        "summary": "List all modules loaded by the server",
                        "complexity": "O(N) where N is the number of loaded modules.",
                        "since": "4.0.0",
                        "group": "server",
                        "arity": 2,
                        "command_flags": [
                            "admin",
                            "noscript"
                        ],
                        "acl_categories": [
                            "admin",
                            "slow",
                            "dangerous"
                        ],
                        "function": "moduleCommand",
                        "container": "MODULE"
                    }
                }
            ],
            "group": "server",
            "since": "4.0.0"
        }
    },
    {
        "PFADD": {
            "body": "Adds all the element arguments to the HyperLogLog data structure stored at the variable name specified as first argument.\n\nAs a side effect of this command the HyperLogLog internals may be updated to reflect a different estimation of the number of unique items added so far (the cardinality of the set).\n\nIf the approximated cardinality estimated by the HyperLogLog changed after executing the command, `PFADD` returns 1, otherwise 0 is returned. The command automatically creates an empty HyperLogLog structure (that is, a Redis String of a specified length and with a given encoding) if the specified key does not exist.\n\nTo call the command without elements but just the variable name is valid, this will result into no operation performed if the variable already exists, or just the creation of the data structure if the key does not exist (in the latter case 1 is returned).\n\nFor an introduction to HyperLogLog data structure check the [`PFCOUNT`](./pfcount) command page.\n\n@examples\n\n```cli\nPFADD hll a b c d e f g\nPFCOUNT hll\n```\n\n",
            "return_summary": "@integer-reply, specifically:\n\n* 1 if at least 1 HyperLogLog internal register was altered. 0 otherwise.",
            "": "",
            "summary": "Adds the specified elements to the specified HyperLogLog.",
            "complexity": "O(1) to add every element.",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "optional": true,
                    "multiple": true,
                    "multiple_token": true,
                    "name": "element",
                    "type": "string",
                    "value": "element"
                }
            ],
            "since": "2.8.9",
            "group": "hyperloglog",
            "arity": -2,
            "command_flags": [
                "write",
                "denyoom",
                "fast"
            ],
            "acl_categories": [
                "write",
                "hyperloglog",
                "fast"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "pfaddCommand"
        }
    },
    {
        "PERSIST": {
            "body": "Remove the existing timeout on `key`, turning the key from _volatile_ (a key\nwith an expire set) to _persistent_ (a key that will never expire as no timeout\nis associated).\n\n@examples\n\n```cli\nSET mykey \"Hello\"\nEXPIRE mykey 10\nTTL mykey\nPERSIST mykey\nTTL mykey\n```\n\n",
            "return_summary": "@integer-reply, specifically:\n\n* `1` if the timeout was removed.\n* `0` if `key` does not exist or does not have an associated timeout.",
            "": "",
            "summary": "Remove the expiration from a key",
            "complexity": "O(1)",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                }
            ],
            "since": "2.2.0",
            "group": "generic",
            "arity": 2,
            "command_flags": [
                "write",
                "fast"
            ],
            "acl_categories": [
                "keyspace",
                "write",
                "fast"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "persistCommand"
        }
    },
    {
        "SMOVE": {
            "body": "Move `member` from the set at `source` to the set at `destination`.\nThis operation is atomic.\nIn every given moment the element will appear to be a member of `source` **or**\n`destination` for other clients.\n\nIf the source set does not exist or does not contain the specified element, no\noperation is performed and `0` is returned.\nOtherwise, the element is removed from the source set and added to the\ndestination set.\nWhen the specified element already exists in the destination set, it is only\nremoved from the source set.\n\nAn error is returned if `source` or `destination` does not hold a set value.\n\n@examples\n\n```cli\nSADD myset \"one\"\nSADD myset \"two\"\nSADD myotherset \"three\"\nSMOVE myset myotherset \"two\"\nSMEMBERS myset\nSMEMBERS myotherset\n```\n\n",
            "return_summary": "@integer-reply, specifically:\n\n* `1` if the element is moved.\n* `0` if the element is not a member of `source` and no operation was performed.",
            "": "",
            "summary": "Move a member from one set to another",
            "complexity": "O(1)",
            "arguments": [
                {
                    "name": "source",
                    "type": "key",
                    "value": "source"
                },
                {
                    "name": "destination",
                    "type": "key",
                    "value": "destination"
                },
                {
                    "name": "member",
                    "type": "string",
                    "value": "member"
                }
            ],
            "since": "1.0.0",
            "group": "set",
            "arity": 4,
            "command_flags": [
                "write",
                "fast"
            ],
            "acl_categories": [
                "write",
                "set",
                "fast"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write",
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                },
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 2
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "smoveCommand"
        }
    },
    {
        "PEXPIREAT": {
            "body": "`PEXPIREAT` has the same effect and semantic as [`EXPIREAT`](./expireat), but the Unix time at\nwhich the key will expire is specified in milliseconds instead of seconds.\n\n## Options\n\nThe `PEXPIREAT` command supports a set of options since Redis 7.0:\n\n* `NX` -- Set expiry only when the key has no expiry\n* `XX` -- Set expiry only when the key has an existing expiry\n* `GT` -- Set expiry only when the new expiry is greater than current one\n* `LT` -- Set expiry only when the new expiry is less than current one\n\nA non-volatile key is treated as an infinite TTL for the purpose of `GT` and `LT`.\nThe `GT`, `LT` and `NX` options are mutually exclusive.\n\n@examples\n\n```cli\nSET mykey \"Hello\"\nPEXPIREAT mykey 1555555555005\nTTL mykey\nPTTL mykey\n```\n\n",
            "history": [
                [
                    "7.0",
                    "Added options: `NX`, `XX`, `GT` and `LT`."
                ]
            ],
            "return_summary": "@integer-reply, specifically:\n\n* `1` if the timeout was set.\n* `0` if the timeout was not set. e.g. key doesn't exist, or operation skipped due to the provided arguments.",
            "": "",
            "summary": "Set the expiration for a key as a UNIX timestamp specified in milliseconds",
            "complexity": "O(1)",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "name": "milliseconds-timestamp",
                    "type": "posix time",
                    "value": "milliseconds-timestamp"
                },
                {
                    "optional": true,
                    "name": "nx_xx_gt_lt",
                    "type": "oneof",
                    "value": [
                        {
                            "name": "__TBD__56__",
                            "token": "NX"
                        },
                        {
                            "name": "__TBD__57__",
                            "token": "XX"
                        },
                        {
                            "name": "__TBD__58__",
                            "token": "GT"
                        },
                        {
                            "name": "__TBD__59__",
                            "token": "LT"
                        }
                    ]
                }
            ],
            "since": "2.6.0",
            "group": "generic",
            "arity": -3,
            "command_flags": [
                "write",
                "fast"
            ],
            "acl_categories": [
                "keyspace",
                "write",
                "fast"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "pexpireatCommand"
        }
    },
    {
        "RPUSHX": {
            "body": "Inserts specified values at the tail of the list stored at `key`, only if `key`\nalready exists and holds a list.\nIn contrary to [`RPUSH`](./rpush), no operation will be performed when `key` does not yet\nexist.\n\n@examples\n\n```cli\nRPUSH mylist \"Hello\"\nRPUSHX mylist \"World\"\nRPUSHX myotherlist \"World\"\nLRANGE mylist 0 -1\nLRANGE myotherlist 0 -1\n```\n\n",
            "history": [
                [
                    "4.0",
                    "Accepts multiple `element` arguments."
                ]
            ],
            "": "",
            "return_types": [
                {
                    "description": "the length of the list after the push operation.",
                    "type": "integer"
                }
            ],
            "summary": "Append an element to a list, only if the list exists",
            "complexity": "O(1) for each element added, so O(N) to add N elements when the command is called with multiple arguments.",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "multiple": true,
                    "multiple_token": true,
                    "name": "element",
                    "type": "string",
                    "value": "element"
                }
            ],
            "since": "2.2.0",
            "group": "list",
            "arity": -3,
            "command_flags": [
                "write",
                "denyoom",
                "fast"
            ],
            "acl_categories": [
                "write",
                "list",
                "fast"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "rpushxCommand"
        }
    },
    {
        "REPLICAOF": {
            "body": "The `REPLICAOF` command can change the replication settings of a replica on the fly.\n\nIf a Redis server is already acting as replica, the command `REPLICAOF` NO ONE will turn off the replication, turning the Redis server into a MASTER.  In the proper form `REPLICAOF` hostname port will make the server a replica of another server listening at the specified hostname and port.\n\nIf a server is already a replica of some master, `REPLICAOF` hostname port will stop the replication against the old server and start the synchronization against the new one, discarding the old dataset.\n\nThe form `REPLICAOF` NO ONE will stop replication, turning the server into a MASTER, but will not discard the replication. So, if the old master stops working, it is possible to turn the replica into a master and set the application to use this new master in read/write. Later when the other Redis server is fixed, it can be reconfigured to work as a replica.\n\n@examples\n\n```\n> REPLICAOF NO ONE\n\"OK\"\n\n> REPLICAOF 127.0.0.1 6799\n\"OK\"\n```\n\n",
            "": "",
            "return_types": [
                {
                    "type": "simple-string"
                }
            ],
            "summary": "Make the server a replica of another instance, or promote it as master.",
            "arguments": [
                {
                    "name": "host",
                    "type": "string",
                    "value": "host"
                },
                {
                    "name": "port",
                    "type": "string",
                    "value": "port"
                }
            ],
            "since": "5.0.0",
            "group": "server",
            "arity": 3,
            "command_flags": [
                "admin",
                "noscript",
                "stale"
            ],
            "acl_categories": [
                "admin",
                "slow",
                "dangerous"
            ],
            "function": "replicaofCommand"
        }
    },
    {
        "ZRANDMEMBER": {
            "body": "When called with just the `key` argument, return a random element from the sorted set value stored at `key`.\n\nIf the provided `count` argument is positive, return an array of **distinct elements**.\nThe array's length is either `count` or the sorted set's cardinality ([`ZCARD`](./zcard)), whichever is lower.\n\nIf called with a negative `count`, the behavior changes and the command is allowed to return the **same element multiple times**.\nIn this case, the number of returned elements is the absolute value of the specified `count`.\n\nThe optional `WITHSCORES` modifier changes the reply so it includes the respective scores of the randomly selected elements from the sorted set.\n\n@examples\n\n```cli\nZADD dadi 1 uno 2 due 3 tre 4 quattro 5 cinque 6 sei\nZRANDMEMBER dadi\nZRANDMEMBER dadi\nZRANDMEMBER dadi -5 WITHSCORES\n```\n\n## Specification of the behavior when count is passed\n\nWhen the `count` argument is a positive value this command behaves as follows:\n\n* No repeated elements are returned.\n* If `count` is bigger than the cardinality of the sorted set, the command will only return the whole sorted set without additional elements.\n* The order of elements in the reply is not truly random, so it is up to the client to shuffle them if needed.\n\nWhen the `count` is a negative value, the behavior changes as follows:\n\n* Repeating elements are possible.\n* Exactly `count` elements, or an empty array if the sorted set is empty (non-existing key), are always returned.\n* The order of elements in the reply is truly random.\n\n",
            "return_summary": "@bulk-string-reply: without the additional `count` argument, the command returns a Bulk Reply with the randomly selected element, or `nil` when `key` does not exist.\n\n@array-reply: when the additional `count` argument is passed, the command returns an array of elements, or an empty array when `key` does not exist.\nIf the `WITHSCORES` modifier is used, the reply is a list elements and their scores from the sorted set.",
            "": "",
            "summary": "Get one or multiple random elements from a sorted set",
            "complexity": "O(N) where N is the number of elements returned",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "optional": true,
                    "name": "options",
                    "type": "block",
                    "value": [
                        {
                            "name": "count",
                            "type": "integer",
                            "value": "count"
                        },
                        {
                            "optional": true,
                            "name": "withscores",
                            "token": "WITHSCORES"
                        }
                    ]
                }
            ],
            "since": "6.2.0",
            "group": "sorted_set",
            "arity": -2,
            "command_flags": [
                "readonly",
                "random"
            ],
            "acl_categories": [
                "read",
                "sortedset",
                "slow"
            ],
            "key_specs": [
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "zrandmemberCommand"
        }
    },
    {
        "SORT_RO": {
            "body": "Read-only variant of the [`SORT`](./sort) command. It is exactly like the original [`SORT`](./sort) but refuses the `STORE` option and can safely be used in read-only replicas.\n\nSince the original [`SORT`](./sort) has a `STORE` option it is technically flagged as a writing command in the Redis command table. For this reason read-only replicas in a Redis Cluster will redirect it to the master instance even if the connection is in read-only mode (see the [`READONLY`](./readonly) command of Redis Cluster).\n\nSince Redis 7.0.0, the `SORT_RO` variant was introduced in order to allow [`SORT`](./sort) behavior in read-only replicas without breaking compatibility on command flags.\n\nSee original [`SORT`](./sort) for more details.\n\n@examples\n\n```\nSORT_RO mylist BY weight_*->fieldname GET object_*->fieldname\n```\n\n",
            "": "",
            "return_types": [
                {
                    "description": "a list of sorted elements.",
                    "type": "array"
                }
            ],
            "summary": "Sort the elements in a list, set or sorted set. Read-only variant of SORT.",
            "complexity": "O(N+M*log(M)) where N is the number of elements in the list or set to sort, and M the number of returned elements. When the elements are not sorted, complexity is O(N).",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "token": "BY",
                    "optional": true,
                    "name": "pattern",
                    "type": "pattern",
                    "value": "pattern"
                },
                {
                    "token": "LIMIT",
                    "optional": true,
                    "name": "offset_count",
                    "type": "block",
                    "value": [
                        {
                            "name": "offset",
                            "type": "integer",
                            "value": "offset"
                        },
                        {
                            "name": "count",
                            "type": "integer",
                            "value": "count"
                        }
                    ]
                },
                {
                    "token": "GET",
                    "optional": true,
                    "multiple": true,
                    "multiple_token": true,
                    "name": "pattern",
                    "type": "string",
                    "value": "pattern"
                },
                {
                    "optional": true,
                    "name": "asc_desc",
                    "type": "oneof",
                    "value": [
                        {
                            "name": "__TBD__60__",
                            "token": "ASC"
                        },
                        {
                            "name": "__TBD__61__",
                            "token": "DESC"
                        }
                    ]
                },
                {
                    "optional": true,
                    "name": "sorting",
                    "token": "ALPHA"
                }
            ],
            "since": "7.0.0",
            "group": "generic",
            "arity": -2,
            "command_flags": [
                "readonly"
            ],
            "acl_categories": [
                "read",
                "set",
                "sortedset",
                "list",
                "slow",
                "dangerous"
            ],
            "key_specs": [
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "sortroCommand"
        }
    },
    {
        "PUNSUBSCRIBE": {
            "body": "Unsubscribes the client from the given patterns, or from all of them if none is\ngiven.\n\nWhen no patterns are specified, the client is unsubscribed from all the\npreviously subscribed patterns.\nIn this case, a message for every unsubscribed pattern will be sent to the\nclient.\n\n",
            "return_summary": "",
            "summary": "Stop listening for messages posted to channels matching the given patterns",
            "complexity": "O(N+M) where N is the number of patterns the client is already subscribed and M is the number of total patterns subscribed in the system (by any client).",
            "arguments": [
                {
                    "optional": true,
                    "multiple": true,
                    "multiple_token": true,
                    "name": "pattern",
                    "type": "pattern",
                    "value": "pattern"
                }
            ],
            "since": "2.0.0",
            "group": "pubsub",
            "arity": -1,
            "command_flags": [
                "pubsub",
                "noscript",
                "loading",
                "stale"
            ],
            "acl_categories": [
                "pubsub",
                "slow"
            ],
            "function": "punsubscribeCommand"
        }
    },
    {
        "BITFIELD_RO": {
            "body": "Read-only variant of the [`BITFIELD`](./bitfield) command.\nIt is like the original [`BITFIELD`](./bitfield) but only accepts `GET` subcommand and can safely be used in read-only replicas.\n\nSince the original [`BITFIELD`](./bitfield) has `SET` and `INCRBY` options it is technically flagged as a writing command in the Redis command table.\nFor this reason read-only replicas in a Redis Cluster will redirect it to the master instance even if the connection is in read-only mode (see the [`READONLY`](./readonly) command of Redis Cluster).\n\nSince Redis 6.2, the `BITFIELD_RO` variant was introduced in order to allow [`BITFIELD`](./bitfield) behavior in read-only replicas without breaking compatibility on command flags.\n\nSee original [`BITFIELD`](./bitfield) for more details.\n\n@examples\n\n```\nBITFIELD_RO hello GET i8 16\n```\n\n",
            "": "",
            "return_types": [
                {
                    "description": "An array with each entry being the corresponding result of the subcommand given at the same position.",
                    "type": "array"
                }
            ],
            "summary": "Perform arbitrary bitfield integer operations on strings. Read-only variant of BITFIELD",
            "complexity": "O(1) for each subcommand specified",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "token": "GET",
                    "name": "type_offset",
                    "type": "block",
                    "value": [
                        {
                            "name": "type",
                            "type": "type",
                            "value": "type"
                        },
                        {
                            "name": "offset",
                            "type": "integer",
                            "value": "offset"
                        }
                    ]
                }
            ],
            "since": "6.2.0",
            "group": "bitmap",
            "arity": -2,
            "command_flags": [
                "readonly",
                "fast"
            ],
            "acl_categories": [
                "read",
                "bitmap",
                "fast"
            ],
            "key_specs": [
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "bitfieldroCommand"
        }
    },
    {
        "PFDEBUG": {
            "arity": -3,
            "command_flags": [
                "write",
                "denyoom",
                "admin"
            ],
            "acl_categories": [
                "write",
                "hyperloglog",
                "admin",
                "slow",
                "dangerous"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 2
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "pfdebugCommand",
            "group": "hyperloglog",
            "internal": true
        }
    },
    {
        "WAIT": {
            "body": "This command blocks the current client until all the previous write commands\nare successfully transferred and acknowledged by at least the specified number\nof replicas. If the timeout, specified in milliseconds, is reached, the command\nreturns even if the specified number of replicas were not yet reached.\n\nThe command **will always return** the number of replicas that acknowledged\nthe write commands sent before the `WAIT` command, both in the case where\nthe specified number of replicas are reached, or when the timeout is reached.\n\nA few remarks:\n\n1. When `WAIT` returns, all the previous write commands sent in the context of the current connection are guaranteed to be received by the number of replicas returned by `WAIT`.\n2. If the command is sent as part of a [`MULTI`](./multi) transaction, the command does not block but instead just return ASAP the number of replicas that acknowledged the previous write commands.\n3. A timeout of 0 means to block forever.\n4. Since `WAIT` returns the number of replicas reached both in case of failure and success, the client should check that the returned value is equal or greater to the replication level it demanded.\n\nConsistency and WAIT\n---\n\nNote that `WAIT` does not make Redis a strongly consistent store: while synchronous replication is part of a replicated state machine, it is not the only thing needed. However in the context of Sentinel or Redis Cluster failover, `WAIT` improves the real world data safety.\n\nSpecifically if a given write is transferred to one or more replicas, it is more likely (but not guaranteed) that if the master fails, we'll be able to promote, during a failover, a replica that received the write: both Sentinel and Redis Cluster will do a best-effort attempt to promote the best replica among the set of available replicas.\n\nHowever this is just a best-effort attempt so it is possible to still lose a write synchronously replicated to multiple replicas.\n\nImplementation details\n---\n\nSince the introduction of partial resynchronization with replicas (PSYNC feature) Redis replicas asynchronously ping their master with the offset they already processed in the replication stream. This is used in multiple ways:\n\n1. Detect timed out replicas.\n2. Perform a partial resynchronization after a disconnection.\n3. Implement `WAIT`.\n\nIn the specific case of the implementation of `WAIT`, Redis remembers, for each client, the replication offset of the produced replication stream when a given\nwrite command was executed in the context of a given client. When `WAIT` is\ncalled Redis checks if the specified number of replicas already acknowledged\nthis offset or a greater one.\n\n@examples\n\n```\n> SET foo bar\nOK\n> WAIT 1 0\n(integer) 1\n> WAIT 2 1000\n(integer) 1\n```\n\nIn the following example the first call to `WAIT` does not use a timeout and asks for the write to reach 1 replica. It returns with success. In the second attempt instead we put a timeout, and ask for the replication of the write to two replicas. Since there is a single replica available, after one second `WAIT` unblocks and returns 1, the number of replicas reached.\n\n",
            "": "",
            "return_types": [
                {
                    "description": "The command returns the number of replicas reached by all the writes performed in the context of the current connection.",
                    "type": "integer"
                }
            ],
            "summary": "Wait for the synchronous replication of all the write commands sent in the context of the current connection",
            "complexity": "O(1)",
            "arguments": [
                {
                    "name": "numreplicas",
                    "type": "integer",
                    "value": "numreplicas"
                },
                {
                    "name": "timeout",
                    "type": "integer",
                    "value": "timeout"
                }
            ],
            "since": "3.0.0",
            "group": "generic",
            "arity": 3,
            "command_flags": [
                "noscript"
            ],
            "acl_categories": [
                "slow",
                "connection"
            ],
            "function": "waitCommand"
        }
    },
    {
        "SSCAN": {
            "body": "See [`SCAN`](./scan) for `SSCAN` documentation.\n\n",
            "return_summary": "",
            "summary": "Incrementally iterate Set elements",
            "complexity": "O(1) for every call. O(N) for a complete iteration, including enough command calls for the cursor to return back to 0. N is the number of elements inside the collection..",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "name": "cursor",
                    "type": "integer",
                    "value": "cursor"
                },
                {
                    "token": "MATCH",
                    "optional": true,
                    "name": "pattern",
                    "type": "pattern",
                    "value": "pattern"
                },
                {
                    "token": "COUNT",
                    "optional": true,
                    "name": "count",
                    "type": "integer",
                    "value": "count"
                }
            ],
            "since": "2.8.0",
            "group": "set",
            "arity": -3,
            "command_flags": [
                "readonly",
                "random"
            ],
            "acl_categories": [
                "read",
                "set",
                "slow"
            ],
            "key_specs": [
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "sscanCommand"
        }
    },
    {
        "HGET": {
            "body": "Returns the value associated with `field` in the hash stored at `key`.\n\n@examples\n\n```cli\nHSET myhash field1 \"foo\"\nHGET myhash field1\nHGET myhash field2\n```\n\n",
            "": "",
            "return_types": [
                {
                    "description": "the value associated with `field`, or `nil` when `field` is not",
                    "type": "bulk-string"
                }
            ],
            "summary": "Get the value of a hash field",
            "complexity": "O(1)",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "name": "field",
                    "type": "string",
                    "value": "field"
                }
            ],
            "since": "2.0.0",
            "group": "hash",
            "arity": 3,
            "command_flags": [
                "readonly",
                "fast"
            ],
            "acl_categories": [
                "read",
                "hash",
                "fast"
            ],
            "key_specs": [
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "hgetCommand"
        }
    },
    {
        "READWRITE": {
            "body": "Disables read queries for a connection to a Redis Cluster replica node.\n\nRead queries against a Redis Cluster replica node are disabled by default,\nbut you can use the [`READONLY`](./readonly) command to change this behavior on a per-\nconnection basis. The `READWRITE` command resets the readonly mode flag\nof a connection back to readwrite.\n\n",
            "": "",
            "return_types": [
                {
                    "type": "simple-string"
                }
            ],
            "summary": "Disables read queries for a connection to a cluster replica node",
            "complexity": "O(1)",
            "since": "3.0.0",
            "group": "cluster",
            "arity": 1,
            "command_flags": [
                "fast"
            ],
            "acl_categories": [
                "fast",
                "connection"
            ],
            "function": "readwriteCommand"
        }
    },
    {
        "ZLEXCOUNT": {
            "body": "When all the elements in a sorted set are inserted with the same score, in order to force lexicographical ordering, this command returns the number of elements in the sorted set at `key` with a value between `min` and `max`.\n\nThe `min` and `max` arguments have the same meaning as described for\n[`ZRANGEBYLEX`](./zrangebylex).\n\nNote: the command has a complexity of just O(log(N)) because it uses elements ranks (see [`ZRANK`](./zrank)) to get an idea of the range. Because of this there is no need to do a work proportional to the size of the range.\n\n@examples\n\n```cli\nZADD myzset 0 a 0 b 0 c 0 d 0 e\nZADD myzset 0 f 0 g\nZLEXCOUNT myzset - +\nZLEXCOUNT myzset [b [f\n```\n\n",
            "": "",
            "return_types": [
                {
                    "description": "the number of elements in the specified score range.",
                    "type": "integer"
                }
            ],
            "summary": "Count the number of members in a sorted set between a given lexicographical range",
            "complexity": "O(log(N)) with N being the number of elements in the sorted set.",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "name": "min",
                    "type": "string",
                    "value": "min"
                },
                {
                    "name": "max",
                    "type": "string",
                    "value": "max"
                }
            ],
            "since": "2.8.9",
            "group": "sorted_set",
            "arity": 4,
            "command_flags": [
                "readonly",
                "fast"
            ],
            "acl_categories": [
                "read",
                "sortedset",
                "fast"
            ],
            "key_specs": [
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "zlexcountCommand"
        }
    },
    {
        "MSETNX": {
            "body": "Sets the given keys to their respective values.\n`MSETNX` will not perform any operation at all even if just a single key already\nexists.\n\nBecause of this semantic `MSETNX` can be used in order to set different keys\nrepresenting different fields of an unique logic object in a way that ensures\nthat either all the fields or none at all are set.\n\n`MSETNX` is atomic, so all given keys are set at once.\nIt is not possible for clients to see that some of the keys were updated while\nothers are unchanged.\n\n@examples\n\n```cli\nMSETNX key1 \"Hello\" key2 \"there\"\nMSETNX key2 \"new\" key3 \"world\"\nMGET key1 key2 key3\n```\n\n",
            "return_summary": "@integer-reply, specifically:\n\n* `1` if the all the keys were set.\n* `0` if no key was set (at least one key already existed).",
            "": "",
            "summary": "Set multiple keys to multiple values, only if none of the keys exist",
            "complexity": "O(N) where N is the number of keys to set.",
            "arguments": [
                {
                    "multiple": true,
                    "multiple_token": true,
                    "name": "key_value",
                    "type": "block",
                    "value": [
                        {
                            "name": "key",
                            "type": "key",
                            "value": "key"
                        },
                        {
                            "name": "value",
                            "type": "string",
                            "value": "value"
                        }
                    ]
                }
            ],
            "since": "1.0.1",
            "group": "string",
            "arity": -3,
            "command_flags": [
                "write",
                "denyoom"
            ],
            "acl_categories": [
                "write",
                "string",
                "slow"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": -1,
                            "step": 2,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "msetnxCommand"
        }
    },
    {
        "SUBSCRIBE": {
            "body": "Subscribes the client to the specified channels.\n\nOnce the client enters the subscribed state it is not supposed to issue any\nother commands, except for additional `SUBSCRIBE`, [`PSUBSCRIBE`](./psubscribe), [`UNSUBSCRIBE`](./unsubscribe),\n[`PUNSUBSCRIBE`](./punsubscribe), [`PING`](./ping), [`RESET`](./reset) and `QUIT` commands.\n\n",
            "history": [
                [
                    "6.2",
                    "[`RESET`](./reset) can be called to exit subscribed state."
                ]
            ],
            "return_summary": "",
            "summary": "Listen for messages published to the given channels",
            "complexity": "O(N) where N is the number of channels to subscribe to.",
            "arguments": [
                {
                    "multiple": true,
                    "multiple_token": true,
                    "name": "channel",
                    "type": "string",
                    "value": "channel"
                }
            ],
            "since": "2.0.0",
            "group": "pubsub",
            "arity": -2,
            "command_flags": [
                "pubsub",
                "noscript",
                "loading",
                "stale"
            ],
            "acl_categories": [
                "pubsub",
                "slow"
            ],
            "function": "subscribeCommand"
        }
    },
    {
        "GEORADIUS_RO": {
            "arity": -6,
            "command_flags": [
                "readonly"
            ],
            "acl_categories": [
                "read",
                "geo",
                "slow"
            ],
            "key_specs": [
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "georadiusroCommand",
            "group": "geo"
        }
    },
    {
        "HSETNX": {
            "body": "Sets `field` in the hash stored at `key` to `value`, only if `field` does not\nyet exist.\nIf `key` does not exist, a new key holding a hash is created.\nIf `field` already exists, this operation has no effect.\n\n@examples\n\n```cli\nHSETNX myhash field \"Hello\"\nHSETNX myhash field \"World\"\nHGET myhash field\n```\n\n",
            "return_summary": "@integer-reply, specifically:\n\n* `1` if `field` is a new field in the hash and `value` was set.\n* `0` if `field` already exists in the hash and no operation was performed.",
            "": "",
            "summary": "Set the value of a hash field, only if the field does not exist",
            "complexity": "O(1)",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "name": "field",
                    "type": "string",
                    "value": "field"
                },
                {
                    "name": "value",
                    "type": "string",
                    "value": "value"
                }
            ],
            "since": "2.0.0",
            "group": "hash",
            "arity": 4,
            "command_flags": [
                "write",
                "denyoom",
                "fast"
            ],
            "acl_categories": [
                "write",
                "hash",
                "fast"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "hsetnxCommand"
        }
    },
    {
        "ZSCAN": {
            "body": "See [`SCAN`](./scan) for `ZSCAN` documentation.\n\n",
            "return_summary": "",
            "summary": "Incrementally iterate sorted sets elements and associated scores",
            "complexity": "O(1) for every call. O(N) for a complete iteration, including enough command calls for the cursor to return back to 0. N is the number of elements inside the collection..",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "name": "cursor",
                    "type": "integer",
                    "value": "cursor"
                },
                {
                    "token": "MATCH",
                    "optional": true,
                    "name": "pattern",
                    "type": "pattern",
                    "value": "pattern"
                },
                {
                    "token": "COUNT",
                    "optional": true,
                    "name": "count",
                    "type": "integer",
                    "value": "count"
                }
            ],
            "since": "2.8.0",
            "group": "sorted_set",
            "arity": -3,
            "command_flags": [
                "readonly",
                "random"
            ],
            "acl_categories": [
                "read",
                "sortedset",
                "slow"
            ],
            "key_specs": [
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "zscanCommand"
        }
    },
    {
        "KEYS": {
            "body": "Returns all keys matching `pattern`.\n\nWhile the time complexity for this operation is O(N), the constant times are\nfairly low.\nFor example, Redis running on an entry level laptop can scan a 1 million key\ndatabase in 40 milliseconds.\n\n**Warning**: consider `KEYS` as a command that should only be used in production\nenvironments with extreme care.\nIt may ruin performance when it is executed against large databases.\nThis command is intended for debugging and special operations, such as changing\nyour keyspace layout.\nDon't use `KEYS` in your regular application code.\nIf you're looking for a way to find keys in a subset of your keyspace, consider\nusing [`SCAN`](./scan) or [sets][tdts].\n\n[tdts]: /topics/data-types#sets\n\nSupported glob-style patterns:\n\n* `h?llo` matches `hello`, `hallo` and `hxllo`\n* `h*llo` matches `hllo` and `heeeello`\n* `h[ae]llo` matches `hello` and `hallo,` but not `hillo`\n* `h[^e]llo` matches `hallo`, `hbllo`, ... but not `hello`\n* `h[a-b]llo` matches `hallo` and `hbllo`\n\nUse `\\` to escape special characters if you want to match them verbatim.\n\n@examples\n\n```cli\nMSET firstname Jack lastname Stuntman age 35\nKEYS *name*\nKEYS a??\nKEYS *\n```\n\n",
            "": "",
            "return_types": [
                {
                    "description": "list of keys matching `pattern`.",
                    "type": "array"
                }
            ],
            "summary": "Find all keys matching the given pattern",
            "complexity": "O(N) with N being the number of keys in the database, under the assumption that the key names in the database and the given pattern have limited length.",
            "arguments": [
                {
                    "name": "pattern",
                    "type": "pattern",
                    "value": "pattern"
                }
            ],
            "since": "1.0.0",
            "group": "generic",
            "arity": 2,
            "command_flags": [
                "readonly",
                "sort_for_script"
            ],
            "acl_categories": [
                "keyspace",
                "read",
                "slow",
                "dangerous"
            ],
            "function": "keysCommand"
        }
    },
    {
        "LATENCY": {
            "arity": -2,
            "command_flags": [],
            "acl_categories": [
                "slow"
            ],
            "subcommands": [
                {
                    "LATEST": {
                        "body": "The `LATENCY LATEST` command reports the latest latency events logged.\n\nEach reported event has the following fields:\n\n* Event name.\n* Unix timestamp of the latest latency spike for the event.\n* Latest event latency in millisecond.\n* All-time maximum latency for this event.\n\n\"All-time\" means the maximum latency since the Redis instance was\nstarted, or the time that events were reset `LATENCY RESET`.\n\n@example:\n\n```\n127.0.0.1:6379> debug sleep 1\nOK\n(1.00s)\n127.0.0.1:6379> debug sleep .25\nOK\n127.0.0.1:6379> latency latest\n1) 1) \"command\"\n   2) (integer) 1405067976\n   3) (integer) 251\n   4) (integer) 1001\n```\n\nFor more information refer to the [Latency Monitoring Framework page][lm].\n\n[lm]: /topics/latency-monitor\n\n",
                        "": "",
                        "return_types": [
                            {
                                "description": "specifically:",
                                "type": "array"
                            }
                        ],
                        "summary": "Return the latest latency samples for all events.",
                        "since": "2.8.13",
                        "group": "server",
                        "arity": 2,
                        "command_flags": [
                            "admin",
                            "noscript",
                            "loading",
                            "stale"
                        ],
                        "acl_categories": [
                            "admin",
                            "slow",
                            "dangerous"
                        ],
                        "function": "latencyCommand",
                        "container": "LATENCY"
                    }
                },
                {
                    "GRAPH": {
                        "body": "Produces an ASCII-art style graph for the specified event.\n\n`LATENCY GRAPH` lets you intuitively understand the latency trend of an `event` via state-of-the-art visualization. It can be used for quickly grasping the situation before resorting to means such parsing the raw data from `LATENCY HISTORY` or external tooling.\n\nValid values for `event` are:\n* `active-defrag-cycle`\n* `aof-fsync-always`\n* `aof-stat`\n* `aof-rewrite-diff-write`\n* `aof-rename`\n* `aof-write`\n* `aof-write-active-child`\n* `aof-write-alone`\n* `aof-write-pending-fsync`\n* `command`\n* `expire-cycle`\n* `eviction-cycle`\n* `eviction-del`\n* `fast-command`\n* `fork`\n* `rdb-unlink-temp-file`\n\n@example\n\n```\n127.0.0.1:6379> latency reset command\n(integer) 0\n127.0.0.1:6379> debug sleep .1\nOK\n127.0.0.1:6379> debug sleep .2\nOK\n127.0.0.1:6379> debug sleep .3\nOK\n127.0.0.1:6379> debug sleep .5\nOK\n127.0.0.1:6379> debug sleep .4\nOK\n127.0.0.1:6379> latency graph command\ncommand - high 500 ms, low 101 ms (all time high 500 ms)\n--------------------------------------------------------------------------------\n   #_\n  _||\n _|||\n_||||\n\n11186\n542ss\nsss\n```\n\nThe vertical labels under each graph column represent the amount of seconds,\nminutes, hours or days ago the event happened. For example \"15s\" means that the\nfirst graphed event happened 15 seconds ago.\n\nThe graph is normalized in the min-max scale so that the zero (the underscore\nin the lower row) is the minimum, and a # in the higher row is the maximum.\n\nFor more information refer to the [Latency Monitoring Framework page][lm].\n\n[lm]: /topics/latency-monitor\n\n",
                        "": "",
                        "return_types": [
                            {
                                "type": "bulk-string"
                            }
                        ],
                        "summary": "Return a latency graph for the event.",
                        "arguments": [
                            {
                                "name": "event",
                                "type": "string",
                                "value": "event"
                            }
                        ],
                        "since": "2.8.13",
                        "group": "server",
                        "arity": 3,
                        "command_flags": [
                            "admin",
                            "noscript",
                            "loading",
                            "stale"
                        ],
                        "acl_categories": [
                            "admin",
                            "slow",
                            "dangerous"
                        ],
                        "function": "latencyCommand",
                        "container": "LATENCY"
                    }
                },
                {
                    "DOCTOR": {
                        "body": "The `LATENCY DOCTOR` command reports about different latency-related issues and advises about possible remedies.\n\nThis command is the most powerful analysis tool in the latency monitoring\nframework, and is able to provide additional statistical data like the average\nperiod between latency spikes, the median deviation, and a human-readable\nanalysis of the event. For certain events, like `fork`, additional information\nis provided, like the rate at which the system forks processes.\n\nThis is the output you should post in the Redis mailing list if you are\nlooking for help about Latency related issues.\n\n@example\n\n```\n127.0.0.1:6379> latency doctor\n\nDave, I have observed latency spikes in this Redis instance.\nYou don't mind talking about it, do you Dave?\n\n1. command: 5 latency spikes (average 300ms, mean deviation 120ms,\n    period 73.40 sec). Worst all time event 500ms.\n\nI have a few advices for you:\n\n- Your current Slow Log configuration only logs events that are\n    slower than your configured latency monitor threshold. Please\n    use 'CONFIG SET slowlog-log-slower-than 1000'.\n- Check your Slow Log to understand what are the commands you are\n    running which are too slow to execute. Please check\n    http://redis.io/commands/slowlog for more information.\n- Deleting, expiring or evicting (because of maxmemory policy)\n    large objects is a blocking operation. If you have very large\n    objects that are often deleted, expired, or evicted, try to\n    fragment those objects into multiple smaller objects.\n```\n\n**Note:** the doctor has erratic psychological behaviors, so we recommend interacting with it carefully.\n\nFor more information refer to the [Latency Monitoring Framework page][lm].\n\n[lm]: /topics/latency-monitor\n\n",
                        "": "",
                        "return_types": [
                            {
                                "type": "bulk-string"
                            }
                        ],
                        "summary": "Return a human readable latency analysis report.",
                        "since": "2.8.13",
                        "group": "server",
                        "arity": 2,
                        "command_flags": [
                            "admin",
                            "noscript",
                            "loading",
                            "stale"
                        ],
                        "acl_categories": [
                            "admin",
                            "slow",
                            "dangerous"
                        ],
                        "function": "latencyCommand",
                        "container": "LATENCY"
                    }
                },
                {
                    "HELP": {
                        "body": "The `LATENCY HELP` command returns a helpful text describing the different\nsubcommands.\n\nFor more information refer to the [Latency Monitoring Framework page][lm].\n\n[lm]: /topics/latency-monitor\n\n",
                        "": "",
                        "return_types": [
                            {
                                "description": "a list of subcommands and their descriptions",
                                "type": "array"
                            }
                        ],
                        "summary": "Show helpful text about the different subcommands.",
                        "since": "2.8.13",
                        "group": "server",
                        "arity": 2,
                        "command_flags": [
                            "loading",
                            "stale"
                        ],
                        "acl_categories": [
                            "slow"
                        ],
                        "function": "latencyCommand",
                        "container": "LATENCY"
                    }
                },
                {
                    "HISTORY": {
                        "body": "The `LATENCY HISTORY` command returns the raw data of the `event`'s latency spikes time series.\n\nThis is useful to an application that wants to fetch raw data in order to perform monitoring, display graphs, and so forth.\n\nThe command will return up to 160 timestamp-latency pairs for the `event`.\n\nValid values for `event` are:\n* `active-defrag-cycle`\n* `aof-fsync-always`\n* `aof-stat`\n* `aof-rewrite-diff-write`\n* `aof-rename`\n* `aof-write`\n* `aof-write-active-child`\n* `aof-write-alone`\n* `aof-write-pending-fsync`\n* `command`\n* `expire-cycle`\n* `eviction-cycle`\n* `eviction-del`\n* `fast-command`\n* `fork`\n* `rdb-unlink-temp-file`\n\n@example\n\n```\n127.0.0.1:6379> latency history command\n1) 1) (integer) 1405067822\n   2) (integer) 251\n2) 1) (integer) 1405067941\n   2) (integer) 1001\n```\n\nFor more information refer to the [Latency Monitoring Framework page][lm].\n\n[lm]: /topics/latency-monitor\n\n",
                        "": "",
                        "return_types": [
                            {
                                "description": "specifically:",
                                "type": "array"
                            }
                        ],
                        "summary": "Return timestamp-latency samples for the event.",
                        "arguments": [
                            {
                                "name": "event",
                                "type": "string",
                                "value": "event"
                            }
                        ],
                        "since": "2.8.13",
                        "group": "server",
                        "arity": 3,
                        "command_flags": [
                            "admin",
                            "noscript",
                            "loading",
                            "stale"
                        ],
                        "acl_categories": [
                            "admin",
                            "slow",
                            "dangerous"
                        ],
                        "function": "latencyCommand",
                        "container": "LATENCY"
                    }
                },
                {
                    "RESET": {
                        "body": "The `LATENCY RESET` command resets the latency spikes time series of all, or only some, events.\n\nWhen the command is called without arguments, it resets all the\nevents, discarding the currently logged latency spike events, and resetting\nthe maximum event time register.\n\nIt is possible to reset only specific events by providing the `event` names\nas arguments.\n\nValid values for `event` are:\n* `active-defrag-cycle`\n* `aof-fsync-always`\n* `aof-stat`\n* `aof-rewrite-diff-write`\n* `aof-rename`\n* `aof-write`\n* `aof-write-active-child`\n* `aof-write-alone`\n* `aof-write-pending-fsync`\n* `command`\n* `expire-cycle`\n* `eviction-cycle`\n* `eviction-del`\n* `fast-command`\n* `fork`\n* `rdb-unlink-temp-file`\n\nFor more information refer to the [Latency Monitoring Framework page][lm].\n\n[lm]: /topics/latency-monitor\n\n",
                        "": "",
                        "return_types": [
                            {
                                "description": "the number of event time series that were reset.",
                                "type": "integer"
                            }
                        ],
                        "summary": "Reset latency data for one or more events.",
                        "arguments": [
                            {
                                "optional": true,
                                "multiple": true,
                                "multiple_token": true,
                                "name": "event",
                                "type": "string",
                                "value": "event"
                            }
                        ],
                        "since": "2.8.13",
                        "group": "server",
                        "arity": -2,
                        "command_flags": [
                            "admin",
                            "noscript",
                            "loading",
                            "stale"
                        ],
                        "acl_categories": [
                            "admin",
                            "slow",
                            "dangerous"
                        ],
                        "function": "latencyCommand",
                        "container": "LATENCY"
                    }
                }
            ],
            "group": "server",
            "since": "2.8.13"
        }
    },
    {
        "HSET": {
            "body": "Sets `field` in the hash stored at `key` to `value`.\nIf `key` does not exist, a new key holding a hash is created.\nIf `field` already exists in the hash, it is overwritten.\n\nAs of Redis 4.0.0, HSET is variadic and allows for multiple `field`/`value` pairs.\n\n@examples\n\n```cli\nHSET myhash field1 \"Hello\"\nHGET myhash field1\n```\n\n",
            "": "",
            "return_types": [
                {
                    "description": "The number of fields that were added.",
                    "type": "integer"
                }
            ],
            "summary": "Set the string value of a hash field",
            "complexity": "O(1) for each field/value pair added, so O(N) to add N field/value pairs when the command is called with multiple field/value pairs.",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "multiple": true,
                    "multiple_token": true,
                    "name": "field_value",
                    "type": "block",
                    "value": [
                        {
                            "name": "field",
                            "type": "string",
                            "value": "field"
                        },
                        {
                            "name": "value",
                            "type": "string",
                            "value": "value"
                        }
                    ]
                }
            ],
            "since": "2.0.0",
            "group": "hash",
            "arity": -4,
            "command_flags": [
                "write",
                "denyoom",
                "fast"
            ],
            "acl_categories": [
                "write",
                "hash",
                "fast"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "hsetCommand"
        }
    },
    {
        "XTRIM": {
            "body": "`XTRIM` trims the stream by evicting older entries (entries with lower IDs) if needed.\n\nTrimming the stream can be done using one of these strategies:\n\n* `MAXLEN`: Evicts entries as long as the stream's length exceeds the specified `threshold`, where `threshold` is a positive integer.\n* `MINID`: Evicts entries with IDs lower than `threshold`, where `threshold` is a stream ID.\n\nFor example, this will trim the stream to exactly the latest 1000 items:\n\n```\nXTRIM mystream MAXLEN 1000\n```\n\nWhereas in this example, all entries that have an ID lower than 649085820-0 will be evicted:\n\n```\nXTRIM mystream MINID 649085820\n```\n\nBy default, or when provided with the optional `=` argument, the command performs exact trimming.\n\nDepending on the strategy, exact trimming means:\n\n* `MAXLEN`: the trimmed stream's length will be exactly the minimum between its original length and the specified `threshold`.\n* `MINID`: the oldest ID in the stream will be exactly the minimum between its original oldest ID and the specified `threshold`.\n\nNearly exact trimming\n---\n\nBecause exact trimming may require additional effort from the Redis server, the optional `~` argument can be provided to make it more efficient.\n\nFor example:\n\n```\nXTRIM mystream MAXLEN ~ 1000\n```\n\nThe `~` argument between the `MAXLEN` strategy and the `threshold` means that the user is requesting to trim the stream so its length is **at least** the `threshold`, but possibly slightly more.\nIn this case, Redis will stop trimming early when performance can be gained (for example, when a whole macro node in the data structure can't be removed).\nThis makes trimming much more efficient, and it is usually what you want, although after trimming, the stream may have few tens of additional entries over the `threshold`.\n\nAnother way to control the amount of work done by the command when using the `~`, is the `LIMIT` clause. \nWhen used, it specifies the maximal `count` of entries that will be evicted.\nWhen `LIMIT` and `count` aren't specified, the default value of 100 * the number of entries in a macro node will be implicitly used as the `count`.\nSpecifying the value 0 as `count` disables the limiting mechanism entirely.\n\n@examples\n\n```cli\nXADD mystream * field1 A field2 B field3 C field4 D\nXTRIM mystream MAXLEN 2\nXRANGE mystream - +\n```\n\n",
            "history": [
                [
                    "6.2",
                    "Added the `MINID` trimming strategy and the `LIMIT` option."
                ]
            ],
            "": "",
            "return_types": [
                {
                    "description": "The number of entries deleted from the stream.",
                    "type": "integer"
                }
            ],
            "summary": "Trims the stream to (approximately if '~' is passed) a certain size",
            "complexity": "O(N), with N being the number of evicted entries. Constant times are very small however, since entries are organized in macro nodes containing multiple entries that can be released with a single deallocation.",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "name": "trim",
                    "type": "block",
                    "value": [
                        {
                            "name": "maxlen_minid",
                            "type": "oneof",
                            "value": [
                                {
                                    "name": "__TBD__62__",
                                    "token": "MAXLEN"
                                },
                                {
                                    "name": "__TBD__63__",
                                    "token": "MINID"
                                }
                            ]
                        },
                        {
                            "optional": true,
                            "name": "=_~",
                            "type": "oneof",
                            "value": [
                                {
                                    "name": "__TBD__64__",
                                    "token": "="
                                },
                                {
                                    "name": "__TBD__65__",
                                    "token": "~"
                                }
                            ]
                        },
                        {
                            "name": "threshold",
                            "type": "string",
                            "value": "threshold"
                        },
                        {
                            "token": "LIMIT",
                            "optional": true,
                            "name": "count",
                            "type": "integer",
                            "value": "count"
                        }
                    ]
                }
            ],
            "since": "5.0.0",
            "group": "stream",
            "arity": -4,
            "command_flags": [
                "write",
                "random"
            ],
            "acl_categories": [
                "write",
                "stream",
                "slow"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "xtrimCommand"
        }
    },
    {
        "GEORADIUSBYMEMBER_RO": {
            "arity": -5,
            "command_flags": [
                "readonly"
            ],
            "acl_categories": [
                "read",
                "geo",
                "slow"
            ],
            "key_specs": [
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "georadiusbymemberroCommand",
            "group": ""
        }
    },
    {
        "RANDOMKEY": {
            "body": "Return a random key from the currently selected database.\n\n",
            "": "",
            "return_types": [
                {
                    "description": "the random key, or `nil` when the database is empty.",
                    "type": "bulk-string"
                }
            ],
            "summary": "Return a random key from the keyspace",
            "complexity": "O(1)",
            "since": "1.0.0",
            "group": "generic",
            "arity": 1,
            "command_flags": [
                "readonly",
                "random"
            ],
            "acl_categories": [
                "keyspace",
                "read",
                "slow"
            ],
            "function": "randomkeyCommand"
        }
    },
    {
        "PUBLISH": {
            "body": "Posts a message to the given channel.\n\nIn a Redis Cluster clients can publish to every node. The cluster makes sure\nthat published messages are forwarded as needed, so clients can subscribe to any\nchannel by connecting to any one of the nodes.\n\n",
            "": "",
            "return_types": [
                {
                    "description": "the number of clients that received the message. Note that in a",
                    "type": "integer"
                }
            ],
            "summary": "Post a message to a channel",
            "complexity": "O(N+M) where N is the number of clients subscribed to the receiving channel and M is the total number of subscribed patterns (by any client).",
            "arguments": [
                {
                    "name": "channel",
                    "type": "string",
                    "value": "channel"
                },
                {
                    "name": "message",
                    "type": "string",
                    "value": "message"
                }
            ],
            "since": "2.0.0",
            "group": "pubsub",
            "arity": 3,
            "command_flags": [
                "pubsub",
                "loading",
                "stale",
                "fast",
                "may_replicate"
            ],
            "acl_categories": [
                "pubsub",
                "fast"
            ],
            "function": "publishCommand"
        }
    },
    {
        "GEOPOS": {
            "body": "Return the positions (longitude,latitude) of all the specified members of the geospatial index represented by the sorted set at *key*.\n\nGiven a sorted set representing a geospatial index, populated using the [`GEOADD`](./geoadd) command, it is often useful to obtain back the coordinates of specified members. When the geospatial index is populated via [`GEOADD`](./geoadd) the coordinates are converted into a 52 bit geohash, so the coordinates returned may not be exactly the ones used in order to add the elements, but small errors may be introduced.\n\nThe command can accept a variable number of arguments so it always returns an array of positions even when a single element is specified.\n\n@examples\n\n```cli\nGEOADD Sicily 13.361389 38.115556 \"Palermo\" 15.087269 37.502669 \"Catania\"\nGEOPOS Sicily Palermo Catania NonExisting\n```\n\n",
            "return_summary": "@array-reply, specifically:\n\nThe command returns an array where each element is a two elements array\nrepresenting longitude and latitude (x,y) of each member name passed as\nargument to the command.\n\nNon existing elements are reported as NULL elements of the array.",
            "": "",
            "summary": "Returns longitude and latitude of members of a geospatial index",
            "complexity": "O(N) where N is the number of members requested.",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "multiple": true,
                    "multiple_token": true,
                    "name": "member",
                    "type": "string",
                    "value": "member"
                }
            ],
            "since": "3.2.0",
            "group": "geo",
            "arity": -2,
            "command_flags": [
                "readonly"
            ],
            "acl_categories": [
                "read",
                "geo",
                "slow"
            ],
            "key_specs": [
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "geoposCommand"
        }
    },
    {
        "CONFIG": {
            "arity": -2,
            "command_flags": [],
            "acl_categories": [
                "slow"
            ],
            "subcommands": [
                {
                    "RESETSTAT": {
                        "body": "Resets the statistics reported by Redis using the [`INFO`](./info) command.\n\nThese are the counters that are reset:\n\n* Keyspace hits\n* Keyspace misses\n* Number of commands processed\n* Number of connections received\n* Number of expired keys\n* Number of rejected connections\n* Latest fork(2) time\n* The `aof_delayed_fsync` counter\n\n",
                        "": "",
                        "return_types": [
                            {
                                "description": "always `OK`.",
                                "type": "simple-string"
                            }
                        ],
                        "summary": "Reset the stats returned by INFO",
                        "complexity": "O(1)",
                        "since": "2.0.0",
                        "group": "server",
                        "arity": 2,
                        "command_flags": [
                            "admin",
                            "noscript",
                            "stale"
                        ],
                        "acl_categories": [
                            "admin",
                            "slow",
                            "dangerous"
                        ],
                        "function": "configResetStatCommand",
                        "container": "CONFIG"
                    }
                },
                {
                    "GET": {
                        "body": "The `CONFIG GET` command is used to read the configuration parameters of a\nrunning Redis server.\nNot all the configuration parameters are supported in Redis 2.4, while Redis 2.6\ncan read the whole configuration of a server using this command.\n\nThe symmetric command used to alter the configuration at run time is `CONFIG\nSET`.\n\n`CONFIG GET` takes a single argument, which is a glob-style pattern.\nAll the configuration parameters matching this parameter are reported as a list\nof key-value pairs.\nExample:\n\n```\nredis> config get *max-*-entries*\n1) \"hash-max-zipmap-entries\"\n2) \"512\"\n3) \"list-max-ziplist-entries\"\n4) \"512\"\n5) \"set-max-intset-entries\"\n6) \"512\"\n```\n\nYou can obtain a list of all the supported configuration parameters by typing\n`CONFIG GET *` in an open `redis-cli` prompt.\n\nAll the supported parameters have the same meaning of the equivalent\nconfiguration parameter used in the [redis.conf][hgcarr22rc] file, with the\nfollowing important differences:\n\n[hgcarr22rc]: http://github.com/redis/redis/raw/2.8/redis.conf\n\n* Where bytes or other quantities are specified, it is not possible to use\n  the `redis.conf` abbreviated form (`10k`, `2gb` ... and so forth), everything\n  should be specified as a well-formed 64-bit integer, in the base unit of the\n  configuration directive.\n* The save parameter is a single string of space-separated integers.\n  Every pair of integers represent a seconds/modifications threshold.\n\nFor instance what in `redis.conf` looks like:\n\n```\nsave 900 1\nsave 300 10\n```\n\nthat means, save after 900 seconds if there is at least 1 change to the dataset,\nand after 300 seconds if there are at least 10 changes to the dataset, will be\nreported by `CONFIG GET` as \"900 1 300 10\".\n\n",
                        "return_summary": "The return type of the command is a @array-reply.",
                        "": "",
                        "summary": "Get the value of a configuration parameter",
                        "arguments": [
                            {
                                "name": "parameter",
                                "type": "string",
                                "value": "parameter"
                            }
                        ],
                        "since": "2.0.0",
                        "group": "server",
                        "arity": 3,
                        "command_flags": [
                            "admin",
                            "noscript",
                            "loading",
                            "stale"
                        ],
                        "acl_categories": [
                            "admin",
                            "slow",
                            "dangerous"
                        ],
                        "function": "configGetCommand",
                        "container": "CONFIG"
                    }
                },
                {
                    "SET": {
                        "body": "The `CONFIG SET` command is used in order to reconfigure the server at run time\nwithout the need to restart Redis.\nYou can change both trivial parameters or switch from one to another persistence\noption using this command.\n\nThe list of configuration parameters supported by `CONFIG SET` can be obtained\nissuing a `CONFIG GET *` command, that is the symmetrical command used to obtain\ninformation about the configuration of a running Redis instance.\n\nAll the configuration parameters set using `CONFIG SET` are immediately loaded\nby Redis and will take effect starting with the next command executed.\n\nAll the supported parameters have the same meaning of the equivalent\nconfiguration parameter used in the [redis.conf][hgcarr22rc] file, with the\nfollowing important differences:\n\n[hgcarr22rc]: http://github.com/redis/redis/raw/6.0/redis.conf\n\n* In options where bytes or other quantities are specified, it is not\n  possible to use the `redis.conf` abbreviated form (`10k`, `2gb` ... and so forth),\n  everything should be specified as a well-formed 64-bit integer, in the base\n  unit of the configuration directive. However since Redis version 3.0 or\n  greater, it is possible to use `CONFIG SET` with memory units for\n  `maxmemory`, client output buffers, and replication backlog size.\n* The save parameter is a single string of space-separated integers.\n  Every pair of integers represent a seconds/modifications threshold.\n\nFor instance what in `redis.conf` looks like:\n\n```\nsave 900 1\nsave 300 10\n```\n\nthat means, save after 900 seconds if there is at least 1 change to the dataset,\nand after 300 seconds if there are at least 10 changes to the dataset, should\nbe set using `CONFIG SET SAVE \"900 1 300 10\"`.\n\nIt is possible to switch persistence from RDB snapshotting to append-only file\n(and the other way around) using the `CONFIG SET` command.\nFor more information about how to do that please check the [persistence\npage][tp].\n\n[tp]: /topics/persistence\n\nIn general what you should know is that setting the `appendonly` parameter to\n`yes` will start a background process to save the initial append-only file\n(obtained from the in memory data set), and will append all the subsequent\ncommands on the append-only file, thus obtaining exactly the same effect of a\nRedis server that started with AOF turned on since the start.\n\nYou can have both the AOF enabled with RDB snapshotting if you want, the two\noptions are not mutually exclusive.\n\n",
                        "": "",
                        "return_types": [
                            {
                                "description": "`OK` when the configuration was set properly.",
                                "type": "simple-string"
                            }
                        ],
                        "summary": "Set a configuration parameter to the given value",
                        "arguments": [
                            {
                                "name": "parameter",
                                "type": "string",
                                "value": "parameter"
                            },
                            {
                                "name": "value",
                                "type": "string",
                                "value": "value"
                            }
                        ],
                        "since": "2.0.0",
                        "group": "server",
                        "arity": 4,
                        "command_flags": [
                            "admin",
                            "noscript",
                            "stale"
                        ],
                        "acl_categories": [
                            "admin",
                            "slow",
                            "dangerous"
                        ],
                        "function": "configSetCommand",
                        "container": "CONFIG"
                    }
                },
                {
                    "REWRITE": {
                        "body": "The `CONFIG REWRITE` command rewrites the `redis.conf` file the server was started with, applying the minimal changes needed to make it reflect the configuration currently used by the server, which may be different compared to the original one because of the use of the `CONFIG SET` command.\n\nThe rewrite is performed in a very conservative way:\n\n* Comments and the overall structure of the original redis.conf are preserved as much as possible.\n* If an option already exists in the old redis.conf file, it will be rewritten at the same position (line number).\n* If an option was not already present, but it is set to its default value, it is not added by the rewrite process.\n* If an option was not already present, but it is set to a non-default value, it is appended at the end of the file.\n* Non used lines are blanked. For instance if you used to have multiple `save` directives, but the current configuration has fewer or none as you disabled RDB persistence, all the lines will be blanked.\n\nCONFIG REWRITE is also able to rewrite the configuration file from scratch if the original one no longer exists for some reason. However if the server was started without a configuration file at all, the CONFIG REWRITE will just return an error.\n\n## Atomic rewrite process\n\nIn order to make sure the redis.conf file is always consistent, that is, on errors or crashes you always end with the old file, or the new one, the rewrite is performed with a single `write(2)` call that has enough content to be at least as big as the old file. Sometimes additional padding in the form of comments is added in order to make sure the resulting file is big enough, and later the file gets truncated to remove the padding at the end.\n\n",
                        "": "",
                        "return_types": [
                            {
                                "description": "`OK` when the configuration was rewritten properly.",
                                "type": "simple-string"
                            }
                        ],
                        "summary": "Rewrite the configuration file with the in memory configuration",
                        "since": "2.8.0",
                        "group": "server",
                        "arity": 2,
                        "command_flags": [
                            "admin",
                            "noscript",
                            "stale"
                        ],
                        "acl_categories": [
                            "admin",
                            "slow",
                            "dangerous"
                        ],
                        "function": "configRewriteCommand",
                        "container": "CONFIG"
                    }
                },
                {
                    "HELP": {
                        "arity": 2,
                        "command_flags": [
                            "loading",
                            "stale"
                        ],
                        "acl_categories": [
                            "slow"
                        ],
                        "function": "configHelpCommand",
                        "container": "CONFIG",
                        "group": "server"
                    }
                }
            ],
            "group": "server",
            "since": "2.0.0"
        }
    },
    {
        "MEMORY": {
            "arity": -2,
            "command_flags": [],
            "acl_categories": [
                "slow"
            ],
            "subcommands": [
                {
                    "PURGE": {
                        "body": "The `MEMORY PURGE` command attempts to purge dirty pages so these can be\nreclaimed by the allocator.\n\nThis command is currently implemented only when using **jemalloc** as an\nallocator, and evaluates to a benign NOOP for all others.\n\n",
                        "": "",
                        "return_types": [
                            {
                                "type": "simple-string"
                            }
                        ],
                        "summary": "Ask the allocator to release memory",
                        "since": "4.0.0",
                        "group": "server",
                        "arity": 2,
                        "command_flags": [],
                        "acl_categories": [
                            "slow"
                        ],
                        "function": "memoryCommand",
                        "container": "MEMORY"
                    }
                },
                {
                    "STATS": {
                        "body": "The `MEMORY STATS` command returns an @array-reply about the memory usage of the\nserver.\n\nThe information about memory usage is provided as metrics and their respective\nvalues. The following metrics are reported:\n\n*   `peak.allocated`: Peak memory consumed by Redis in bytes (see [`INFO`](./info)'s\n     `used_memory_peak`)\n*   `total.allocated`: Total number of bytes allocated by Redis using its\n     allocator (see [`INFO`](./info)'s `used_memory`)\n*   `startup.allocated`: Initial amount of memory consumed by Redis at startup\n     in bytes (see [`INFO`](./info)'s `used_memory_startup`)\n*   `replication.backlog`: Size in bytes of the replication backlog (see\n     [`INFO`](./info)'s `repl_backlog_active`)\n*   `clients.slaves`: The total size in bytes of all replicas overheads (output\n     and query buffers, connection contexts)\n*   `clients.normal`: The total size in bytes of all clients overheads (output\n     and query buffers, connection contexts)\n*   `aof.buffer`: The summed size in bytes of the current and rewrite AOF\n     buffers (see [`INFO`](./info)'s `aof_buffer_length` and `aof_rewrite_buffer_length`,\n     respectively)\n*    `lua.caches`: the summed size in bytes of the overheads of the Lua scripts'\n     caches\n*   `dbXXX`: For each of the server's databases, the overheads of the main and\n     expiry dictionaries (`overhead.hashtable.main` and\n    `overhead.hashtable.expires`, respectively) are reported in bytes\n*   `overhead.total`: The sum of all overheads, i.e. `startup.allocated`,\n     `replication.backlog`, `clients.slaves`, `clients.normal`, `aof.buffer` and\n     those of the internal data structures that are used in managing the\n     Redis keyspace (see [`INFO`](./info)'s `used_memory_overhead`)\n*   `keys.count`: The total number of keys stored across all databases in the\n     server\n*   `keys.bytes-per-key`: The ratio between **net memory usage** (`total.allocated`\n     minus `startup.allocated`) and `keys.count` \n*   `dataset.bytes`: The size in bytes of the dataset, i.e. `overhead.total`\n     subtracted from `total.allocated` (see [`INFO`](./info)'s `used_memory_dataset`)\n*   `dataset.percentage`: The percentage of `dataset.bytes` out of the net\n     memory usage\n*   `peak.percentage`: The percentage of `peak.allocated` out of\n     `total.allocated`\n*   `fragmentation`: See [`INFO`](./info)'s `mem_fragmentation_ratio`\n\n",
                        "": "",
                        "return_types": [
                            {
                                "description": "nested list of memory usage metrics and their values",
                                "type": "array"
                            }
                        ],
                        "summary": "Show memory usage details",
                        "since": "4.0.0",
                        "group": "server",
                        "arity": 2,
                        "command_flags": [
                            "random"
                        ],
                        "acl_categories": [
                            "slow"
                        ],
                        "function": "memoryCommand",
                        "container": "MEMORY"
                    }
                },
                {
                    "HELP": {
                        "body": "The `MEMORY HELP` command returns a helpful text describing the different\nsubcommands.\n\n",
                        "": "",
                        "return_types": [
                            {
                                "description": "a list of subcommands and their descriptions",
                                "type": "array"
                            }
                        ],
                        "summary": "Show helpful text about the different subcommands",
                        "since": "4.0.0",
                        "group": "server",
                        "arity": 2,
                        "command_flags": [
                            "loading",
                            "stale"
                        ],
                        "acl_categories": [
                            "slow"
                        ],
                        "function": "memoryCommand",
                        "container": "MEMORY"
                    }
                },
                {
                    "USAGE": {
                        "body": "The `MEMORY USAGE` command reports the number of bytes that a key and its value\nrequire to be stored in RAM.\n\nThe reported usage is the total of memory allocations for data and\nadministrative overheads that a key its value require.\n\nFor nested data types, the optional `SAMPLES` option can be provided, where\n`count` is the number of sampled nested values. By default, this option is set\nto `5`. To sample the all of the nested values, use `SAMPLES 0`. \n\n@examples\n\nWith Redis v4.0.1 64-bit and **jemalloc**, the empty string measures as follows:\n\n```\n> SET \"\" \"\"\nOK\n> MEMORY USAGE \"\"\n(integer) 51\n```\n\nThese bytes are pure overhead at the moment as no actual data is stored, and are\nused for maintaining the internal data structures of the server. Longer keys and\nvalues show asymptotically linear usage.\n\n```\n> SET foo bar\nOK\n> MEMORY USAGE foo\n(integer) 54\n> SET cento 01234567890123456789012345678901234567890123\n45678901234567890123456789012345678901234567890123456789\nOK\n127.0.0.1:6379> MEMORY USAGE cento\n(integer) 153\n```\n\n",
                        "": "",
                        "return_types": [
                            {
                                "description": "the memory usage in bytes, or `nil` when the key does not exist.",
                                "type": "integer"
                            }
                        ],
                        "summary": "Estimate the memory usage of a key",
                        "complexity": "O(N) where N is the number of samples.",
                        "arguments": [
                            {
                                "name": "key",
                                "type": "key",
                                "value": "key"
                            },
                            {
                                "token": "SAMPLES",
                                "optional": true,
                                "name": "count",
                                "type": "integer",
                                "value": "count"
                            }
                        ],
                        "since": "4.0.0",
                        "group": "server",
                        "arity": -3,
                        "command_flags": [
                            "readonly"
                        ],
                        "acl_categories": [
                            "read",
                            "slow"
                        ],
                        "key_specs": [
                            {
                                "flags": [
                                    "read"
                                ],
                                "begin_search": {
                                    "index": {
                                        "pos": 2
                                    }
                                },
                                "find_keys": {
                                    "range": {
                                        "lastkey": 0,
                                        "step": 1,
                                        "limit": 0
                                    }
                                }
                            }
                        ],
                        "function": "memoryCommand",
                        "container": "MEMORY"
                    }
                },
                {
                    "DOCTOR": {
                        "body": "The `MEMORY DOCTOR` command reports about different memory-related issues that\nthe Redis server experiences, and advises about possible remedies.\n\n",
                        "": "",
                        "return_types": [
                            {
                                "type": "bulk-string"
                            }
                        ],
                        "summary": "Outputs memory problems report",
                        "since": "4.0.0",
                        "group": "server",
                        "arity": 2,
                        "command_flags": [
                            "random"
                        ],
                        "acl_categories": [
                            "slow"
                        ],
                        "function": "memoryCommand",
                        "container": "MEMORY"
                    }
                },
                {
                    "MALLOC-STATS": {
                        "body": "The `MEMORY MALLOC-STATS` command provides an internal statistics report from\nthe memory allocator.\n\nThis command is currently implemented only when using **jemalloc** as an\nallocator, and evaluates to a benign NOOP for all others.\n\n",
                        "": "",
                        "return_types": [
                            {
                                "description": "the memory allocator's internal statistics report",
                                "type": "bulk-string"
                            }
                        ],
                        "summary": "Show allocator internal stats",
                        "since": "4.0.0",
                        "group": "server",
                        "arity": 2,
                        "command_flags": [
                            "random"
                        ],
                        "acl_categories": [
                            "slow"
                        ],
                        "function": "memoryCommand",
                        "container": "MEMORY"
                    }
                }
            ],
            "group": "server",
            "since": "4.0.0"
        }
    },
    {
        "XAUTOCLAIM": {
            "body": "This command transfers ownership of pending stream entries that match the specified criteria. Conceptually, `XAUTOCLAIM`  is equivalent to calling [`XPENDING`](./xpending) and then [`XCLAIM`](./xclaim),\nbut provides a more straightforward way to deal with message delivery failures via [`SCAN`](./scan)-like semantics.\n\nLike [`XCLAIM`](./xclaim), the command operates on the stream entries at `<key>` and in the context of the provided `<group>`.\nIt transfers ownership to `<consumer>` of messages pending for more than `<min-idle-time>` milliseconds and having an equal or greater ID than `<start>`.\n\nThe optional `<count>` argument, which defaults to 100, is the upper limit of the number of entries that the command attempts to claim.\nInternally, the command begins scanning the consumer group's Pending Entries List (PEL) from `<start>` and filters out entries having an idle time less than or equal to `<min-idle-time>`.\nThe maximum number of pending entries that the command scans is the product of multiplying `<count>`'s value by 10 (hard-coded).\nIt is possible, therefore, that the number of entries claimed will be less than the specified value.\n\nThe optional `JUSTID` argument changes the reply to return just an array of IDs of messages successfully claimed, without returning the actual message.\nUsing this option means the retry counter is not incremented.\n\nThe command returns the claimed entries as an array. It also returns a stream ID intended for cursor-like use as the `<start>` argument for its subsequent call.\nWhen there are no remaining PEL entries, the command returns the special `0-0` ID to signal completion.\nHowever, note that you may want to continue calling `XAUTOCLAIM` even after the scan is complete with the `0-0` as `<start>` ID, because enough time passed, so older pending entries may now be eligible for claiming.\n\nNote that only messages that are idle longer than `<min-idle-time>` are claimed, and claiming a message resets its idle time.\nThis ensures that only a single consumer can successfully claim a given pending message at a specific instant of time and trivially reduces the probability of processing the same message multiple times.\n\nLastly, claiming a message with `XAUTOCLAIM` also increments the attempted deliveries count for that message, unless the `JUSTID` option has been specified (which only delivers the message ID, not the message itself).\nMessages that cannot be processed for some reason - for example, because consumers systematically crash when processing them - will exhibit high attempted delivery counts that can be detected by monitoring.\n\n@examples\n\n```\n> XAUTOCLAIM mystream mygroup Alice 3600000 0-0 COUNT 25\n1) \"0-0\"\n2) 1) 1) \"1609338752495-0\"\n      2) 1) \"field\"\n         2) \"value\"\n```\n\nIn the above example, we attempt to claim up to 25 entries that are pending and idle (not having been acknowledged or claimed) for at least an hour, starting at the stream's beginning.\nThe consumer \"Alice\" from the \"mygroup\" group acquires ownership of these messages.\nNote that the stream ID returned in the example is `0-0`, indicating that the entire stream was scanned.\n\n",
            "return_summary": "@array-reply, specifically:\n\nAn array with two elements:\n\n1. The first element is a stream ID to be used as the `<start>` argument for the next call to `XAUTOCLAIM`\n2. The second element is an array containing all the successfully claimed messages in the same format as [`XRANGE`](./xrange).",
            "": "",
            "summary": "Changes (or acquires) ownership of messages in a consumer group, as if the messages were delivered to the specified consumer.",
            "complexity": "O(1) if COUNT is small.",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "name": "group",
                    "type": "string",
                    "value": "group"
                },
                {
                    "name": "consumer",
                    "type": "string",
                    "value": "consumer"
                },
                {
                    "name": "min-idle-time",
                    "type": "string",
                    "value": "min-idle-time"
                },
                {
                    "name": "start",
                    "type": "string",
                    "value": "start"
                },
                {
                    "token": "COUNT",
                    "optional": true,
                    "name": "count",
                    "type": "integer",
                    "value": "count"
                },
                {
                    "optional": true,
                    "name": "justid",
                    "token": "JUSTID"
                }
            ],
            "since": "6.2.0",
            "group": "stream",
            "arity": -6,
            "command_flags": [
                "write",
                "random",
                "fast"
            ],
            "acl_categories": [
                "write",
                "stream",
                "fast"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "xautoclaimCommand"
        }
    },
    {
        "EVALSHA_RO": {
            "body": "This is a read-only variant of the [`EVALSHA`](./evalsha) command that isn't allowed to execute commands that modify data.\n\n Unlike [`EVALSHA`](./evalsha), scripts executed with this command can always be killed and never affect the replication stream.\n Because it can only read data, this command can always be executed on a master or a replica.\n\n",
            "return_summary": "",
            "summary": "Execute a read-only Lua script server side",
            "complexity": "Depends on the script that is executed.",
            "arguments": [
                {
                    "name": "sha1",
                    "type": "string",
                    "value": "sha1"
                },
                {
                    "name": "numkeys",
                    "type": "integer",
                    "value": "numkeys"
                },
                {
                    "multiple": true,
                    "multiple_token": true,
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "multiple": true,
                    "multiple_token": true,
                    "name": "arg",
                    "type": "string",
                    "value": "arg"
                }
            ],
            "since": "7.0.0",
            "group": "scripting",
            "arity": -3,
            "command_flags": [
                "noscript",
                "skip_monitor"
            ],
            "acl_categories": [
                "slow",
                "scripting"
            ],
            "key_specs": [
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 2
                        }
                    },
                    "find_keys": {
                        "keynum": {
                            "keynumidx": 0,
                            "firstkey": 1,
                            "step": 1
                        }
                    }
                }
            ],
            "function": "evalShaRoCommand",
            "get_keys_function": "evalGetKeys"
        }
    },
    {
        "LLEN": {
            "body": "Returns the length of the list stored at `key`.\nIf `key` does not exist, it is interpreted as an empty list and `0` is returned.\nAn error is returned when the value stored at `key` is not a list.\n\n@examples\n\n```cli\nLPUSH mylist \"World\"\nLPUSH mylist \"Hello\"\nLLEN mylist\n```\n\n",
            "": "",
            "return_types": [
                {
                    "description": "the length of the list at `key`.",
                    "type": "integer"
                }
            ],
            "summary": "Get the length of a list",
            "complexity": "O(1)",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                }
            ],
            "since": "1.0.0",
            "group": "list",
            "arity": 2,
            "command_flags": [
                "readonly",
                "fast"
            ],
            "acl_categories": [
                "read",
                "list",
                "fast"
            ],
            "key_specs": [
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "llenCommand"
        }
    },
    {
        "XREADGROUP": {
            "body": "The `XREADGROUP` command is a special version of the [`XREAD`](./xread) command\nwith support for consumer groups. Probably you will have to understand the\n[`XREAD`](./xread) command before reading this page will makes sense.\n\nMoreover, if you are new to streams, we recommend to read our\n[introduction to Redis Streams](/topics/streams-intro).\nMake sure to understand the concept of consumer group in the introduction\nso that following how this command works will be simpler.\n\n## Consumer groups in 30 seconds\n\nThe difference between this command and the vanilla [`XREAD`](./xread) is that this\none supports consumer groups.\n\nWithout consumer groups, just using [`XREAD`](./xread), all the clients are served with all the entries arriving in a stream. Instead using consumer groups with `XREADGROUP`, it is possible to create groups of clients that consume different parts of the messages arriving in a given stream. If, for instance, the stream gets the new entries A, B, and C and there are two consumers reading via a consumer group, one client will get, for instance, the messages A and C, and the other the message B, and so forth.\n\nWithin a consumer group, a given consumer (that is, just a client consuming messages from the stream), has to identify with an unique *consumer name*. Which is just a string.\n\nOne of the guarantees of consumer groups is that a given consumer can only see the history of messages that were delivered to it, so a message has just a single owner. However there is a special feature called *message claiming* that allows other consumers to claim messages in case there is a non recoverable failure of some consumer. In order to implement such semantics, consumer groups require explicit acknowledgment of the messages successfully processed by the consumer, via the [`XACK`](./xack) command. This is needed because the stream will track, for each consumer group, who is processing what message.\n\nThis is how to understand if you want to use a consumer group or not:\n\n1. If you have a stream and multiple clients, and you want all the clients to get all the messages, you do not need a consumer group.\n2. If you have a stream and multiple clients, and you want the stream to be *partitioned* or *sharded* across your clients, so that each client will get a sub set of the messages arriving in a stream, you need a consumer group.\n\n## Differences between XREAD and XREADGROUP\n\nFrom the point of view of the syntax, the commands are almost the same,\nhowever `XREADGROUP` *requires* a special and mandatory option:\n\n    GROUP <group-name> <consumer-name>\n\nThe group name is just the name of a consumer group associated to the stream.\nThe group is created using the [`XGROUP`](./xgroup) command. The consumer name is the\nstring that is used by the client to identify itself inside the group.\nThe consumer is auto created inside the consumer group the first time it\nis saw. Different clients should select a different consumer name.\n\nWhen you read with `XREADGROUP`, the server will *remember* that a given\nmessage was delivered to you: the message will be stored inside the\nconsumer group in what is called a Pending Entries List (PEL), that is\na list of message IDs delivered but not yet acknowledged.\n\nThe client will have to acknowledge the message processing using [`XACK`](./xack)\nin order for the pending entry to be removed from the PEL. The PEL\ncan be inspected using the [`XPENDING`](./xpending) command.\n\nThe `NOACK` subcommand can be used to avoid adding the message to the PEL in\ncases where reliability is not a requirement and the occasional message loss\nis acceptable. This is equivalent to acknowledging the message when it is read.\n\nThe ID to specify in the **STREAMS** option when using `XREADGROUP` can\nbe one of the following two:\n\n* The special `>` ID, which means that the consumer want to receive only messages that were *never delivered to any other consumer*. It just means, give me new messages.\n* Any other ID, that is, 0 or any other valid ID or incomplete ID (just the millisecond time part), will have the effect of returning entries that are pending for the consumer sending the command with IDs greater than the one provided. So basically if the ID is not `>`, then the command will just let the client access its pending entries: messages delivered to it, but not yet acknowledged. Note that in this case, both `BLOCK` and `NOACK` are ignored.\n\nLike [`XREAD`](./xread) the `XREADGROUP` command can be used in a blocking way. There\nare no differences in this regard.\n\n## What happens when a message is delivered to a consumer?\n\nTwo things:\n\n1. If the message was never delivered to anyone, that is, if we are talking about a new message, then a PEL (Pending Entries List) is created.\n2. If instead the message was already delivered to this consumer, and it is just re-fetching the same message again, then the *last delivery counter* is updated to the current time, and the *number of deliveries* is incremented by one. You can access those message properties using the [`XPENDING`](./xpending) command.\n\n## Usage example\n\nNormally you use the command like that in order to get new messages and\nprocess them. In pseudo-code:\n\n```\nWHILE true\n    entries = XREADGROUP GROUP $GroupName $ConsumerName BLOCK 2000 COUNT 10 STREAMS mystream >\n    if entries == nil\n        puts \"Timeout... try again\"\n        CONTINUE\n    end\n\n    FOREACH entries AS stream_entries\n        FOREACH stream_entries as message\n            process_message(message.id,message.fields)\n\n            # ACK the message as processed\n            XACK mystream $GroupName message.id\n        END\n    END\nEND\n```\n\nIn this way the example consumer code will fetch only new messages, process\nthem, and acknowledge them via [`XACK`](./xack). However the example code above is\nnot complete, because it does not handle recovering after a crash. What\nwill happen if we crash in the middle of processing messages, is that our\nmessages will remain in the pending entries list, so we can access our\nhistory by giving `XREADGROUP` initially an ID of 0, and performing the same\nloop. Once providing an ID of 0 the reply is an empty set of messages, we\nknow that we processed and acknowledged all the pending messages: we\ncan start to use `>` as ID, in order to get the new messages and rejoin the\nconsumers that are processing new things.\n\nTo see how the command actually replies, please check the [`XREAD`](./xread) command page.\n\n",
            "return_summary": "@array-reply, specifically:\n\nThe command returns an array of results: each element of the returned\narray is an array composed of a two element containing the key name and\nthe entries reported for that key. The entries reported are full stream\nentries, having IDs and the list of all the fields and values. Field and\nvalues are guaranteed to be reported in the same order they were added\nby [`XADD`](./xadd).\n\nWhen **BLOCK** is used, on timeout a null reply is returned.\n\nReading the [Redis Streams introduction](/topics/streams-intro) is highly\nsuggested in order to understand more about the streams overall behavior\nand semantics.",
            "": "",
            "summary": "Return new entries from a stream using a consumer group, or access the history of the pending entries for a given consumer. Can block.",
            "complexity": "For each stream mentioned: O(M) with M being the number of elements returned. If M is constant (e.g. always asking for the first 10 elements with COUNT), you can consider it O(1). On the other side when XREADGROUP blocks, XADD will pay the O(N) time in order to serve the N clients blocked on the stream getting new data.",
            "arguments": [
                {
                    "token": "GROUP",
                    "name": "group_consumer",
                    "type": "block",
                    "value": [
                        {
                            "name": "group",
                            "type": "string",
                            "value": "group"
                        },
                        {
                            "name": "consumer",
                            "type": "string",
                            "value": "consumer"
                        }
                    ]
                },
                {
                    "token": "COUNT",
                    "optional": true,
                    "name": "count",
                    "type": "integer",
                    "value": "count"
                },
                {
                    "token": "BLOCK",
                    "optional": true,
                    "name": "milliseconds",
                    "type": "integer",
                    "value": "milliseconds"
                },
                {
                    "optional": true,
                    "name": "noack",
                    "token": "NOACK"
                },
                {
                    "name": "streams",
                    "token": "STREAMS"
                },
                {
                    "multiple": true,
                    "multiple_token": true,
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "multiple": true,
                    "multiple_token": true,
                    "name": "ID",
                    "type": "string",
                    "value": "ID"
                }
            ],
            "since": "5.0.0",
            "group": "stream",
            "arity": -7,
            "command_flags": [
                "write"
            ],
            "acl_categories": [
                "write",
                "stream",
                "slow",
                "blocking"
            ],
            "key_specs": [
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "keyword": {
                            "keyword": "STREAMS",
                            "startfrom": 4
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": -1,
                            "step": 1,
                            "limit": 2
                        }
                    }
                }
            ],
            "function": "xreadCommand",
            "get_keys_function": "xreadGetKeys"
        }
    },
    {
        "SETNX": {
            "body": "Set `key` to hold string `value` if `key` does not exist.\nIn that case, it is equal to [`SET`](./set).\nWhen `key` already holds a value, no operation is performed.\n`SETNX` is short for \"**SET** if **N**ot e**X**ists\".\n\n@examples\n\n```cli\nSETNX mykey \"Hello\"\nSETNX mykey \"World\"\nGET mykey\n```\n\n## Design pattern: Locking with `SETNX`\n\n**Please note that:**\n\n1. The following pattern is discouraged in favor of [the Redlock algorithm](https://redis.io/topics/distlock) which is only a bit more complex to implement, but offers better guarantees and is fault tolerant.\n2. We document the old pattern anyway because certain existing implementations link to this page as a reference. Moreover it is an interesting example of how Redis commands can be used in order to mount programming primitives.\n3. Anyway even assuming a single-instance locking primitive, starting with 2.6.12 it is possible to create a much simpler locking primitive, equivalent to the one discussed here, using the [`SET`](./set) command to acquire the lock, and a simple Lua script to release the lock. The pattern is documented in the [`SET`](./set) command page.\n\nThat said, `SETNX` can be used, and was historically used, as a locking primitive. For example, to acquire the lock of the key `foo`, the client could try the\nfollowing:\n\n```\nSETNX lock.foo <current Unix time + lock timeout + 1>\n```\n\nIf `SETNX` returns `1` the client acquired the lock, setting the `lock.foo` key\nto the Unix time at which the lock should no longer be considered valid.\nThe client will later use `DEL lock.foo` in order to release the lock.\n\nIf `SETNX` returns `0` the key is already locked by some other client.\nWe can either return to the caller if it's a non blocking lock, or enter a loop\nretrying to hold the lock until we succeed or some kind of timeout expires.\n\n### Handling deadlocks\n\nIn the above locking algorithm there is a problem: what happens if a client\nfails, crashes, or is otherwise not able to release the lock?\nIt's possible to detect this condition because the lock key contains a UNIX\ntimestamp.\nIf such a timestamp is equal to the current Unix time the lock is no longer\nvalid.\n\nWhen this happens we can't just call [`DEL`](./del) against the key to remove the lock\nand then try to issue a `SETNX`, as there is a race condition here, when\nmultiple clients detected an expired lock and are trying to release it.\n\n* C1 and C2 read `lock.foo` to check the timestamp, because they both received\n  `0` after executing `SETNX`, as the lock is still held by C3 that crashed\n  after holding the lock.\n* C1 sends `DEL lock.foo`\n* C1 sends `SETNX lock.foo` and it succeeds\n* C2 sends `DEL lock.foo`\n* C2 sends `SETNX lock.foo` and it succeeds\n* **ERROR**: both C1 and C2 acquired the lock because of the race condition.\n\nFortunately, it's possible to avoid this issue using the following algorithm.\nLet's see how C4, our sane client, uses the good algorithm:\n\n*   C4 sends `SETNX lock.foo` in order to acquire the lock\n\n*   The crashed client C3 still holds it, so Redis will reply with `0` to C4.\n\n*   C4 sends `GET lock.foo` to check if the lock expired.\n    If it is not, it will sleep for some time and retry from the start.\n\n*   Instead, if the lock is expired because the Unix time at `lock.foo` is older\n    than the current Unix time, C4 tries to perform:\n\n    ```\n    GETSET lock.foo <current Unix timestamp + lock timeout + 1>\n    ```\n\n*   Because of the [`GETSET`](./getset) semantic, C4 can check if the old value stored at\n    `key` is still an expired timestamp.\n    If it is, the lock was acquired.\n\n*   If another client, for instance C5, was faster than C4 and acquired the lock\n    with the [`GETSET`](./getset) operation, the C4 [`GETSET`](./getset) operation will return a non\n    expired timestamp.\n    C4 will simply restart from the first step.\n    Note that even if C4 set the key a bit a few seconds in the future this is\n    not a problem.\n\nIn order to make this locking algorithm more robust, a\nclient holding a lock should always check the timeout didn't expire before\nunlocking the key with [`DEL`](./del) because client failures can be complex, not just\ncrashing but also blocking a lot of time against some operations and trying\nto issue [`DEL`](./del) after a lot of time (when the LOCK is already held by another\nclient).\n\n",
            "return_summary": "@integer-reply, specifically:\n\n* `1` if the key was set\n* `0` if the key was not set",
            "": "",
            "summary": "Set the value of a key, only if the key does not exist",
            "complexity": "O(1)",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "name": "value",
                    "type": "string",
                    "value": "value"
                }
            ],
            "since": "1.0.0",
            "group": "string",
            "arity": 3,
            "command_flags": [
                "write",
                "denyoom",
                "fast"
            ],
            "acl_categories": [
                "write",
                "string",
                "fast"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "setnxCommand"
        }
    },
    {
        "SELECT": {
            "body": "Select the Redis logical database having the specified zero-based numeric index.\nNew connections always use the database 0.\n\nSelectable Redis databases are a form of namespacing: all databases are still persisted in the same RDB / AOF file. However different databases can have keys with the same name, and commands like [`FLUSHDB`](./flushdb), [`SWAPDB`](./swapdb) or [`RANDOMKEY`](./randomkey) work on specific databases.\n\nIn practical terms, Redis databases should be used to separate different keys belonging to the same application (if needed), and not to use a single Redis instance for multiple unrelated applications.\n\nWhen using Redis Cluster, the `SELECT` command cannot be used, since Redis Cluster only supports database zero. In the case of a Redis Cluster, having multiple databases would be useless and an unnecessary source of complexity. Commands operating atomically on a single database would not be possible with the Redis Cluster design and goals.\n\nSince the currently selected database is a property of the connection, clients should track the currently selected database and re-select it on reconnection. While there is no command in order to query the selected database in the current connection, the `CLIENT LIST` output shows, for each client, the currently selected database.\n\n",
            "": "",
            "return_types": [
                {
                    "type": "simple-string"
                }
            ],
            "summary": "Change the selected database for the current connection",
            "arguments": [
                {
                    "name": "index",
                    "type": "integer",
                    "value": "index"
                }
            ],
            "since": "1.0.0",
            "group": "connection",
            "arity": 2,
            "command_flags": [
                "loading",
                "stale",
                "fast"
            ],
            "acl_categories": [
                "fast",
                "connection"
            ],
            "function": "selectCommand"
        }
    },
    {
        "PEXPIRETIME": {
            "body": "`PEXPIRETIME` has the same semantic as [`EXPIRETIME`](./expiretime), but returns the absolute Unix expiration timestamp in milliseconds instead of seconds.\n\n@examples\n\n```cli\nSET mykey \"Hello\"\nPEXPIREAT mykey 33177117420000\nPEXPIRETIME mykey\n```\n\n",
            "": "",
            "return_types": [
                {
                    "description": "Expiration Unix timestamp in milliseconds, or a negative value in order to signal an error (see the description below).",
                    "type": "integer"
                }
            ],
            "summary": "Get the expiration Unix timestamp for a key in milliseconds",
            "complexity": "O(1)",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                }
            ],
            "since": "7.0.0",
            "group": "generic",
            "arity": 2,
            "command_flags": [
                "readonly",
                "random",
                "fast"
            ],
            "acl_categories": [
                "keyspace",
                "read",
                "fast"
            ],
            "key_specs": [
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "pexpiretimeCommand"
        }
    },
    {
        "EXPIRETIME": {
            "body": "Returns the absolute Unix timestamp (since January 1, 1970) in seconds at which the given key will expire.\n\nSee also the [`PEXPIRETIME`](./pexpiretime) command which returns the same information with milliseconds resolution.\n\n@examples\n\n```cli\nSET mykey \"Hello\"\nEXPIREAT mykey 33177117420\nEXPIRETIME mykey\n```\n\n",
            "": "",
            "return_types": [
                {
                    "description": "Expiration Unix timestamp in seconds, or a negative value in order to signal an error (see the description below).",
                    "type": "integer"
                }
            ],
            "summary": "Get the expiration Unix timestamp for a key",
            "complexity": "O(1)",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                }
            ],
            "since": "7.0.0",
            "group": "generic",
            "arity": 2,
            "command_flags": [
                "readonly",
                "random",
                "fast"
            ],
            "acl_categories": [
                "keyspace",
                "read",
                "fast"
            ],
            "key_specs": [
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "expiretimeCommand"
        }
    },
    {
        "SRANDMEMBER": {
            "body": "When called with just the `key` argument, return a random element from the set value stored at `key`.\n\nIf the provided `count` argument is positive, return an array of **distinct elements**.\nThe array's length is either `count` or the set's cardinality ([`SCARD`](./scard)), whichever is lower.\n\nIf called with a negative `count`, the behavior changes and the command is allowed to return the **same element multiple times**.\nIn this case, the number of returned elements is the absolute value of the specified `count`.\n\n@examples\n\n```cli\nSADD myset one two three\nSRANDMEMBER myset\nSRANDMEMBER myset 2\nSRANDMEMBER myset -5\n```\n\n## Specification of the behavior when count is passed\n\nWhen the `count` argument is a positive value this command behaves as follows:\n\n* No repeated elements are returned.\n* If `count` is bigger than the set's cardinality, the command will only return the whole set without additional elements.\n* The order of elements in the reply is not truly random, so it is up to the client to shuffle them if needed.\n\nWhen the `count` is a negative value, the behavior changes as follows:\n\n* Repeating elements are possible.\n* Exactly `count` elements, or an empty array if the set is empty (non-existing key), are always returned.\n* The order of elements in the reply is truly random.\n\n## Distribution of returned elements\n\nNote: this section is relevant only for Redis 5 or below, as Redis 6 implements a fairer algorithm. \n\nThe distribution of the returned elements is far from perfect when the number of elements in the set is small, this is due to the fact that we used an approximated random element function that does not really guarantees good distribution.\n\nThe algorithm used, that is implemented inside dict.c, samples the hash table buckets to find a non-empty one. Once a non empty bucket is found, since we use chaining in our hash table implementation, the number of elements inside the bucket is checked and a random element is selected.\n\nThis means that if you have two non-empty buckets in the entire hash table, and one has three elements while one has just one, the element that is alone in its bucket will be returned with much higher probability.\n\n",
            "history": [
                [
                    "2.6.0",
                    "Added the optional `count` argument."
                ]
            ],
            "return_summary": "@bulk-string-reply: without the additional `count` argument, the command returns a Bulk Reply with the randomly selected element, or `nil` when `key` does not exist.\n\n@array-reply: when the additional `count` argument is passed, the command returns an array of elements, or an empty array when `key` does not exist.",
            "": "",
            "summary": "Get one or multiple random members from a set",
            "complexity": "Without the count argument O(1), otherwise O(N) where N is the absolute value of the passed count.",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "optional": true,
                    "name": "count",
                    "type": "integer",
                    "value": "count"
                }
            ],
            "since": "1.0.0",
            "group": "set",
            "arity": -2,
            "command_flags": [
                "readonly",
                "random"
            ],
            "acl_categories": [
                "read",
                "set",
                "slow"
            ],
            "key_specs": [
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "srandmemberCommand"
        }
    },
    {
        "DEBUG": {
            "arity": -2,
            "command_flags": [
                "admin",
                "noscript",
                "loading",
                "stale"
            ],
            "acl_categories": [
                "admin",
                "slow",
                "dangerous"
            ],
            "function": "debugCommand",
            "group": "server",
            "internal": true
        }
    },
    {
        "ZREVRANGEBYLEX": {
            "body": "When all the elements in a sorted set are inserted with the same score, in order to force lexicographical ordering, this command returns all the elements in the sorted set at `key` with a value between `max` and `min`.\n\nApart from the reversed ordering, `ZREVRANGEBYLEX` is similar to [`ZRANGEBYLEX`](./zrangebylex).\n\nAs per Redis 6.2.0, this command is considered deprecated. Please prefer using the [`ZRANGE`](./zrange) command with the `BYLEX` and `REV` arguments in new code.\n\n@examples\n\n```cli\nZADD myzset 0 a 0 b 0 c 0 d 0 e 0 f 0 g\nZREVRANGEBYLEX myzset [c -\nZREVRANGEBYLEX myzset (c -\nZREVRANGEBYLEX myzset (g [aaa\n```\n\n",
            "deprecated": true,
            "": "",
            "return_types": [
                {
                    "description": "list of elements in the specified score range.",
                    "type": "array"
                }
            ],
            "summary": "Return a range of members in a sorted set, by lexicographical range, ordered from higher to lower strings.",
            "complexity": "O(log(N)+M) with N being the number of elements in the sorted set and M the number of elements being returned. If M is constant (e.g. always asking for the first 10 elements with LIMIT), you can consider it O(log(N)).",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "name": "max",
                    "type": "string",
                    "value": "max"
                },
                {
                    "name": "min",
                    "type": "string",
                    "value": "min"
                },
                {
                    "token": "LIMIT",
                    "optional": true,
                    "name": "offset_count",
                    "type": "block",
                    "value": [
                        {
                            "name": "offset",
                            "type": "integer",
                            "value": "offset"
                        },
                        {
                            "name": "count",
                            "type": "integer",
                            "value": "count"
                        }
                    ]
                }
            ],
            "since": "2.8.9",
            "group": "sorted_set",
            "arity": -4,
            "command_flags": [
                "readonly"
            ],
            "acl_categories": [
                "read",
                "sortedset",
                "slow"
            ],
            "key_specs": [
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "zrevrangebylexCommand"
        }
    },
    {
        "XINFO": {
            "arity": -2,
            "command_flags": [],
            "acl_categories": [
                "slow"
            ],
            "subcommands": [
                {
                    "HELP": {
                        "body": "The `XINFO HELP` command returns a helpful text describing the different subcommands.\n\n",
                        "": "",
                        "return_types": [
                            {
                                "description": "a list of subcommands and their descriptions",
                                "type": "array"
                            }
                        ],
                        "summary": "Show helpful text about the different subcommands",
                        "complexity": "O(1)",
                        "since": "5.0.0",
                        "group": "stream",
                        "arity": 2,
                        "command_flags": [
                            "loading",
                            "stale"
                        ],
                        "acl_categories": [
                            "stream",
                            "slow"
                        ],
                        "function": "xinfoCommand",
                        "container": "XINFO"
                    }
                },
                {
                    "GROUPS": {
                        "body": "This command returns the list of all consumers groups of the stream stored at `<key>`.\n\nBy default, only the following information is provided for each of the groups:\n\n* **name**: the consumer group's name\n* **consumers**: the number of consumers in the group\n* **pending**: the length of the group's pending entries list (PEL), which are messages that were delivered but are yet to be acknowledged\n* **last-delivered-id**: the ID of the last entry delivered the group's consumers\n\n@reply\n\n@array-reply: a list of consumer groups.\n\n@examples\n\n```\n> XINFO GROUPS mystream\n1) 1) name\n   2) \"mygroup\"\n   3) consumers\n   4) (integer) 2\n   5) pending\n   6) (integer) 2\n   7) last-delivered-id\n   8) \"1588152489012-0\"\n2) 1) name\n   2) \"some-other-group\"\n   3) consumers\n   4) (integer) 1\n   5) pending\n   6) (integer) 0\n   7) last-delivered-id\n   8) \"1588152498034-0\"\n```\n\n",
                        "return_summary": "",
                        "summary": "List the consumer groups of a stream",
                        "complexity": "O(1)",
                        "arguments": [
                            {
                                "name": "key",
                                "type": "key",
                                "value": "key"
                            }
                        ],
                        "since": "5.0.0",
                        "group": "stream",
                        "arity": 3,
                        "command_flags": [
                            "readonly"
                        ],
                        "acl_categories": [
                            "read",
                            "stream",
                            "slow"
                        ],
                        "key_specs": [
                            {
                                "flags": [
                                    "read"
                                ],
                                "begin_search": {
                                    "index": {
                                        "pos": 2
                                    }
                                },
                                "find_keys": {
                                    "range": {
                                        "lastkey": 0,
                                        "step": 1,
                                        "limit": 0
                                    }
                                }
                            }
                        ],
                        "function": "xinfoCommand",
                        "container": "XINFO"
                    }
                },
                {
                    "CONSUMERS": {
                        "body": "This command returns the list of consumers that belong to the `<groupname>` consumer group of the stream stored at `<key>`.\n\nThe following information is provided for each consumer in the group:\n\n* **name**: the consumer's name\n* **pending**: the number of pending messages for the client, which are messages that were delivered but are yet to be acknowledged\n* **idle**: the number of milliseconds that have passed since the consumer last interacted with the server\n\n@reply\n\n@array-reply: a list of consumers.\n\n@examples\n\n```\n> XINFO CONSUMERS mystream mygroup\n1) 1) name\n   2) \"Alice\"\n   3) pending\n   4) (integer) 1\n   5) idle\n   6) (integer) 9104628\n2) 1) name\n   2) \"Bob\"\n   3) pending\n   4) (integer) 1\n   5) idle\n   6) (integer) 83841983\n```\n\n",
                        "return_summary": "",
                        "summary": "List the consumers in a consumer group",
                        "complexity": "O(1)",
                        "arguments": [
                            {
                                "name": "key",
                                "type": "key",
                                "value": "key"
                            },
                            {
                                "name": "groupname",
                                "type": "string",
                                "value": "groupname"
                            }
                        ],
                        "since": "5.0.0",
                        "group": "stream",
                        "arity": 4,
                        "command_flags": [
                            "readonly",
                            "random"
                        ],
                        "acl_categories": [
                            "read",
                            "stream",
                            "slow"
                        ],
                        "key_specs": [
                            {
                                "flags": [
                                    "read"
                                ],
                                "begin_search": {
                                    "index": {
                                        "pos": 2
                                    }
                                },
                                "find_keys": {
                                    "range": {
                                        "lastkey": 0,
                                        "step": 1,
                                        "limit": 0
                                    }
                                }
                            }
                        ],
                        "function": "xinfoCommand",
                        "container": "XINFO"
                    }
                },
                {
                    "STREAM": {
                        "body": "This command returns information about the stream stored at `<key>`.\n\nThe informative details provided by this command are:\n\n* **length**: the number of entries in the stream (see [`XLEN`](./xlen))\n* **radix-tree-keys**: the number of keys in the underlying radix data structure\n* **radix-tree-nodes**: the number of nodes in the underlying radix data structure\n* **groups**: the number of consumer groups defined for the stream\n* **last-generated-id**: the ID of the least-recently entry that was added to the stream\n* **first-entry**: the ID and field-value tuples of the first entry in the stream\n* **last-entry**: the ID and field-value tuples of the last entry in the stream\n\nThe optional `FULL` modifier provides a more verbose reply.\nWhen provided, the `FULL` reply includes an **entries** array that consists of the stream entries (ID and field-value tuples) in ascending order.\nFurthermore, **groups** is also an array, and for each of the consumer groups it consists of the information reported by `XINFO GROUP` and `XINFO CONSUMERS`.\n\nThe `COUNT` option can be used to limit the number of stream and PEL entries that are returned (The first `<count>` entries are returned).\nThe default `COUNT` is 10 and a `COUNT` of 0 means that all entries will be returned (execution time may be long if the stream has a lot of entries).\n\n@examples\n\nDefault reply:\n\n```\n> XINFO STREAM mystream\n 1) length\n 2) (integer) 2\n 3) radix-tree-keys\n 4) (integer) 1\n 5) radix-tree-nodes\n 6) (integer) 2\n 7) groups\n 8) (integer) 2\n 9) last-generated-id\n10) 1538385846314-0\n11) first-entry\n12) 1) 1538385820729-0\n    2) 1) \"foo\"\n       2) \"bar\"\n13) last-entry\n14) 1) 1538385846314-0\n    2) 1) \"field\"\n       2) \"value\"\n```\n\nFull reply:\n\n```\n> XADD mystream * foo bar\n\"1588152471065-0\"\n> XADD mystream * foo bar2\n\"1588152473531-0\"\n> XGROUP CREATE mystream mygroup 0-0\nOK\n> XREADGROUP GROUP mygroup Alice COUNT 1 STREAMS mystream >\n1) 1) \"mystream\"\n   2) 1) 1) \"1588152471065-0\"\n         2) 1) \"foo\"\n            2) \"bar\"\n> XINFO STREAM mystream FULL\n 1) \"length\"\n 2) (integer) 2\n 3) \"radix-tree-keys\"\n 4) (integer) 1\n 5) \"radix-tree-nodes\"\n 6) (integer) 2\n 7) \"last-generated-id\"\n 8) \"1588152473531-0\"\n 9) \"entries\"\n10) 1) 1) \"1588152471065-0\"\n       2) 1) \"foo\"\n          2) \"bar\"\n    2) 1) \"1588152473531-0\"\n       2) 1) \"foo\"\n          2) \"bar2\"\n11) \"groups\"\n12) 1)  1) \"name\"\n        2) \"mygroup\"\n        3) \"last-delivered-id\"\n        4) \"1588152471065-0\"\n        5) \"pel-count\"\n        6) (integer) 1\n        7) \"pending\"\n        8) 1) 1) \"1588152471065-0\"\n              2) \"Alice\"\n              3) (integer) 1588152520299\n              4) (integer) 1\n        9) \"consumers\"\n       10) 1) 1) \"name\"\n              2) \"Alice\"\n              3) \"seen-time\"\n              4) (integer) 1588152520299\n              5) \"pel-count\"\n              6) (integer) 1\n              7) \"pending\"\n              8) 1) 1) \"1588152471065-0\"\n                    2) (integer) 1588152520299\n                    3) (integer) 1\n```\n\n",
                        "": "",
                        "return_types": [
                            {
                                "description": "a list of informational bits",
                                "type": "array"
                            }
                        ],
                        "summary": "Get information about a stream",
                        "complexity": "O(1)",
                        "arguments": [
                            {
                                "name": "key",
                                "type": "key",
                                "value": "key"
                            },
                            {
                                "optional": true,
                                "name": "full",
                                "type": "block",
                                "value": [
                                    {
                                        "token": "FULL",
                                        "name": "full"
                                    },
                                    {
                                        "token": "COUNT",
                                        "optional": true,
                                        "name": "count",
                                        "type": "integer",
                                        "value": "count"
                                    }
                                ]
                            }
                        ],
                        "since": "5.0.0",
                        "group": "stream",
                        "arity": -3,
                        "command_flags": [
                            "readonly"
                        ],
                        "acl_categories": [
                            "read",
                            "stream",
                            "slow"
                        ],
                        "key_specs": [
                            {
                                "flags": [
                                    "read"
                                ],
                                "begin_search": {
                                    "index": {
                                        "pos": 2
                                    }
                                },
                                "find_keys": {
                                    "range": {
                                        "lastkey": 0,
                                        "step": 1,
                                        "limit": 0
                                    }
                                }
                            }
                        ],
                        "function": "xinfoCommand",
                        "container": "XINFO"
                    }
                }
            ],
            "group": "stream",
            "since": "5.0.0"
        }
    },
    {
        "GEODIST": {
            "body": "Return the distance between two members in the geospatial index represented by the sorted set.\n\nGiven a sorted set representing a geospatial index, populated using the [`GEOADD`](./geoadd) command, the command returns the distance between the two specified members in the specified unit.\n\nIf one or both the members are missing, the command returns NULL.\n\nThe unit must be one of the following, and defaults to meters:\n\n* **m** for meters.\n* **km** for kilometers.\n* **mi** for miles.\n* **ft** for feet.\n\nThe distance is computed assuming that the Earth is a perfect sphere, so errors up to 0.5% are possible in edge cases.\n\n@examples\n\n```cli\nGEOADD Sicily 13.361389 38.115556 \"Palermo\" 15.087269 37.502669 \"Catania\"\nGEODIST Sicily Palermo Catania\nGEODIST Sicily Palermo Catania km\nGEODIST Sicily Palermo Catania mi\nGEODIST Sicily Foo Bar\n```\n\n",
            "return_summary": "@bulk-string-reply, specifically:\n\nThe command returns the distance as a double (represented as a string)\nin the specified unit, or NULL if one or both the elements are missing.",
            "": "",
            "summary": "Returns the distance between two members of a geospatial index",
            "complexity": "O(log(N))",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "name": "member1",
                    "type": "string",
                    "value": "member1"
                },
                {
                    "name": "member2",
                    "type": "string",
                    "value": "member2"
                },
                {
                    "optional": true,
                    "name": "m_km_ft_mi",
                    "type": "oneof",
                    "value": [
                        {
                            "name": "__TBD__66__",
                            "token": "m"
                        },
                        {
                            "name": "__TBD__67__",
                            "token": "km"
                        },
                        {
                            "name": "__TBD__68__",
                            "token": "ft"
                        },
                        {
                            "name": "__TBD__69__",
                            "token": "mi"
                        }
                    ]
                }
            ],
            "since": "3.2.0",
            "group": "geo",
            "arity": -4,
            "command_flags": [
                "readonly"
            ],
            "acl_categories": [
                "read",
                "geo",
                "slow"
            ],
            "key_specs": [
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "geodistCommand"
        }
    },
    {
        "SREM": {
            "body": "Remove the specified members from the set stored at `key`.\nSpecified members that are not a member of this set are ignored.\nIf `key` does not exist, it is treated as an empty set and this command returns\n`0`.\n\nAn error is returned when the value stored at `key` is not a set.\n\n@examples\n\n```cli\nSADD myset \"one\"\nSADD myset \"two\"\nSADD myset \"three\"\nSREM myset \"one\"\nSREM myset \"four\"\nSMEMBERS myset\n```\n\n",
            "history": [
                [
                    "2.4",
                    "Accepts multiple `member` arguments."
                ]
            ],
            "": "",
            "return_types": [
                {
                    "description": "the number of members that were removed from the set, not",
                    "type": "integer"
                }
            ],
            "summary": "Remove one or more members from a set",
            "complexity": "O(N) where N is the number of members to be removed.",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "multiple": true,
                    "multiple_token": true,
                    "name": "member",
                    "type": "string",
                    "value": "member"
                }
            ],
            "since": "1.0.0",
            "group": "set",
            "arity": -3,
            "command_flags": [
                "write",
                "fast"
            ],
            "acl_categories": [
                "write",
                "set",
                "fast"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "sremCommand"
        }
    },
    {
        "SORT": {
            "body": "Returns or stores the elements contained in the [list][tdtl], [set][tdts] or\n[sorted set][tdtss] at `key`.\n\nSince Redis 7.0.0, there is also the [`SORT_RO`](./sort_ro) read-only variant of this command.\n\nBy default, sorting is numeric and elements are compared by their value\ninterpreted as double precision floating point number.\nThis is `SORT` in its simplest form:\n\n[tdtl]: /topics/data-types#lists\n[tdts]: /topics/data-types#set\n[tdtss]: /topics/data-types#sorted-sets\n\n```\nSORT mylist\n```\n\nAssuming `mylist` is a list of numbers, this command will return the same list\nwith the elements sorted from small to large.\nIn order to sort the numbers from large to small, use the `DESC` modifier:\n\n```\nSORT mylist DESC\n```\n\nWhen `mylist` contains string values and you want to sort them\nlexicographically, use the `ALPHA` modifier:\n\n```\nSORT mylist ALPHA\n```\n\nRedis is UTF-8 aware, assuming you correctly set the `LC_COLLATE` environment\nvariable.\n\nThe number of returned elements can be limited using the `LIMIT` modifier.\nThis modifier takes the `offset` argument, specifying the number of elements to\nskip and the `count` argument, specifying the number of elements to return from\nstarting at `offset`.\nThe following example will return 10 elements of the sorted version of `mylist`,\nstarting at element 0 (`offset` is zero-based):\n\n```\nSORT mylist LIMIT 0 10\n```\n\nAlmost all modifiers can be used together.\nThe following example will return the first 5 elements, lexicographically sorted\nin descending order:\n\n```\nSORT mylist LIMIT 0 5 ALPHA DESC\n```\n\n## Sorting by external keys\n\nSometimes you want to sort elements using external keys as weights to compare\ninstead of comparing the actual elements in the list, set or sorted set.\nLet's say the list `mylist` contains the elements `1`, `2` and `3` representing\nunique IDs of objects stored in `object_1`, `object_2` and `object_3`.\nWhen these objects have associated weights stored in `weight_1`, `weight_2` and\n`weight_3`, `SORT` can be instructed to use these weights to sort `mylist` with\nthe following statement:\n\n```\nSORT mylist BY weight_*\n```\n\nThe `BY` option takes a pattern (equal to `weight_*` in this example) that is\nused to generate the keys that are used for sorting.\nThese key names are obtained substituting the first occurrence of `*` with the\nactual value of the element in the list (`1`, `2` and `3` in this example).\n\n## Skip sorting the elements\n\nThe `BY` option can also take a non-existent key, which causes `SORT` to skip\nthe sorting operation.\nThis is useful if you want to retrieve external keys (see the `GET` option\nbelow) without the overhead of sorting.\n\n```\nSORT mylist BY nosort\n```\n\n## Retrieving external keys\n\nOur previous example returns just the sorted IDs.\nIn some cases, it is more useful to get the actual objects instead of their IDs\n(`object_1`, `object_2` and `object_3`).\nRetrieving external keys based on the elements in a list, set or sorted set can\nbe done with the following command:\n\n```\nSORT mylist BY weight_* GET object_*\n```\n\nThe `GET` option can be used multiple times in order to get more keys for every\nelement of the original list, set or sorted set.\n\nIt is also possible to `GET` the element itself using the special pattern `#`:\n\n```\nSORT mylist BY weight_* GET object_* GET #\n```\n\n## Storing the result of a SORT operation\n\nBy default, `SORT` returns the sorted elements to the client.\nWith the `STORE` option, the result will be stored as a list at the specified\nkey instead of being returned to the client.\n\n```\nSORT mylist BY weight_* STORE resultkey\n```\n\nAn interesting pattern using `SORT ... STORE` consists in associating an\n[`EXPIRE`](./expire) timeout to the resulting key so that in applications where the result\nof a `SORT` operation can be cached for some time.\nOther clients will use the cached list instead of calling `SORT` for every\nrequest.\nWhen the key will timeout, an updated version of the cache can be created by\ncalling `SORT ... STORE` again.\n\nNote that for correctly implementing this pattern it is important to avoid\nmultiple clients rebuilding the cache at the same time.\nSome kind of locking is needed here (for instance using [`SETNX`](./setnx)).\n\n## Using hashes in `BY` and `GET`\n\nIt is possible to use `BY` and `GET` options against hash fields with the\nfollowing syntax:\n\n```\nSORT mylist BY weight_*->fieldname GET object_*->fieldname\n```\n\nThe string `->` is used to separate the key name from the hash field name.\nThe key is substituted as documented above, and the hash stored at the resulting\nkey is accessed to retrieve the specified hash field.\n\n",
            "return_summary": "@array-reply: without passing the `store` option the command returns a list of sorted elements.\n@integer-reply: when the `store` option is specified the command returns the number of sorted elements in the destination list.",
            "": "",
            "summary": "Sort the elements in a list, set or sorted set",
            "complexity": "O(N+M*log(M)) where N is the number of elements in the list or set to sort, and M the number of returned elements. When the elements are not sorted, complexity is O(N).",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "token": "BY",
                    "optional": true,
                    "name": "pattern",
                    "type": "pattern",
                    "value": "pattern"
                },
                {
                    "token": "LIMIT",
                    "optional": true,
                    "name": "offset_count",
                    "type": "block",
                    "value": [
                        {
                            "name": "offset",
                            "type": "integer",
                            "value": "offset"
                        },
                        {
                            "name": "count",
                            "type": "integer",
                            "value": "count"
                        }
                    ]
                },
                {
                    "token": "GET",
                    "optional": true,
                    "multiple": true,
                    "multiple_token": true,
                    "name": "pattern",
                    "type": "string",
                    "value": "pattern"
                },
                {
                    "optional": true,
                    "name": "asc_desc",
                    "type": "oneof",
                    "value": [
                        {
                            "name": "__TBD__70__",
                            "token": "ASC"
                        },
                        {
                            "name": "__TBD__71__",
                            "token": "DESC"
                        }
                    ]
                },
                {
                    "optional": true,
                    "name": "sorting",
                    "token": "ALPHA"
                },
                {
                    "token": "STORE",
                    "optional": true,
                    "name": "destination",
                    "type": "key",
                    "value": "destination"
                }
            ],
            "since": "1.0.0",
            "group": "generic",
            "arity": -2,
            "command_flags": [
                "write",
                "denyoom"
            ],
            "acl_categories": [
                "write",
                "set",
                "sortedset",
                "list",
                "slow",
                "dangerous"
            ],
            "key_specs": [
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                },
                {
                    "flags": [
                        "write",
                        "incomplete"
                    ],
                    "begin_search": {
                        "unknown": null
                    },
                    "find_keys": {
                        "unknown": null
                    }
                }
            ],
            "function": "sortCommand",
            "get_keys_function": "sortGetKeys"
        }
    },
    {
        "FLUSHALL": {
            "body": "Delete all the keys of all the existing databases, not just the currently selected one.\nThis command never fails.\n\nBy default, `FLUSHALL` will synchronously flush all the databases.\nStarting with Redis 6.2, setting the **lazyfree-lazy-user-flush** configuration directive to \"yes\" changes the default flush mode to asynchronous.\n\nIt is possible to use one of the following modifiers to dictate the flushing mode explicitly:\n\n* `ASYNC`: flushes the databases asynchronously\n* `SYNC`: flushes the databases synchronously\n\nNote: an asynchronous `FLUSHALL` command only deletes keys that were present at the time the command was invoked. Keys created during an asynchronous flush will be unaffected.\n\n",
            "history": [
                [
                    "4.0.0",
                    "Added the `ASYNC` flushing mode modifier."
                ],
                [
                    "6.2.0",
                    "Added the `SYNC` flushing mode modifier and the **lazyfree-lazy-user-flush** configuration directive."
                ]
            ],
            "": "",
            "return_types": [
                {
                    "type": "simple-string"
                }
            ],
            "summary": "Remove all keys from all databases",
            "complexity": "O(N) where N is the total number of keys in all databases",
            "arguments": [
                {
                    "optional": true,
                    "name": "async_sync",
                    "type": "oneof",
                    "value": [
                        {
                            "name": "__TBD__72__",
                            "token": "ASYNC"
                        },
                        {
                            "name": "__TBD__73__",
                            "token": "SYNC"
                        }
                    ]
                }
            ],
            "since": "1.0.0",
            "group": "server",
            "arity": -1,
            "command_flags": [
                "write"
            ],
            "acl_categories": [
                "keyspace",
                "write",
                "slow",
                "dangerous"
            ],
            "function": "flushallCommand"
        }
    },
    {
        "POST": {
            "arity": -1,
            "command_flags": [
                "readonly",
                "loading",
                "stale"
            ],
            "acl_categories": [
                "read",
                "slow"
            ],
            "function": "securityWarningCommand",
            "group": "server",
            "internal": true
        }
    },
    {
        "ECHO": {
            "body": "Returns `message`.\n\n@examples\n\n```cli\nECHO \"Hello World!\"\n```\n\n",
            "": "",
            "return_types": [
                {
                    "type": "bulk-string"
                }
            ],
            "summary": "Echo the given string",
            "arguments": [
                {
                    "name": "message",
                    "type": "string",
                    "value": "message"
                }
            ],
            "since": "1.0.0",
            "group": "connection",
            "arity": 2,
            "command_flags": [
                "fast"
            ],
            "acl_categories": [
                "fast",
                "connection"
            ],
            "function": "echoCommand"
        }
    },
    {
        "ZUNIONSTORE": {
            "body": "Computes the union of `numkeys` sorted sets given by the specified keys, and\nstores the result in `destination`.\nIt is mandatory to provide the number of input keys (`numkeys`) before passing\nthe input keys and the other (optional) arguments.\n\nBy default, the resulting score of an element is the sum of its scores in the\nsorted sets where it exists.\n\nUsing the `WEIGHTS` option, it is possible to specify a multiplication factor\nfor each input sorted set.\nThis means that the score of every element in every input sorted set is\nmultiplied by this factor before being passed to the aggregation function.\nWhen `WEIGHTS` is not given, the multiplication factors default to `1`.\n\nWith the `AGGREGATE` option, it is possible to specify how the results of the\nunion are aggregated.\nThis option defaults to `SUM`, where the score of an element is summed across\nthe inputs where it exists.\nWhen this option is set to either `MIN` or `MAX`, the resulting set will contain\nthe minimum or maximum score of an element across the inputs where it exists.\n\nIf `destination` already exists, it is overwritten.\n\n@examples\n\n```cli\nZADD zset1 1 \"one\"\nZADD zset1 2 \"two\"\nZADD zset2 1 \"one\"\nZADD zset2 2 \"two\"\nZADD zset2 3 \"three\"\nZUNIONSTORE out 2 zset1 zset2 WEIGHTS 2 3\nZRANGE out 0 -1 WITHSCORES\n```\n\n",
            "": "",
            "return_types": [
                {
                    "description": "the number of elements in the resulting sorted set at",
                    "type": "integer"
                }
            ],
            "summary": "Add multiple sorted sets and store the resulting sorted set in a new key",
            "complexity": "O(N)+O(M log(M)) with N being the sum of the sizes of the input sorted sets, and M being the number of elements in the resulting sorted set.",
            "arguments": [
                {
                    "name": "destination",
                    "type": "key",
                    "value": "destination"
                },
                {
                    "name": "numkeys",
                    "type": "integer",
                    "value": "numkeys"
                },
                {
                    "multiple": true,
                    "multiple_token": true,
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "token": "WEIGHTS",
                    "optional": true,
                    "multiple": true,
                    "name": "weight",
                    "type": "integer",
                    "value": "weight"
                },
                {
                    "token": "AGGREGATE",
                    "optional": true,
                    "name": "sum_min_max",
                    "type": "oneof",
                    "value": [
                        {
                            "name": "__TBD__74__",
                            "token": "SUM"
                        },
                        {
                            "name": "__TBD__75__",
                            "token": "MIN"
                        },
                        {
                            "name": "__TBD__76__",
                            "token": "MAX"
                        }
                    ]
                }
            ],
            "since": "2.0.0",
            "group": "sorted_set",
            "arity": -4,
            "command_flags": [
                "write",
                "denyoom"
            ],
            "acl_categories": [
                "write",
                "sortedset",
                "slow"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                },
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 2
                        }
                    },
                    "find_keys": {
                        "keynum": {
                            "keynumidx": 0,
                            "firstkey": 1,
                            "step": 1
                        }
                    }
                }
            ],
            "function": "zunionstoreCommand",
            "get_keys_function": "zunionInterDiffStoreGetKeys"
        }
    },
    {
        "EVALSHA": {
            "body": "Evaluates a script cached on the server side by its SHA1 digest.\nScripts are cached on the server side using the `SCRIPT LOAD` command.\nThe command is otherwise identical to [`EVAL`](./eval).\n\n",
            "return_summary": "",
            "summary": "Execute a Lua script server side",
            "complexity": "Depends on the script that is executed.",
            "arguments": [
                {
                    "name": "sha1",
                    "type": "string",
                    "value": "sha1"
                },
                {
                    "name": "numkeys",
                    "type": "integer",
                    "value": "numkeys"
                },
                {
                    "optional": true,
                    "multiple": true,
                    "multiple_token": true,
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "optional": true,
                    "multiple": true,
                    "multiple_token": true,
                    "name": "arg",
                    "type": "string",
                    "value": "arg"
                }
            ],
            "since": "2.6.0",
            "group": "scripting",
            "arity": -3,
            "command_flags": [
                "noscript",
                "skip_monitor",
                "may_replicate"
            ],
            "acl_categories": [
                "slow",
                "scripting"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write",
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 2
                        }
                    },
                    "find_keys": {
                        "keynum": {
                            "keynumidx": 0,
                            "firstkey": 1,
                            "step": 1
                        }
                    }
                }
            ],
            "function": "evalShaCommand",
            "get_keys_function": "evalGetKeys"
        }
    },
    {
        "TYPE": {
            "body": "Returns the string representation of the type of the value stored at `key`.\nThe different types that can be returned are: `string`, `list`, `set`, `zset`,\n`hash` and `stream`.\n\n@examples\n\n```cli\nSET key1 \"value\"\nLPUSH key2 \"value\"\nSADD key3 \"value\"\nTYPE key1\nTYPE key2\nTYPE key3\n```\n\n",
            "": "",
            "return_types": [
                {
                    "description": "type of `key`, or `none` when `key` does not exist.",
                    "type": "simple-string"
                }
            ],
            "summary": "Determine the type stored at key",
            "complexity": "O(1)",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                }
            ],
            "since": "1.0.0",
            "group": "generic",
            "arity": 2,
            "command_flags": [
                "readonly",
                "fast"
            ],
            "acl_categories": [
                "keyspace",
                "read",
                "fast"
            ],
            "key_specs": [
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "typeCommand"
        }
    },
    {
        "ZREMRANGEBYSCORE": {
            "body": "Removes all elements in the sorted set stored at `key` with a score between\n`min` and `max` (inclusive).\n\nSince version 2.1.6, `min` and `max` can be exclusive, following the syntax of\n[`ZRANGEBYSCORE`](./zrangebyscore).\n\n@examples\n\n```cli\nZADD myzset 1 \"one\"\nZADD myzset 2 \"two\"\nZADD myzset 3 \"three\"\nZREMRANGEBYSCORE myzset -inf (2\nZRANGE myzset 0 -1 WITHSCORES\n```\n\n",
            "": "",
            "return_types": [
                {
                    "description": "the number of elements removed.",
                    "type": "integer"
                }
            ],
            "summary": "Remove all members in a sorted set within the given scores",
            "complexity": "O(log(N)+M) with N being the number of elements in the sorted set and M the number of elements removed by the operation.",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "name": "min",
                    "type": "double",
                    "value": "min"
                },
                {
                    "name": "max",
                    "type": "double",
                    "value": "max"
                }
            ],
            "since": "1.2.0",
            "group": "sorted_set",
            "arity": 4,
            "command_flags": [
                "write"
            ],
            "acl_categories": [
                "write",
                "sortedset",
                "slow"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "zremrangebyscoreCommand"
        }
    },
    {
        "ZINCRBY": {
            "body": "Increments the score of `member` in the sorted set stored at `key` by\n`increment`.\nIf `member` does not exist in the sorted set, it is added with `increment` as\nits score (as if its previous score was `0.0`).\nIf `key` does not exist, a new sorted set with the specified `member` as its\nsole member is created.\n\nAn error is returned when `key` exists but does not hold a sorted set.\n\nThe `score` value should be the string representation of a numeric value, and\naccepts double precision floating point numbers.\nIt is possible to provide a negative value to decrement the score.\n\n@examples\n\n```cli\nZADD myzset 1 \"one\"\nZADD myzset 2 \"two\"\nZINCRBY myzset 2 \"one\"\nZRANGE myzset 0 -1 WITHSCORES\n```\n\n",
            "": "",
            "return_types": [
                {
                    "description": "the new score of `member` (a double precision floating point",
                    "type": "bulk-string"
                }
            ],
            "summary": "Increment the score of a member in a sorted set",
            "complexity": "O(log(N)) where N is the number of elements in the sorted set.",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "name": "increment",
                    "type": "integer",
                    "value": "increment"
                },
                {
                    "name": "member",
                    "type": "string",
                    "value": "member"
                }
            ],
            "since": "1.2.0",
            "group": "sorted_set",
            "arity": 4,
            "command_flags": [
                "write",
                "denyoom",
                "fast"
            ],
            "acl_categories": [
                "write",
                "sortedset",
                "fast"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "zincrbyCommand"
        }
    },
    {
        "XRANGE": {
            "body": "The command returns the stream entries matching a given range of IDs.\nThe range is specified by a minimum and maximum ID. All the entries having\nan ID between the two specified or exactly one of the two IDs specified\n(closed interval) are returned.\n\nThe `XRANGE` command has a number of applications:\n\n* Returning items in a specific time range. This is possible because\n  Stream IDs are [related to time](/topics/streams-intro).\n* Iterating a stream incrementally, returning just\n  a few items at every iteration. However it is semantically much more\n  robust than the [`SCAN`](./scan) family of functions.\n* Fetching a single entry from a stream, providing the ID of the entry\n  to fetch two times: as start and end of the query interval.\n\nThe command also has a reciprocal command returning items in the\nreverse order, called [`XREVRANGE`](./xrevrange), which is otherwise identical.\n\n## `-` and `+` special IDs\n\nThe `-` and `+` special IDs mean respectively the minimum ID possible\nand the maximum ID possible inside a stream, so the following command\nwill just return every entry in the stream:\n\n```\n> XRANGE somestream - +\n1) 1) 1526985054069-0\n   2) 1) \"duration\"\n      2) \"72\"\n      3) \"event-id\"\n      4) \"9\"\n      5) \"user-id\"\n      6) \"839248\"\n2) 1) 1526985069902-0\n   2) 1) \"duration\"\n      2) \"415\"\n      3) \"event-id\"\n      4) \"2\"\n      5) \"user-id\"\n      6) \"772213\"\n... other entries here ...\n```\n\nThe `-` ID is effectively just exactly as specifying `0-0`, while\n`+` is equivalent to `18446744073709551615-18446744073709551615`, however\nthey are nicer to type.\n\n## Incomplete IDs\n\nStream IDs are composed of two parts, a Unix millisecond time stamp and a\nsequence number for entries inserted in the same millisecond. It is possible\nto use `XRANGE` specifying just the first part of the ID, the millisecond time,\nlike in the following example:\n\n```\n> XRANGE somestream 1526985054069 1526985055069\n```\n\nIn this case, `XRANGE` will auto-complete the start interval with `-0`\nand end interval with `-18446744073709551615`, in order to return all the\nentries that were generated between a given millisecond and the end of\nthe other specified millisecond. This also means that repeating the same\nmillisecond two times, we get all the entries within such millisecond,\nbecause the sequence number range will be from zero to the maximum.\n\nUsed in this way `XRANGE` works as a range query command to obtain entries\nin a specified time. This is very handy in order to access the history\nof past events in a stream.\n\n## Exclusive ranges\n\nThe range is close (inclusive) by default, meaning that the reply can include\nentries with IDs matching the query's start and end intervals. It is possible\nto specify an open interval (exclusive) by prefixing the ID with the\ncharacter `(`. This is useful for iterating the stream, as explained below.\n\n## Returning a maximum number of entries\n\nUsing the **COUNT** option it is possible to reduce the number of entries\nreported. This is a very important feature even if it may look marginal,\nbecause it allows, for instance, to model operations such as *give me\nthe entry greater or equal to the following*:\n\n```\n> XRANGE somestream 1526985054069-0 + COUNT 1\n1) 1) 1526985054069-0\n   2) 1) \"duration\"\n      2) \"72\"\n      3) \"event-id\"\n      4) \"9\"\n      5) \"user-id\"\n      6) \"839248\"\n```\n\nIn the above case the entry `1526985054069-0` exists, otherwise the server\nwould have sent us the next one. Using `COUNT` is also the base in order to\nuse `XRANGE` as an iterator.\n\n## Iterating a stream\n\nIn order to iterate a stream, we can proceed as follows. Let's assume that\nwe want two elements per iteration. We start fetching the first two\nelements, which is trivial:\n\n```\n> XRANGE writers - + COUNT 2\n1) 1) 1526985676425-0\n   2) 1) \"name\"\n      2) \"Virginia\"\n      3) \"surname\"\n      4) \"Woolf\"\n2) 1) 1526985685298-0\n   2) 1) \"name\"\n      2) \"Jane\"\n      3) \"surname\"\n      4) \"Austen\"\n```\n\nThen instead of starting the iteration again from `-`, as the start\nof the range we use the entry ID of the *last* entry returned by the\nprevious `XRANGE` call as an exclusive interval.\n\nThe ID of the last entry is `1526985685298-0`, so we just prefix it\nwith a '(', and continue our iteration:\n\n```\n> XRANGE writers (1526985685298-0 + COUNT 2\n1) 1) 1526985691746-0\n   2) 1) \"name\"\n      2) \"Toni\"\n      3) \"surname\"\n      4) \"Morrison\"\n2) 1) 1526985712947-0\n   2) 1) \"name\"\n      2) \"Agatha\"\n      3) \"surname\"\n      4) \"Christie\"\n```\n\nAnd so forth. Eventually this will allow to visit all the entries in the\nstream. Obviously, we can start the iteration from any ID, or even from\na specific time, by providing a given incomplete start ID. Moreover, we\ncan limit the iteration to a given ID or time, by providing an end\nID or incomplete ID instead of `+`.\n\nThe command [`XREAD`](./xread) is also able to iterate the stream.\nThe command [`XREVRANGE`](./xrevrange) can iterate the stream reverse, from higher IDs\n(or times) to lower IDs (or times).\n\n### Iterating with earlier versions of Redis\n\nWhile exclusive range intervals are only available from Redis 6.2, it is still\npossible to use a similar stream iteration pattern with earlier versions. You\nstart fetching from the stream the same way as described above to obtain the\nfirst entries.\n\nFor the subsequent calls, you'll need to programmatically advance the last\nentry's ID returned. Most Redis client should abstract this detail, but the\nimplementation can also be in the application if needed. In the example above,\nthis means incrementing the sequence of `1526985685298-0` by one, from 0 to 1.\nThe second call would, therefore, be:\n\n```\n> XRANGE writers 1526985685298-1 + COUNT 2\n1) 1) 1526985691746-0\n   2) 1) \"name\"\n      2) \"Toni\"\n...\n```\n\nAlso, note that once the sequence part of the last ID equals \n18446744073709551615, you'll need to increment the timestamp and reset the\nsequence part to 0. For example, incrementing the ID\n`1526985685298-18446744073709551615` should result in `1526985685299-0`.\n\nA symmetrical pattern applies to iterating the stream with [`XREVRANGE`](./xrevrange). The\nonly difference is that the client needs to decrement the ID for the subsequent\ncalls. When decrementing an ID with a sequence part of 0, the timestamp needs\nto be decremented by 1 and the sequence set to 18446744073709551615.\n\n## Fetching single items\n\nIf you look for an `XGET` command you'll be disappointed because `XRANGE`\nis effectively the way to go in order to fetch a single entry from a\nstream. All you have to do is to specify the ID two times in the arguments\nof XRANGE:\n\n```\n> XRANGE mystream 1526984818136-0 1526984818136-0\n1) 1) 1526984818136-0\n   2) 1) \"duration\"\n      2) \"1532\"\n      3) \"event-id\"\n      4) \"5\"\n      5) \"user-id\"\n      6) \"7782813\"\n```\n\n## Additional information about streams\n\nFor further information about Redis streams please check our\n[introduction to Redis Streams document](/topics/streams-intro).\n\n@examples\n\n```cli\nXADD writers * name Virginia surname Woolf\nXADD writers * name Jane surname Austen\nXADD writers * name Toni surname Morrison\nXADD writers * name Agatha surname Christie\nXADD writers * name Ngozi surname Adichie\nXLEN writers\nXRANGE writers - + COUNT 2\n```\n\n",
            "return_summary": "@array-reply, specifically:\n\nThe command returns the entries with IDs matching the specified range.\nThe returned entries are complete, that means that the ID and all the fields\nthey are composed are returned. Moreover, the entries are returned with\ntheir fields and values in the exact same order as [`XADD`](./xadd) added them.",
            "": "",
            "summary": "Return a range of elements in a stream, with IDs matching the specified IDs interval",
            "complexity": "O(N) with N being the number of elements being returned. If N is constant (e.g. always asking for the first 10 elements with COUNT), you can consider it O(1).",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "name": "start",
                    "type": "string",
                    "value": "start"
                },
                {
                    "name": "end",
                    "type": "string",
                    "value": "end"
                },
                {
                    "token": "COUNT",
                    "optional": true,
                    "name": "count",
                    "type": "integer",
                    "value": "count"
                }
            ],
            "since": "5.0.0",
            "group": "stream",
            "arity": -4,
            "command_flags": [
                "readonly"
            ],
            "acl_categories": [
                "read",
                "stream",
                "slow"
            ],
            "key_specs": [
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "xrangeCommand"
        }
    },
    {
        "MGET": {
            "body": "Returns the values of all specified keys.\nFor every key that does not hold a string value or does not exist, the special\nvalue `nil` is returned.\nBecause of this, the operation never fails.\n\n@examples\n\n```cli\nSET key1 \"Hello\"\nSET key2 \"World\"\nMGET key1 key2 nonexisting\n```\n\n",
            "": "",
            "return_types": [
                {
                    "description": "list of values at the specified keys.",
                    "type": "array"
                }
            ],
            "summary": "Get the values of all the given keys",
            "complexity": "O(N) where N is the number of keys to retrieve.",
            "arguments": [
                {
                    "multiple": true,
                    "multiple_token": true,
                    "name": "key",
                    "type": "key",
                    "value": "key"
                }
            ],
            "since": "1.0.0",
            "group": "string",
            "arity": -2,
            "command_flags": [
                "readonly",
                "fast"
            ],
            "acl_categories": [
                "read",
                "string",
                "fast"
            ],
            "key_specs": [
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": -1,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "mgetCommand"
        }
    },
    {
        "EXEC": {
            "body": "Executes all previously queued commands in a [transaction][tt] and restores the\nconnection state to normal.\n\n[tt]: /topics/transactions\n\nWhen using [`WATCH`](./watch), `EXEC` will execute commands only if the watched keys were\nnot modified, allowing for a [check-and-set mechanism][ttc].\n\n[ttc]: /topics/transactions#cas\n\n",
            "return_summary": "@array-reply: each element being the reply to each of the commands in the\natomic transaction.\n\nWhen using [`WATCH`](./watch), `EXEC` can return a @nil-reply if the execution was aborted.",
            "": "",
            "summary": "Execute all commands issued after MULTI",
            "since": "1.2.0",
            "group": "transactions",
            "arity": 1,
            "command_flags": [
                "noscript",
                "loading",
                "stale",
                "skip_slowlog"
            ],
            "acl_categories": [
                "slow",
                "transaction"
            ],
            "function": "execCommand"
        }
    },
    {
        "INCR": {
            "body": "Increments the number stored at `key` by one.\nIf the key does not exist, it is set to `0` before performing the operation.\nAn error is returned if the key contains a value of the wrong type or contains a\nstring that can not be represented as integer.\nThis operation is limited to 64 bit signed integers.\n\n**Note**: this is a string operation because Redis does not have a dedicated\ninteger type.\nThe string stored at the key is interpreted as a base-10 **64 bit signed\ninteger** to execute the operation.\n\nRedis stores integers in their integer representation, so for string values\nthat actually hold an integer, there is no overhead for storing the string\nrepresentation of the integer.\n\n@examples\n\n```cli\nSET mykey \"10\"\nINCR mykey\nGET mykey\n```\n\n## Pattern: Counter\n\nThe counter pattern is the most obvious thing you can do with Redis atomic\nincrement operations.\nThe idea is simply send an `INCR` command to Redis every time an operation\noccurs.\nFor instance in a web application we may want to know how many page views this\nuser did every day of the year.\n\nTo do so the web application may simply increment a key every time the user\nperforms a page view, creating the key name concatenating the User ID and a\nstring representing the current date.\n\nThis simple pattern can be extended in many ways:\n\n* It is possible to use `INCR` and [`EXPIRE`](./expire) together at every page view to have\n  a counter counting only the latest N page views separated by less than the\n  specified amount of seconds.\n* A client may use GETSET in order to atomically get the current counter value\n  and reset it to zero.\n* Using other atomic increment/decrement commands like [`DECR`](./decr) or [`INCRBY`](./incrby) it\n  is possible to handle values that may get bigger or smaller depending on the\n  operations performed by the user.\n  Imagine for instance the score of different users in an online game.\n\n## Pattern: Rate limiter\n\nThe rate limiter pattern is a special counter that is used to limit the rate at\nwhich an operation can be performed.\nThe classical materialization of this pattern involves limiting the number of\nrequests that can be performed against a public API.\n\nWe provide two implementations of this pattern using `INCR`, where we assume\nthat the problem to solve is limiting the number of API calls to a maximum of\n_ten requests per second per IP address_.\n\n## Pattern: Rate limiter 1\n\nThe more simple and direct implementation of this pattern is the following:\n\n```\nFUNCTION LIMIT_API_CALL(ip)\nts = CURRENT_UNIX_TIME()\nkeyname = ip+\":\"+ts\nMULTI\n    INCR(keyname)\n    EXPIRE(keyname,10)\nEXEC\ncurrent = RESPONSE_OF_INCR_WITHIN_MULTI\nIF current > 10 THEN\n    ERROR \"too many requests per second\"\nELSE\n    PERFORM_API_CALL()\nEND\n```\n\nBasically we have a counter for every IP, for every different second.\nBut this counters are always incremented setting an expire of 10 seconds so that\nthey'll be removed by Redis automatically when the current second is a different\none.\n\nNote the used of [`MULTI`](./multi) and [`EXEC`](./exec) in order to make sure that we'll both\nincrement and set the expire at every API call.\n\n## Pattern: Rate limiter 2\n\nAn alternative implementation uses a single counter, but is a bit more complex\nto get it right without race conditions.\nWe'll examine different variants.\n\n```\nFUNCTION LIMIT_API_CALL(ip):\ncurrent = GET(ip)\nIF current != NULL AND current > 10 THEN\n    ERROR \"too many requests per second\"\nELSE\n    value = INCR(ip)\n    IF value == 1 THEN\n        EXPIRE(ip,1)\n    END\n    PERFORM_API_CALL()\nEND\n```\n\nThe counter is created in a way that it only will survive one second, starting\nfrom the first request performed in the current second.\nIf there are more than 10 requests in the same second the counter will reach a\nvalue greater than 10, otherwise it will expire and start again from 0.\n\n**In the above code there is a race condition**.\nIf for some reason the client performs the `INCR` command but does not perform\nthe [`EXPIRE`](./expire) the key will be leaked until we'll see the same IP address again.\n\nThis can be fixed easily turning the `INCR` with optional [`EXPIRE`](./expire) into a Lua\nscript that is send using the [`EVAL`](./eval) command (only available since Redis version\n2.6).\n\n```\nlocal current\ncurrent = redis.call(\"incr\",KEYS[1])\nif current == 1 then\n    redis.call(\"expire\",KEYS[1],1)\nend\n```\n\nThere is a different way to fix this issue without using scripting, but using\nRedis lists instead of counters.\nThe implementation is more complex and uses more advanced features but has the\nadvantage of remembering the IP addresses of the clients currently performing an\nAPI call, that may be useful or not depending on the application.\n\n```\nFUNCTION LIMIT_API_CALL(ip)\ncurrent = LLEN(ip)\nIF current > 10 THEN\n    ERROR \"too many requests per second\"\nELSE\n    IF EXISTS(ip) == FALSE\n        MULTI\n            RPUSH(ip,ip)\n            EXPIRE(ip,1)\n        EXEC\n    ELSE\n        RPUSHX(ip,ip)\n    END\n    PERFORM_API_CALL()\nEND\n```\n\nThe [`RPUSHX`](./rpushx) command only pushes the element if the key already exists.\n\nNote that we have a race here, but it is not a problem: [`EXISTS`](./exists) may return\nfalse but the key may be created by another client before we create it inside\nthe [`MULTI`](./multi) / [`EXEC`](./exec) block.\nHowever this race will just miss an API call under rare conditions, so the rate\nlimiting will still work correctly.\n\n",
            "": "",
            "return_types": [
                {
                    "description": "the value of `key` after the increment",
                    "type": "integer"
                }
            ],
            "summary": "Increment the integer value of a key by one",
            "complexity": "O(1)",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                }
            ],
            "since": "1.0.0",
            "group": "string",
            "arity": 2,
            "command_flags": [
                "write",
                "denyoom",
                "fast"
            ],
            "acl_categories": [
                "write",
                "string",
                "fast"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "incrCommand"
        }
    },
    {
        "XREAD": {
            "body": "Read data from one or multiple streams, only returning entries with an\nID greater than the last received ID reported by the caller.\nThis command has an option to block if items are not available, in a similar\nfashion to [`BRPOP`](./brpop) or [`BZPOPMIN`](./bzpopmin) and others.\n\nPlease note that before reading this page, if you are new to streams,\nwe recommend to read [our introduction to Redis Streams](/topics/streams-intro).\n\n## Non-blocking usage\n\nIf the **BLOCK** option is not used, the command is synchronous, and can\nbe considered somewhat related to [`XRANGE`](./xrange): it will return a range of items\ninside streams, however it has two fundamental differences compared to [`XRANGE`](./xrange)\neven if we just consider the synchronous usage:\n\n* This command can be called with multiple streams if we want to read at\n  the same time from a number of keys. This is a key feature of `XREAD` because\n  especially when blocking with **BLOCK**, to be able to listen with a single\n  connection to multiple keys is a vital feature.\n* While [`XRANGE`](./xrange) returns items in a range of IDs, `XREAD` is more suited in\n  order to consume the stream starting from the first entry which is greater\n  than any other entry we saw so far. So what we pass to `XREAD` is, for each\n  stream, the ID of the last element that we received from that stream.\n\nFor example, if I have two streams `mystream` and `writers`, and I want to\nread data from both the streams starting from the first element they contain,\nI could call `XREAD` like in the following example.\n\nNote: we use the **COUNT** option in the example, so that for each stream\nthe call will return at maximum two elements per stream.\n\n```\n> XREAD COUNT 2 STREAMS mystream writers 0-0 0-0\n1) 1) \"mystream\"\n   2) 1) 1) 1526984818136-0\n         2) 1) \"duration\"\n            2) \"1532\"\n            3) \"event-id\"\n            4) \"5\"\n            5) \"user-id\"\n            6) \"7782813\"\n      2) 1) 1526999352406-0\n         2) 1) \"duration\"\n            2) \"812\"\n            3) \"event-id\"\n            4) \"9\"\n            5) \"user-id\"\n            6) \"388234\"\n2) 1) \"writers\"\n   2) 1) 1) 1526985676425-0\n         2) 1) \"name\"\n            2) \"Virginia\"\n            3) \"surname\"\n            4) \"Woolf\"\n      2) 1) 1526985685298-0\n         2) 1) \"name\"\n            2) \"Jane\"\n            3) \"surname\"\n            4) \"Austen\"\n```\n\nThe **STREAMS** option is mandatory and MUST be the final option because\nsuch option gets a variable length of argument in the following format:\n\n    STREAMS key_1 key_2 key_3 ... key_N ID_1 ID_2 ID_3 ... ID_N\n\nSo we start with a list of keys, and later continue with all the associated\nIDs, representing *the last ID we received for that stream*, so that the\ncall will serve us only greater IDs from the same stream.\n\nFor instance in the above example, the last items that we received\nfor the stream `mystream` has ID `1526999352406-0`, while for the\nstream `writers` has the ID `1526985685298-0`.\n\nTo continue iterating the two streams I'll call:\n\n```\n> XREAD COUNT 2 STREAMS mystream writers 1526999352406-0 1526985685298-0\n1) 1) \"mystream\"\n   2) 1) 1) 1526999626221-0\n         2) 1) \"duration\"\n            2) \"911\"\n            3) \"event-id\"\n            4) \"7\"\n            5) \"user-id\"\n            6) \"9488232\"\n2) 1) \"writers\"\n   2) 1) 1) 1526985691746-0\n         2) 1) \"name\"\n            2) \"Toni\"\n            3) \"surname\"\n            4) \"Morrison\"\n      2) 1) 1526985712947-0\n         2) 1) \"name\"\n            2) \"Agatha\"\n            3) \"surname\"\n            4) \"Christie\"\n```\n\nAnd so forth. Eventually, the call will not return any item, but just an\nempty array, then we know that there is nothing more to fetch from our\nstream (and we would have to retry the operation, hence this command\nalso supports a blocking mode).\n\n## Incomplete IDs\n\nTo use incomplete IDs is valid, like it is valid for [`XRANGE`](./xrange). However\nhere the sequence part of the ID, if missing, is always interpreted as\nzero, so the command:\n\n```\n> XREAD COUNT 2 STREAMS mystream writers 0 0\n```\n\nis exactly equivalent to\n\n```\n> XREAD COUNT 2 STREAMS mystream writers 0-0 0-0\n```\n\n## Blocking for data\n\nIn its synchronous form, the command can get new data as long as there\nare more items available. However, at some point, we'll have to wait for\nproducers of data to use [`XADD`](./xadd) to push new entries inside the streams\nwe are consuming. In order to avoid polling at a fixed or adaptive interval\nthe command is able to block if it could not return any data, according\nto the specified streams and IDs, and automatically unblock once one of\nthe requested keys accept data.\n\nIt is important to understand that this command *fans out* to all the\nclients that are waiting for the same range of IDs, so every consumer will\nget a copy of the data, unlike to what happens when blocking list pop\noperations are used.\n\nIn order to block, the **BLOCK** option is used, together with the number\nof milliseconds we want to block before timing out. Normally Redis blocking\ncommands take timeouts in seconds, however this command takes a millisecond\ntimeout, even if normally the server will have a timeout resolution near\nto 0.1 seconds. This time it is possible to block for a shorter time in\ncertain use cases, and if the server internals will improve over time, it is\npossible that the resolution of timeouts will improve.\n\nWhen the **BLOCK** command is passed, but there is data to return at\nleast in one of the streams passed, the command is executed synchronously\n*exactly like if the BLOCK option would be missing*.\n\nThis is an example of blocking invocation, where the command later returns\na null reply because the timeout has elapsed without new data arriving:\n\n```\n> XREAD BLOCK 1000 STREAMS mystream 1526999626221-0\n(nil)\n```\n\n## The special `$` ID.\n\nWhen blocking sometimes we want to receive just entries that are added\nto the stream via [`XADD`](./xadd) starting from the moment we block. In such a case\nwe are not interested in the history of already added entries. For\nthis use case, we would have to check the stream top element ID, and use\nsuch ID in the `XREAD` command line. This is not clean and requires to\ncall other commands, so instead it is possible to use the special `$`\nID to signal the stream that we want only the new things.\n\nIt is **very important** to understand that you should use the `$`\nID only for the first call to `XREAD`. Later the ID should be the one\nof the last reported item in the stream, otherwise you could miss all\nthe entries that are added in between.\n\nThis is how a typical `XREAD` call looks like in the first iteration\nof a consumer willing to consume only new entries:\n\n```\n> XREAD BLOCK 5000 COUNT 100 STREAMS mystream $\n```\n\nOnce we get some replies, the next call will be something like:\n\n```\n> XREAD BLOCK 5000 COUNT 100 STREAMS mystream 1526999644174-3\n```\n\nAnd so forth.\n\n## How multiple clients blocked on a single stream are served\n\nBlocking list operations on lists or sorted sets have a *pop* behavior.\nBasically, the element is removed from the list or sorted set in order\nto be returned to the client. In this scenario you want the items\nto be consumed in a fair way, depending on the moment clients blocked\non a given key arrived. Normally Redis uses the FIFO semantics in this\nuse cases.\n\nHowever note that with streams this is not a problem: stream entries\nare not removed from the stream when clients are served, so every\nclient waiting will be served as soon as an [`XADD`](./xadd) command provides\ndata to the stream.\n\n",
            "return_summary": "@array-reply, specifically:\n\nThe command returns an array of results: each element of the returned\narray is an array composed of a two element containing the key name and\nthe entries reported for that key. The entries reported are full stream\nentries, having IDs and the list of all the fields and values. Field and\nvalues are guaranteed to be reported in the same order they were added\nby [`XADD`](./xadd).\n\nWhen **BLOCK** is used, on timeout a null reply is returned.\n\nReading the [Redis Streams introduction](/topics/streams-intro) is highly\nsuggested in order to understand more about the streams overall behavior\nand semantics.",
            "": "",
            "summary": "Return never seen elements in multiple streams, with IDs greater than the ones reported by the caller for each stream. Can block.",
            "complexity": "For each stream mentioned: O(N) with N being the number of elements being returned, it means that XREAD-ing with a fixed COUNT is O(1). Note that when the BLOCK option is used, XADD will pay O(M) time in order to serve the M clients blocked on the stream getting new data.",
            "arguments": [
                {
                    "token": "COUNT",
                    "optional": true,
                    "name": "count",
                    "type": "integer",
                    "value": "count"
                },
                {
                    "token": "BLOCK",
                    "optional": true,
                    "name": "milliseconds",
                    "type": "integer",
                    "value": "milliseconds"
                },
                {
                    "name": "streams",
                    "token": "STREAMS"
                },
                {
                    "multiple": true,
                    "multiple_token": true,
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "multiple": true,
                    "multiple_token": true,
                    "name": "ID",
                    "type": "string",
                    "value": "ID"
                }
            ],
            "since": "5.0.0",
            "group": "stream",
            "arity": -4,
            "command_flags": [
                "readonly"
            ],
            "acl_categories": [
                "read",
                "stream",
                "slow",
                "blocking"
            ],
            "key_specs": [
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "keyword": {
                            "keyword": "STREAMS",
                            "startfrom": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": -1,
                            "step": 1,
                            "limit": 2
                        }
                    }
                }
            ],
            "function": "xreadCommand",
            "get_keys_function": "xreadGetKeys"
        }
    },
    {
        "RESTORE": {
            "body": "Create a key associated with a value that is obtained by deserializing the\nprovided serialized value (obtained via [`DUMP`](./dump)).\n\nIf `ttl` is 0 the key is created without any expire, otherwise the specified\nexpire time (in milliseconds) is set.\n\nIf the `ABSTTL` modifier was used, `ttl` should represent an absolute\n[Unix timestamp][hewowu] (in milliseconds) in which the key will expire.\n(Redis 5.0 or greater).\n\n[hewowu]: http://en.wikipedia.org/wiki/Unix_time\n\nFor eviction purposes, you may use the `IDLETIME` or `FREQ` modifiers. See\n[`OBJECT`](./object) for more information (Redis 5.0 or greater).\n\n`RESTORE` will return a \"Target key name is busy\" error when `key` already\nexists unless you use the `REPLACE` modifier (Redis 3.0 or greater).\n\n`RESTORE` checks the RDB version and data checksum.\nIf they don't match an error is returned.\n\n@examples\n\n```\nredis> DEL mykey\n0\nredis> RESTORE mykey 0 \"\\n\\x17\\x17\\x00\\x00\\x00\\x12\\x00\\x00\\x00\\x03\\x00\\\n                        x00\\xc0\\x01\\x00\\x04\\xc0\\x02\\x00\\x04\\xc0\\x03\\x00\\\n                        xff\\x04\\x00u#<\\xc0;.\\xe9\\xdd\"\nOK\nredis> TYPE mykey\nlist\nredis> LRANGE mykey 0 -1\n1) \"1\"\n2) \"2\"\n3) \"3\"\n```\n\n",
            "": "",
            "return_types": [
                {
                    "description": "The command returns OK on success.",
                    "type": "simple-string"
                }
            ],
            "summary": "Create a key using the provided serialized value, previously obtained using DUMP.",
            "complexity": "O(1) to create the new key and additional O(N*M) to reconstruct the serialized value, where N is the number of Redis objects composing the value and M their average size. For small string values the time complexity is thus O(1)+O(1*M) where M is small, so simply O(1). However for sorted set values the complexity is O(N*M*log(N)) because inserting values into sorted sets is O(log(N)).",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "name": "ttl",
                    "type": "integer",
                    "value": "ttl"
                },
                {
                    "name": "serialized-value",
                    "type": "string",
                    "value": "serialized-value"
                },
                {
                    "optional": true,
                    "name": "replace",
                    "token": "REPLACE"
                },
                {
                    "optional": true,
                    "name": "absttl",
                    "token": "ABSTTL"
                },
                {
                    "token": "IDLETIME",
                    "optional": true,
                    "name": "seconds",
                    "type": "integer",
                    "value": "seconds"
                },
                {
                    "token": "FREQ",
                    "optional": true,
                    "name": "frequency",
                    "type": "integer",
                    "value": "frequency"
                }
            ],
            "since": "2.6.0",
            "group": "generic",
            "arity": -4,
            "command_flags": [
                "write",
                "denyoom"
            ],
            "acl_categories": [
                "keyspace",
                "write",
                "slow",
                "dangerous"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "restoreCommand"
        }
    },
    {
        "HRANDFIELD": {
            "body": "When called with just the `key` argument, return a random field from the hash value stored at `key`.\n\nIf the provided `count` argument is positive, return an array of **distinct fields**.\nThe array's length is either `count` or the hash's number of fields ([`HLEN`](./hlen)), whichever is lower.\n\nIf called with a negative `count`, the behavior changes and the command is allowed to return the **same field multiple times**.\nIn this case, the number of returned fields is the absolute value of the specified `count`.\n\nThe optional `WITHVALUES` modifier changes the reply so it includes the respective values of the randomly selected hash fields.\n\n@examples\n\n```cli\nHMSET coin heads obverse tails reverse edge null\nHRANDFIELD coin\nHRANDFIELD coin\nHRANDFIELD coin -5 WITHVALUES\n```\n\n## Specification of the behavior when count is passed\n\nWhen the `count` argument is a positive value this command behaves as follows:\n\n* No repeated fields are returned.\n* If `count` is bigger than the number of fields in the hash, the command will only return the whole hash without additional fields.\n* The order of fields in the reply is not truly random, so it is up to the client to shuffle them if needed.\n\nWhen the `count` is a negative value, the behavior changes as follows:\n\n* Repeating fields are possible.\n* Exactly `count` fields, or an empty array if the hash is empty (non-existing key), are always returned.\n* The order of fields in the reply is truly random.\n\n",
            "return_summary": "@bulk-string-reply: without the additional `count` argument, the command returns a Bulk Reply with the randomly selected field, or `nil` when `key` does not exist.\n\n@array-reply: when the additional `count` argument is passed, the command returns an array of fields, or an empty array when `key` does not exist.\nIf the `WITHVALUES` modifier is used, the reply is a list fields and their values from the hash.",
            "": "",
            "summary": "Get one or multiple random fields from a hash",
            "complexity": "O(N) where N is the number of fields returned",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "optional": true,
                    "name": "options",
                    "type": "block",
                    "value": [
                        {
                            "name": "count",
                            "type": "integer",
                            "value": "count"
                        },
                        {
                            "optional": true,
                            "name": "withvalues",
                            "token": "WITHVALUES"
                        }
                    ]
                }
            ],
            "since": "6.2.0",
            "group": "hash",
            "arity": -2,
            "command_flags": [
                "readonly",
                "random"
            ],
            "acl_categories": [
                "read",
                "hash",
                "slow"
            ],
            "key_specs": [
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "hrandfieldCommand"
        }
    },
    {
        "XLEN": {
            "body": "Returns the number of entries inside a stream. If the specified key does not\nexist the command returns zero, as if the stream was empty.\nHowever note that unlike other Redis types, zero-length streams are\npossible, so you should call [`TYPE`](./type) or [`EXISTS`](./exists) in order to check if\na key exists or not.\n\nStreams are not auto-deleted once they have no entries inside (for instance\nafter an [`XDEL`](./xdel) call), because the stream may have consumer groups\nassociated with it.\n\n@examples\n\n```cli\nXADD mystream * item 1\nXADD mystream * item 2\nXADD mystream * item 3\nXLEN mystream\n```\n\n",
            "": "",
            "return_types": [
                {
                    "description": "the number of entries of the stream at `key`.",
                    "type": "integer"
                }
            ],
            "summary": "Return the number of entries in a stream",
            "complexity": "O(1)",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                }
            ],
            "since": "5.0.0",
            "group": "stream",
            "arity": 2,
            "command_flags": [
                "readonly",
                "fast"
            ],
            "acl_categories": [
                "read",
                "stream",
                "fast"
            ],
            "key_specs": [
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "xlenCommand"
        }
    },
    {
        "ASKING": {
            "body": "When a cluster client receives an `-ASK` redirect, the `ASKING` command is sent to the target node followed by the command which was redirected.\nThis is normally done automatically by cluster clients.\n\nIf an `-ASK` redirect is received during a transaction, only one ASKING command needs to be sent to the target node before sending the complete transaction to the target node.\n\nSee [ASK redirection in the Redis Cluster Specification](/topics/cluster-spec#ask-redirection) for details.\n\n",
            "": "",
            "return_types": [
                {
                    "description": "`OK`.",
                    "type": "simple-string"
                }
            ],
            "summary": "Sent by cluster clients after an -ASK redirect",
            "complexity": "O(1)",
            "arguments": [],
            "since": "3.0.0",
            "group": "cluster",
            "arity": 1,
            "command_flags": [
                "fast"
            ],
            "acl_categories": [
                "fast",
                "connection"
            ],
            "function": "askingCommand"
        }
    },
    {
        "WATCH": {
            "body": "Marks the given keys to be watched for conditional execution of a\n[transaction][tt].\n\n[tt]: /topics/transactions\n\n",
            "": "",
            "return_types": [
                {
                    "description": "always `OK`.",
                    "type": "simple-string"
                }
            ],
            "summary": "Watch the given keys to determine execution of the MULTI/EXEC block",
            "complexity": "O(1) for every key.",
            "arguments": [
                {
                    "multiple": true,
                    "multiple_token": true,
                    "name": "key",
                    "type": "key",
                    "value": "key"
                }
            ],
            "since": "2.2.0",
            "group": "transactions",
            "arity": -2,
            "command_flags": [
                "noscript",
                "loading",
                "stale",
                "fast"
            ],
            "acl_categories": [
                "fast",
                "transaction"
            ],
            "key_specs": [
                {
                    "flags": [],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": -1,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "watchCommand"
        }
    },
    {
        "EXPIREAT": {
            "body": "`EXPIREAT` has the same effect and semantic as [`EXPIRE`](./expire), but instead of\nspecifying the number of seconds representing the TTL (time to live), it takes\nan absolute [Unix timestamp][hewowu] (seconds since January 1, 1970). A\ntimestamp in the past will delete the key immediately.\n\n[hewowu]: http://en.wikipedia.org/wiki/Unix_time\n\nPlease for the specific semantics of the command refer to the documentation of\n[`EXPIRE`](./expire).\n\n## Background\n\n`EXPIREAT` was introduced in order to convert relative timeouts to absolute\ntimeouts for the AOF persistence mode.\nOf course, it can be used directly to specify that a given key should expire at\na given time in the future.\n\n## Options\n\nThe `EXPIREAT` command supports a set of options since Redis 7.0:\n\n* `NX` -- Set expiry only when the key has no expiry\n* `XX` -- Set expiry only when the key has an existing expiry\n* `GT` -- Set expiry only when the new expiry is greater than current one\n* `LT` -- Set expiry only when the new expiry is less than current one\n\nA non-volatile key is treated as an infinite TTL for the purpose of `GT` and `LT`.\nThe `GT`, `LT` and `NX` options are mutually exclusive.\n\n@examples\n\n```cli\nSET mykey \"Hello\"\nEXISTS mykey\nEXPIREAT mykey 1293840000\nEXISTS mykey\n```\n\n",
            "history": [
                [
                    "7.0",
                    "Added options: `NX`, `XX`, `GT` and `LT`."
                ]
            ],
            "return_summary": "@integer-reply, specifically:\n\n* `1` if the timeout was set.\n* `0` if the timeout was not set. e.g. key doesn't exist, or operation skipped due to the provided arguments.",
            "": "",
            "summary": "Set the expiration for a key as a UNIX timestamp",
            "complexity": "O(1)",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "name": "timestamp",
                    "type": "posix time",
                    "value": "timestamp"
                },
                {
                    "optional": true,
                    "name": "nx_xx_gt_lt",
                    "type": "oneof",
                    "value": [
                        {
                            "name": "__TBD__77__",
                            "token": "NX"
                        },
                        {
                            "name": "__TBD__78__",
                            "token": "XX"
                        },
                        {
                            "name": "__TBD__79__",
                            "token": "GT"
                        },
                        {
                            "name": "__TBD__80__",
                            "token": "LT"
                        }
                    ]
                }
            ],
            "since": "1.2.0",
            "group": "generic",
            "arity": -3,
            "command_flags": [
                "write",
                "fast"
            ],
            "acl_categories": [
                "keyspace",
                "write",
                "fast"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "expireatCommand"
        }
    },
    {
        "SDIFFSTORE": {
            "body": "This command is equal to [`SDIFF`](./sdiff), but instead of returning the resulting set, it\nis stored in `destination`.\n\nIf `destination` already exists, it is overwritten.\n\n@examples\n\n```cli\nSADD key1 \"a\"\nSADD key1 \"b\"\nSADD key1 \"c\"\nSADD key2 \"c\"\nSADD key2 \"d\"\nSADD key2 \"e\"\nSDIFFSTORE key key1 key2\nSMEMBERS key\n```\n\n",
            "": "",
            "return_types": [
                {
                    "description": "the number of elements in the resulting set.",
                    "type": "integer"
                }
            ],
            "summary": "Subtract multiple sets and store the resulting set in a key",
            "complexity": "O(N) where N is the total number of elements in all given sets.",
            "arguments": [
                {
                    "name": "destination",
                    "type": "key",
                    "value": "destination"
                },
                {
                    "multiple": true,
                    "multiple_token": true,
                    "name": "key",
                    "type": "key",
                    "value": "key"
                }
            ],
            "since": "1.0.0",
            "group": "set",
            "arity": -3,
            "command_flags": [
                "write",
                "denyoom"
            ],
            "acl_categories": [
                "write",
                "set",
                "slow"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                },
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 2
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": -1,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "sdiffstoreCommand"
        }
    },
    {
        "MSET": {
            "body": "Sets the given keys to their respective values.\n`MSET` replaces existing values with new values, just as regular [`SET`](./set).\nSee [`MSETNX`](./msetnx) if you don't want to overwrite existing values.\n\n`MSET` is atomic, so all given keys are set at once.\nIt is not possible for clients to see that some of the keys were updated while\nothers are unchanged.\n\n@examples\n\n```cli\nMSET key1 \"Hello\" key2 \"World\"\nGET key1\nGET key2\n```\n\n",
            "": "",
            "return_types": [
                {
                    "description": "always `OK` since `MSET` can't fail.",
                    "type": "simple-string"
                }
            ],
            "summary": "Set multiple keys to multiple values",
            "complexity": "O(N) where N is the number of keys to set.",
            "arguments": [
                {
                    "multiple": true,
                    "multiple_token": true,
                    "name": "key_value",
                    "type": "block",
                    "value": [
                        {
                            "name": "key",
                            "type": "key",
                            "value": "key"
                        },
                        {
                            "name": "value",
                            "type": "string",
                            "value": "value"
                        }
                    ]
                }
            ],
            "since": "1.0.1",
            "group": "string",
            "arity": -3,
            "command_flags": [
                "write",
                "denyoom"
            ],
            "acl_categories": [
                "write",
                "string",
                "slow"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": -1,
                            "step": 2,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "msetCommand"
        }
    },
    {
        "BRPOP": {
            "body": "`BRPOP` is a blocking list pop primitive.\nIt is the blocking version of [`RPOP`](./rpop) because it blocks the connection when there\nare no elements to pop from any of the given lists.\nAn element is popped from the tail of the first list that is non-empty, with the\ngiven keys being checked in the order that they are given.\n\nSee the [BLPOP documentation][cb] for the exact semantics, since `BRPOP` is\nidentical to [`BLPOP`](./blpop) with the only difference being that it pops elements from\nthe tail of a list instead of popping from the head.\n\n[cb]: /commands/blpop\n\n@examples\n\n```\nredis> DEL list1 list2\n(integer) 0\nredis> RPUSH list1 a b c\n(integer) 3\nredis> BRPOP list1 list2 0\n1) \"list1\"\n2) \"c\"\n```\n\n",
            "history": [
                [
                    "6.0",
                    "`timeout` is interpreted as a double instead of an integer."
                ]
            ],
            "": "",
            "return_types": [
                {
                    "description": "specifically:",
                    "type": "array"
                }
            ],
            "summary": "Remove and get the last element in a list, or block until one is available",
            "complexity": "O(N) where N is the number of provided keys.",
            "arguments": [
                {
                    "multiple": true,
                    "multiple_token": true,
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "name": "timeout",
                    "type": "double",
                    "value": "timeout"
                }
            ],
            "since": "2.0.0",
            "group": "list",
            "arity": -3,
            "command_flags": [
                "write",
                "noscript"
            ],
            "acl_categories": [
                "write",
                "list",
                "slow",
                "blocking"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": -2,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "brpopCommand"
        }
    },
    {
        "PSUBSCRIBE": {
            "body": "Subscribes the client to the given patterns.\n\nSupported glob-style patterns:\n\n* `h?llo` subscribes to `hello`, `hallo` and `hxllo`\n* `h*llo` subscribes to `hllo` and `heeeello`\n* `h[ae]llo` subscribes to `hello` and `hallo,` but not `hillo`\n\nUse `\\` to escape special characters if you want to match them verbatim.\n\n",
            "return_summary": "",
            "summary": "Listen for messages published to channels matching the given patterns",
            "complexity": "O(N) where N is the number of patterns the client is already subscribed to.",
            "arguments": [
                {
                    "multiple": true,
                    "multiple_token": true,
                    "name": "pattern",
                    "type": "block",
                    "value": [
                        {
                            "name": "pattern",
                            "type": "pattern",
                            "value": "pattern"
                        }
                    ]
                }
            ],
            "since": "2.0.0",
            "group": "pubsub",
            "arity": -2,
            "command_flags": [
                "pubsub",
                "noscript",
                "loading",
                "stale"
            ],
            "acl_categories": [
                "pubsub",
                "slow"
            ],
            "function": "psubscribeCommand"
        }
    },
    {
        "ACL": {
            "arity": -2,
            "command_flags": [],
            "acl_categories": [
                "slow"
            ],
            "subcommands": [
                {
                    "HELP": {
                        "body": "The `ACL HELP` command returns a helpful text describing the different subcommands.\n\n",
                        "": "",
                        "return_types": [
                            {
                                "description": "a list of subcommands and their descriptions",
                                "type": "array"
                            }
                        ],
                        "summary": "Show helpful text about the different subcommands",
                        "complexity": "O(1)",
                        "since": "6.0.0",
                        "group": "server",
                        "arity": 2,
                        "command_flags": [
                            "loading",
                            "stale"
                        ],
                        "acl_categories": [
                            "slow"
                        ],
                        "function": "aclCommand",
                        "container": "ACL"
                    }
                },
                {
                    "DELUSER": {
                        "body": "Delete all the specified ACL users and terminate all the connections that are\nauthenticated with such users. Note: the special `default` user cannot be\nremoved from the system, this is the default user that every new connection\nis authenticated with. The list of users may include usernames that do not\nexist, in such case no operation is performed for the non existing users.\n\n@examples\n\n```\n> ACL DELUSER antirez\n1\n```\n\n",
                        "": "",
                        "return_types": [
                            {
                                "description": "The number of users that were deleted. This number will not always match the number of arguments since certain users may not exist.",
                                "type": "integer"
                            }
                        ],
                        "summary": "Remove the specified ACL users and the associated rules",
                        "complexity": "O(1) amortized time considering the typical user.",
                        "arguments": [
                            {
                                "multiple": true,
                                "multiple_token": true,
                                "name": "username",
                                "type": "string",
                                "value": "username"
                            }
                        ],
                        "since": "6.0.0",
                        "group": "server",
                        "arity": -3,
                        "command_flags": [
                            "admin",
                            "noscript",
                            "loading",
                            "stale"
                        ],
                        "acl_categories": [
                            "admin",
                            "slow",
                            "dangerous"
                        ],
                        "function": "aclCommand",
                        "container": "ACL"
                    }
                },
                {
                    "CAT": {
                        "body": "The command shows the available ACL categories if called without arguments.\nIf a category name is given, the command shows all the Redis commands in\nthe specified category.\n\nACL categories are very useful in order to create ACL rules that include or\nexclude a large set of commands at once, without specifying every single\ncommand. For instance, the following rule will let the user `karin` perform\neverything but the most dangerous operations that may affect the server\nstability:\n\n    ACL SETUSER karin on +@all -@dangerous\n\nWe first add all the commands to the set of commands that `karin` is able\nto execute, but then we remove all the dangerous commands.\n\nChecking for all the available categories is as simple as:\n\n```\n> ACL CAT\n 1) \"keyspace\"\n 2) \"read\"\n 3) \"write\"\n 4) \"set\"\n 5) \"sortedset\"\n 6) \"list\"\n 7) \"hash\"\n 8) \"string\"\n 9) \"bitmap\"\n10) \"hyperloglog\"\n11) \"geo\"\n12) \"stream\"\n13) \"pubsub\"\n14) \"admin\"\n15) \"fast\"\n16) \"slow\"\n17) \"blocking\"\n18) \"dangerous\"\n19) \"connection\"\n20) \"transaction\"\n21) \"scripting\"\n```\n\nThen we may want to know what commands are part of a given category:\n\n```\n> ACL CAT dangerous\n 1) \"flushdb\"\n 2) \"acl\"\n 3) \"slowlog\"\n 4) \"debug\"\n 5) \"role\"\n 6) \"keys\"\n 7) \"pfselftest\"\n 8) \"client\"\n 9) \"bgrewriteaof\"\n10) \"replicaof\"\n11) \"monitor\"\n12) \"restore-asking\"\n13) \"latency\"\n14) \"replconf\"\n15) \"pfdebug\"\n16) \"bgsave\"\n17) \"sync\"\n18) \"config\"\n19) \"flushall\"\n20) \"cluster\"\n21) \"info\"\n22) \"lastsave\"\n23) \"slaveof\"\n24) \"swapdb\"\n25) \"module\"\n26) \"restore\"\n27) \"migrate\"\n28) \"save\"\n29) \"shutdown\"\n30) \"psync\"\n31) \"sort\"\n```\n\n",
                        "": "",
                        "return_types": [
                            {
                                "description": "a list of ACL categories or a list of commands inside a given category. The command may return an error if an invalid category name is given as argument.",
                                "type": "array"
                            }
                        ],
                        "summary": "List the ACL categories or the commands inside a category",
                        "complexity": "O(1) since the categories and commands are a fixed set.",
                        "arguments": [
                            {
                                "optional": true,
                                "name": "categoryname",
                                "type": "string",
                                "value": "categoryname"
                            }
                        ],
                        "since": "6.0.0",
                        "group": "server",
                        "arity": -2,
                        "command_flags": [
                            "noscript",
                            "loading",
                            "stale"
                        ],
                        "acl_categories": [
                            "slow"
                        ],
                        "function": "aclCommand",
                        "container": "ACL"
                    }
                },
                {
                    "USERS": {
                        "body": "The command shows a list of all the usernames of the currently configured\nusers in the Redis ACL system.\n\n@examples\n\n```\n> ACL USERS\n1) \"anna\"\n2) \"antirez\"\n3) \"default\"\n```\n\n",
                        "return_summary": "An array of strings.",
                        "": "",
                        "summary": "List the username of all the configured ACL rules",
                        "complexity": "O(N). Where N is the number of configured users.",
                        "since": "6.0.0",
                        "group": "server",
                        "arity": 2,
                        "command_flags": [
                            "admin",
                            "noscript",
                            "loading",
                            "stale"
                        ],
                        "acl_categories": [
                            "admin",
                            "slow",
                            "dangerous"
                        ],
                        "function": "aclCommand",
                        "container": "ACL"
                    }
                },
                {
                    "SETUSER": {
                        "body": "Create an ACL user with the specified rules or modify the rules of an\nexisting user. This is the main interface in order to manipulate Redis ACL\nusers interactively: if the username does not exist, the command creates\nthe username without any privilege, then reads from left to right all the\nrules provided as successive arguments, setting the user ACL rules as specified.\n\nIf the user already exists, the provided ACL rules are simply applied\n*in addition* to the rules already set. For example:\n\n    ACL SETUSER virginia on allkeys +set\n\nThe above command will create a user called `virginia` that is active\n(the on rule), can access any key (allkeys rule), and can call the\nset command (+set rule). Then another SETUSER call can modify the user rules:\n\n    ACL SETUSER virginia +get\n\nThe above rule will not apply the new rule to the user virginia, so other than [`SET`](./set), the user virginia will now be able to also use the [`GET`](./get) command.\n\nWhen we want to be sure to define an user from scratch, without caring if\nit had previously defined rules associated, we can use the special rule\n`reset` as first rule, in order to flush all the other existing rules:\n\n    ACL SETUSER antirez reset [... other rules ...]\n\nAfter resetting an user, it returns back to the status it has when it\nwas just created: non active (off rule), can't execute any command, can't\naccess any key:\n\n    > ACL SETUSER antirez reset\n    +OK\n    > ACL LIST\n    1) \"user antirez off -@all\"\n\nACL rules are either words like \"on\", \"off\", \"reset\", \"allkeys\", or are\nspecial rules that start with a special character, and are followed by\nanother string (without any space in between), like \"+SET\".\n\nThe following documentation is a reference manual about the capabilities of this command, however our [ACL tutorial](/topics/acl) may be a more gentle introduction to how the ACL system works in general.\n\n## List of rules\n\nThis is a list of all the supported Redis ACL rules:\n\n* `on`: set the user as active, it will be possible to authenticate as this user using `AUTH <username> <password>`.\n* `off`: set user as not active, it will be impossible to log as this user. Please note that if a user gets disabled (set to off) after there are connections already authenticated with such a user, the connections will continue to work as expected. To also kill the old connections you can use `CLIENT KILL` with the user option. An alternative is to delete the user with `ACL DELUSER`, that will result in all the connections authenticated as the deleted user to be disconnected.\n* `~<pattern>`: add the specified key pattern (glob style pattern, like in the [`KEYS`](./keys) command), to the list of key patterns accessible by the user. You can add multiple key patterns to the same user. Example: `~objects:*`\n* `allkeys`: alias for `~*`, it allows the user to access all the keys.\n* `resetkeys`: removes all the key patterns from the list of key patterns the user can access.\n* `&<pattern>`: add the specified glob style pattern to the list of Pub/Sub channel patterns accessible by the user. You can add multiple channel patterns to the same user. Example: `&chatroom:*`\n* `allchannels`: alias for `&*`, it allows the user to access all Pub/Sub channels.\n* `resetchannels`: removes all channel patterns from the list of Pub/Sub channel patterns the user can access.\n* `+<command>`: add this command to the list of the commands the user can call. Example: `+zadd`.\n* `+@<category>`: add all the commands in the specified category to the list of commands the user is able to execute. Example: `+@string` (adds all the string commands). For a list of categories check the `ACL CAT` command.\n* `+<command>|<subcommand>`: add the specified command to the list of the commands the user can execute, but only for the specified subcommand. Example: `+config|get`. Generates an error if the specified command is already allowed in its full version for the specified user. Note: there is no symmetrical command to remove subcommands, you need to remove the whole command and re-add the subcommands you want to allow. This is much safer than removing subcommands, in the future Redis may add new dangerous subcommands, so configuring by subtraction is not good.\n* `allcommands`: alias of `+@all`. Adds all the commands there are in the server, including *future commands* loaded via module, to be executed by this user.\n* `-<command>`. Like `+<command>` but removes the command instead of adding it.\n* `-@<category>`: Like `+@<category>` but removes all the commands in the category instead of adding them.\n* `nocommands`: alias for `-@all`. Removes all the commands, the user will no longer be able to execute anything.\n* `nopass`: the user is set as a \"no password\" user. It means that it will be possible to authenticate as such user with any password. By default, the `default` special user is set as \"nopass\". The `nopass` rule will also reset all the configured passwords for the user.\n* `>password`: Add the specified clear text password as an hashed password in the list of the users passwords. Every user can have many active passwords, so that password rotation will be simpler. The specified password is not stored as clear text inside the server. Example: `>mypassword`.\n* `#<hashedpassword>`: Add the specified hashed password to the list of user passwords. A Redis hashed password is hashed with SHA256 and translated into a hexadecimal string. Example: `#c3ab8ff13720e8ad9047dd39466b3c8974e592c2fa383d4a3960714caef0c4f2`.\n* `<password`: Like `>password` but removes the password instead of adding it.\n* `<hashedpassword>`: Like `#<hashedpassword>` but removes the password instead of adding it.\n* reset: Remove any capability from the user. It is set to off, without passwords, unable to execute any command, unable to access any key.\n\n@examples\n\n```\n> ACL SETUSER alan allkeys +@string +@set -SADD >alanpassword\n+OK\n\n> ACL SETUSER antirez heeyyyy\n(error) ERR Error in ACL SETUSER modifier 'heeyyyy': Syntax error\n```\n\n",
                        "history": [
                            [
                                "6.2",
                                "Added Pub/Sub channel patterns."
                            ]
                        ],
                        "": "",
                        "return_types": [
                            {
                                "description": "`OK` on success.",
                                "type": "simple-string"
                            }
                        ],
                        "summary": "Modify or create the rules for a specific ACL user",
                        "complexity": "O(N). Where N is the number of rules provided.",
                        "arguments": [
                            {
                                "name": "username",
                                "type": "string",
                                "value": "username"
                            },
                            {
                                "optional": true,
                                "multiple": true,
                                "multiple_token": true,
                                "name": "rule",
                                "type": "string",
                                "value": "rule"
                            }
                        ],
                        "since": "6.0.0",
                        "group": "server",
                        "arity": -3,
                        "command_flags": [
                            "admin",
                            "noscript",
                            "loading",
                            "stale"
                        ],
                        "acl_categories": [
                            "admin",
                            "slow",
                            "dangerous"
                        ],
                        "function": "aclCommand",
                        "container": "ACL"
                    }
                },
                {
                    "LIST": {
                        "body": "The command shows the currently active ACL rules in the Redis server. Each\nline in the returned array defines a different user, and the format is the\nsame used in the redis.conf file or the external ACL file, so you can\ncut and paste what is returned by the ACL LIST command directly inside a\nconfiguration file if you wish (but make sure to check `ACL SAVE`).\n\n@examples\n\n```\n> ACL LIST\n1) \"user antirez on #9f86d081884c7d659a2feaa0c55ad015a3bf4f1b2b0b822cd15d6c15b0f00a08 ~objects:* &* +@all -@admin -@dangerous\"\n2) \"user default on nopass ~* &* +@all\"\n```\n\n",
                        "return_summary": "An array of strings.",
                        "": "",
                        "summary": "List the current ACL rules in ACL config file format",
                        "complexity": "O(N). Where N is the number of configured users.",
                        "since": "6.0.0",
                        "group": "server",
                        "arity": 2,
                        "command_flags": [
                            "admin",
                            "noscript",
                            "loading",
                            "stale"
                        ],
                        "acl_categories": [
                            "admin",
                            "slow",
                            "dangerous"
                        ],
                        "function": "aclCommand",
                        "container": "ACL"
                    }
                },
                {
                    "LOAD": {
                        "body": "When Redis is configured to use an ACL file (with the `aclfile` configuration\noption), this command will reload the ACLs from the file, replacing all\nthe current ACL rules with the ones defined in the file. The command makes\nsure to have an *all or nothing* behavior, that is:\n\n* If every line in the file is valid, all the ACLs are loaded.\n* If one or more line in the file is not valid, nothing is loaded, and the old ACL rules defined in the server memory continue to be used.\n\n@examples\n\n```\n> ACL LOAD\n+OK\n\n> ACL LOAD\n-ERR /tmp/foo:1: Unknown command or category name in ACL...\n```\n\n",
                        "": "",
                        "return_types": [
                            {
                                "description": "`OK` on success.",
                                "type": "simple-string"
                            }
                        ],
                        "summary": "Reload the ACLs from the configured ACL file",
                        "complexity": "O(N). Where N is the number of configured users.",
                        "since": "6.0.0",
                        "group": "server",
                        "arity": 2,
                        "command_flags": [
                            "admin",
                            "noscript",
                            "loading",
                            "stale"
                        ],
                        "acl_categories": [
                            "admin",
                            "slow",
                            "dangerous"
                        ],
                        "function": "aclCommand",
                        "container": "ACL"
                    }
                },
                {
                    "GETUSER": {
                        "body": "The command returns all the rules defined for an existing ACL user.\n\nSpecifically, it lists the user's ACL flags, password hashes and key name\npatterns. Note that command rules are returned as a string in the same\nformat used with the `ACL SETUSER` command. This description of command rules\nreflects the user's effective permissions, so while it may not be identical to\nthe set of rules used to configure the user, it is still functionally identical.\n\n@array-reply: a list of ACL rule definitions for the user.\n\n@examples\n\nHere's the default configuration for the default user:\n\n```\n> ACL GETUSER default\n1) \"flags\"\n2) 1) \"on\"\n   2) \"allkeys\"\n   3) \"allcommands\"\n   4) \"nopass\"\n3) \"passwords\"\n4) (empty array)\n5) \"commands\"\n6) \"+@all\"\n7) \"keys\"\n8) 1) \"*\"\n9) \"channels\"\n10) 1) \"*\"\n```\n\n",
                        "history": [
                            [
                                "6.2",
                                "Added Pub/Sub channel patterns."
                            ]
                        ],
                        "return_summary": "",
                        "summary": "Get the rules for a specific ACL user",
                        "complexity": "O(N). Where N is the number of password, command and pattern rules that the user has.",
                        "arguments": [
                            {
                                "name": "username",
                                "type": "string",
                                "value": "username"
                            }
                        ],
                        "since": "6.0.0",
                        "group": "server",
                        "arity": 3,
                        "command_flags": [
                            "admin",
                            "noscript",
                            "loading",
                            "stale"
                        ],
                        "acl_categories": [
                            "admin",
                            "slow",
                            "dangerous"
                        ],
                        "function": "aclCommand",
                        "container": "ACL"
                    }
                },
                {
                    "GENPASS": {
                        "body": "ACL users need a solid password in order to authenticate to the server without\nsecurity risks. Such password does not need to be remembered by humans, but\nonly by computers, so it can be very long and strong (unguessable by an\nexternal attacker). The `ACL GENPASS` command generates a password starting\nfrom /dev/urandom if available, otherwise (in systems without /dev/urandom) it\nuses a weaker system that is likely still better than picking a weak password\nby hand.\n\nBy default (if /dev/urandom is available) the password is strong and\ncan be used for other uses in the context of a Redis application, for\ninstance in order to create unique session identifiers or other kind of\nunguessable and not colliding IDs. The password generation is also very cheap\nbecause we don't really ask /dev/urandom for bits at every execution. At\nstartup Redis creates a seed using /dev/urandom, then it will use SHA256\nin counter mode, with HMAC-SHA256(seed,counter) as primitive, in order to\ncreate more random bytes as needed. This means that the application developer\nshould be feel free to abuse `ACL GENPASS` to create as many secure\npseudorandom strings as needed.\n\nThe command output is an hexadecimal representation of a binary string.\nBy default it emits 256 bits (so 64 hex characters). The user can provide\nan argument in form of number of bits to emit from 1 to 1024 to change\nthe output length. Note that the number of bits provided is always\nrounded to the next multiple of 4. So for instance asking for just 1\nbit password will result in 4 bits to be emitted, in the form of a single\nhex character.\n\n@examples\n\n```\n> ACL GENPASS\n\"dd721260bfe1b3d9601e7fbab36de6d04e2e67b0ef1c53de59d45950db0dd3cc\"\n\n> ACL GENPASS 32\n\"355ef3dd\"\n\n> ACL GENPASS 5\n\"90\"\n```\n\n",
                        "": "",
                        "return_types": [
                            {
                                "description": "by default 64 bytes string representing 256 bits of pseudorandom data. Otherwise if an argument if needed, the output string length is the number of specified bits (rounded to the next multiple of 4) divided by 4.",
                                "type": "bulk-string"
                            }
                        ],
                        "summary": "Generate a pseudorandom secure password to use for ACL users",
                        "complexity": "O(1)",
                        "arguments": [
                            {
                                "optional": true,
                                "name": "bits",
                                "type": "integer",
                                "value": "bits"
                            }
                        ],
                        "since": "6.0.0",
                        "group": "server",
                        "arity": -2,
                        "command_flags": [
                            "noscript",
                            "loading",
                            "stale"
                        ],
                        "acl_categories": [
                            "slow"
                        ],
                        "function": "aclCommand",
                        "container": "ACL"
                    }
                },
                {
                    "SAVE": {
                        "body": "When Redis is configured to use an ACL file (with the `aclfile` configuration\noption), this command will save the currently defined ACLs from the server memory to the ACL file.\n\n@examples\n\n```\n> ACL SAVE\n+OK\n\n> ACL SAVE\n-ERR There was an error trying to save the ACLs. Please check the server logs for more information\n```\n\n",
                        "": "",
                        "return_types": [
                            {
                                "description": "`OK` on success.",
                                "type": "simple-string"
                            }
                        ],
                        "summary": "Save the current ACL rules in the configured ACL file",
                        "complexity": "O(N). Where N is the number of configured users.",
                        "since": "6.0.0",
                        "group": "server",
                        "arity": 2,
                        "command_flags": [
                            "admin",
                            "noscript",
                            "loading",
                            "stale"
                        ],
                        "acl_categories": [
                            "admin",
                            "slow",
                            "dangerous"
                        ],
                        "function": "aclCommand",
                        "container": "ACL"
                    }
                },
                {
                    "WHOAMI": {
                        "body": "Return the username the current connection is authenticated with.\nNew connections are authenticated with the \"default\" user. They\ncan change user using [`AUTH`](./auth).\n\n@examples\n\n```\n> ACL WHOAMI\n\"default\"\n```\n\n",
                        "": "",
                        "return_types": [
                            {
                                "description": "the username of the current connection.",
                                "type": "bulk-string"
                            }
                        ],
                        "summary": "Return the name of the user associated to the current connection",
                        "complexity": "O(1)",
                        "since": "6.0.0",
                        "group": "server",
                        "arity": 2,
                        "command_flags": [
                            "noscript",
                            "loading",
                            "stale"
                        ],
                        "acl_categories": [
                            "slow"
                        ],
                        "function": "aclCommand",
                        "container": "ACL"
                    }
                },
                {
                    "LOG": {
                        "body": "The command shows a list of recent ACL security events:\n\n1. Failures to authenticate their connections with [`AUTH`](./auth) or [`HELLO`](./hello).\n2. Commands denied because against the current ACL rules.\n3. Commands denied because accessing keys not allowed in the current ACL rules.\n\nThe optional argument specifies how many entries to show. By default\nup to ten failures are returned. The special [`RESET`](./reset) argument clears the log.\nEntries are displayed starting from the most recent.\n\n@examples\n\n```\n> AUTH someuser wrongpassword\n(error) WRONGPASS invalid username-password pair\n> ACL LOG 1\n1)  1) \"count\"\n    2) (integer) 1\n    3) \"reason\"\n    4) \"auth\"\n    5) \"context\"\n    6) \"toplevel\"\n    7) \"object\"\n    8) \"AUTH\"\n    9) \"username\"\n   10) \"someuser\"\n   11) \"age-seconds\"\n   12) \"4.0960000000000001\"\n   13) \"client-info\"\n   14) \"id=6 addr=127.0.0.1:63026 fd=8 name= age=9 idle=0 flags=N db=0 sub=0 psub=0 multi=-1 qbuf=48 qbuf-free=32720 obl=0 oll=0 omem=0 events=r cmd=auth user=default\"\n```\n\n",
                        "return_summary": "When called to show security events:\n\n@array-reply: a list of ACL security events.\n\nWhen called with [`RESET`](./reset):\n\n@simple-string-reply: `OK` if the security log was cleared.",
                        "": "",
                        "summary": "List latest events denied because of ACLs in place",
                        "complexity": "O(N) with N being the number of entries shown.",
                        "arguments": [
                            {
                                "optional": true,
                                "name": "count_or RESET",
                                "type": "block",
                                "value": [
                                    {
                                        "name": "count",
                                        "type": "string",
                                        "value": "count"
                                    },
                                    {
                                        "name": "or",
                                        "type": "string",
                                        "value": "or"
                                    },
                                    {
                                        "name": "reset",
                                        "type": "string",
                                        "value": "RESET"
                                    }
                                ]
                            }
                        ],
                        "since": "6.0.0",
                        "group": "server",
                        "arity": -2,
                        "command_flags": [
                            "admin",
                            "noscript",
                            "loading",
                            "stale"
                        ],
                        "acl_categories": [
                            "admin",
                            "slow",
                            "dangerous"
                        ],
                        "function": "aclCommand",
                        "container": "ACL"
                    }
                }
            ],
            "group": "server",
            "since": "6.0.0"
        }
    },
    {
        "GEOADD": {
            "body": "Adds the specified geospatial items (longitude, latitude, name) to the specified key. Data is stored into the key as a sorted set, in a way that makes it possible to query the items with the [`GEOSEARCH`](./geosearch) command.\n\nThe command takes arguments in the standard format x,y so the longitude must be specified before the latitude. There are limits to the coordinates that can be indexed: areas very near to the poles are not indexable.\n\nThe exact limits, as specified by EPSG:900913 / EPSG:3785 / OSGEO:41001 are the following:\n\n* Valid longitudes are from -180 to 180 degrees.\n* Valid latitudes are from -85.05112878 to 85.05112878 degrees.\n\nThe command will report an error when the user attempts to index coordinates outside the specified ranges.\n\n**Note:** there is no **GEODEL** command because you can use [`ZREM`](./zrem) to remove elements. The Geo index structure is just a sorted set.\n\n## GEOADD options\n\n`GEOADD` also provides the following options:\n\n* **XX**: Only update elements that already exist. Never add elements.\n* **NX**: Don't update already existing elements. Always add new elements.\n* **CH**: Modify the return value from the number of new elements added, to the total number of elements changed (CH is an abbreviation of *changed*). Changed elements are **new elements added** and elements already existing for which **the coordinates was updated**. So elements specified in the command line having the same score as they had in the past are not counted. Note: normally, the return value of `GEOADD` only counts the number of new elements added.\n\nNote: The **XX** and **NX** options are mutually exclusive.\n\nHow does it work?\n---\n\nThe way the sorted set is populated is using a technique called\n[Geohash](https://en.wikipedia.org/wiki/Geohash). Latitude and Longitude\nbits are interleaved to form a unique 52-bit integer. We know\nthat a sorted set double score can represent a 52-bit integer without losing\nprecision.\n\nThis format allows for bounding box and radius querying by checking the 1+8 areas needed to cover the whole shape and discarding elements outside it. The areas are checked by calculating the range of the box covered, removing enough bits from the less significant part of the sorted set score, and computing the score range to query in the sorted set for each area.\n\nWhat Earth model does it use?\n---\n\nThe model assumes that the Earth is a sphere since it uses the Haversine formula to calculate distance. This formula is only an approximation when applied to the Earth, which is not a perfect sphere.\nThe introduced errors are not an issue when used, for example, by social networks and similar applications requiring this type of querying. \nHowever, in the worst case, the error may be up to 0.5%, so you may want to consider other systems for error-critical applications.\n\n@examples\n\n```cli\nGEOADD Sicily 13.361389 38.115556 \"Palermo\" 15.087269 37.502669 \"Catania\"\nGEODIST Sicily Palermo Catania\nGEORADIUS Sicily 15 37 100 km\nGEORADIUS Sicily 15 37 200 km\n```\n\n",
            "history": [
                [
                    "6.2",
                    "Added the `CH`, `NX` and `XX` options."
                ]
            ],
            "return_summary": "@integer-reply, specifically:\n\n* When used without optional arguments, the number of elements added to the sorted set (excluding score updates).\n* If the `CH` option is specified, the number of elements that were changed (added or updated).",
            "": "",
            "summary": "Add one or more geospatial items in the geospatial index represented using a sorted set",
            "complexity": "O(log(N)) for each item added, where N is the number of elements in the sorted set.",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "optional": true,
                    "name": "nx_xx",
                    "type": "oneof",
                    "value": [
                        {
                            "name": "__TBD__81__",
                            "token": "NX"
                        },
                        {
                            "name": "__TBD__82__",
                            "token": "XX"
                        }
                    ]
                },
                {
                    "optional": true,
                    "name": "change",
                    "token": "CH"
                },
                {
                    "multiple": true,
                    "multiple_token": true,
                    "name": "longitude_latitude_member",
                    "type": "block",
                    "value": [
                        {
                            "name": "longitude",
                            "type": "double",
                            "value": "longitude"
                        },
                        {
                            "name": "latitude",
                            "type": "double",
                            "value": "latitude"
                        },
                        {
                            "name": "member",
                            "type": "string",
                            "value": "member"
                        }
                    ]
                }
            ],
            "since": "3.2.0",
            "group": "geo",
            "arity": -5,
            "command_flags": [
                "write",
                "denyoom"
            ],
            "acl_categories": [
                "write",
                "geo",
                "slow"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "geoaddCommand"
        }
    },
    {
        "SETBIT": {
            "body": "Sets or clears the bit at _offset_ in the string value stored at _key_.\n\nThe bit is either set or cleared depending on _value_, which can be either 0 or\n1.\n\nWhen _key_ does not exist, a new string value is created.\nThe string is grown to make sure it can hold a bit at _offset_.\nThe _offset_ argument is required to be greater than or equal to 0, and smaller\nthan 2^32 (this limits bitmaps to 512MB).\nWhen the string at _key_ is grown, added bits are set to 0.\n\n**Warning**: When setting the last possible bit (_offset_ equal to 2^32 -1) and\nthe string value stored at _key_ does not yet hold a string value, or holds a\nsmall string value, Redis needs to allocate all intermediate memory which can\nblock the server for some time.\nOn a 2010 MacBook Pro, setting bit number 2^32 -1 (512MB allocation) takes\n~300ms, setting bit number 2^30 -1 (128MB allocation) takes ~80ms, setting bit\nnumber 2^28 -1 (32MB allocation) takes ~30ms and setting bit number 2^26 -1 (8MB\nallocation) takes ~8ms.\nNote that once this first allocation is done, subsequent calls to `SETBIT` for\nthe same _key_ will not have the allocation overhead.\n\n@examples\n\n```cli\nSETBIT mykey 7 1\nSETBIT mykey 7 0\nGET mykey\n```\n\n## Pattern: accessing the entire bitmap\n\nThere are cases when you need to set all the bits of single bitmap at once, for\nexample when initializing it to a default non-zero value. It is possible to do\nthis with multiple calls to the `SETBIT` command, one for each bit that needs to\nbe set. However, so as an optimization you can use a single [`SET`](./set) command to set\nthe entire bitmap.\n\nBitmaps are not an actual data type, but a set of bit-oriented operations\ndefined on the String type (for more information refer to the\n[Bitmaps section of the Data Types Introduction page][ti]). This means that\nbitmaps can be used with string commands, and most importantly with [`SET`](./set) and\n[`GET`](./get).\n\nBecause Redis' strings are binary-safe, a bitmap is trivially encoded as a bytes\nstream. The first byte of the string corresponds to offsets 0..7 of\nthe bitmap, the second byte to the 8..15 range, and so forth.\n\nFor example, after setting a few bits, getting the string value of the bitmap\nwould look like this:\n\n```\n> SETBIT bitmapsarestrings 2 1\n> SETBIT bitmapsarestrings 3 1\n> SETBIT bitmapsarestrings 5 1\n> SETBIT bitmapsarestrings 10 1\n> SETBIT bitmapsarestrings 11 1\n> SETBIT bitmapsarestrings 14 1\n> GET bitmapsarestrings\n\"42\"\n```\n\nBy getting the string representation of a bitmap, the client can then parse the\nresponse's bytes by extracting the bit values using native bit operations in its\nnative programming language. Symmetrically, it is also possible to set an entire\nbitmap by performing the bits-to-bytes encoding in the client and calling [`SET`](./set)\nwith the resultant string.\n\n[ti]: /topics/data-types-intro#bitmaps\n\n## Pattern: setting multiple bits\n\n`SETBIT` excels at setting single bits, and can be called several times when\nmultiple bits need to be set. To optimize this operation you can replace\nmultiple `SETBIT` calls with a single call to the variadic [`BITFIELD`](./bitfield) command\nand the use of fields of type `u1`.\n\nFor example, the example above could be replaced by:\n\n```\n> BITFIELD bitsinabitmap SET u1 2 1 SET u1 3 1 SET u1 5 1 SET u1 10 1 SET u1 11 1 SET u1 14 1\n```\n\n## Advanced Pattern: accessing bitmap ranges\n\nIt is also possible to use the [`GETRANGE`](./getrange) and [`SETRANGE`](./setrange) string commands to\nefficiently access a range of bit offsets in a bitmap. Below is a sample\nimplementation in idiomatic Redis Lua scripting that can be run with the [`EVAL`](./eval)\ncommand:\n\n```\n--[[\nSets a bitmap range\n\nBitmaps are stored as Strings in Redis. A range spans one or more bytes,\nso we can call [`SETRANGE`](./setrange) when entire bytes need to be set instead of flipping\nindividual bits. Also, to avoid multiple internal memory allocations in\nRedis, we traverse in reverse.\nExpected input:\n  KEYS[1] - bitfield key\n  ARGV[1] - start offset (0-based, inclusive)\n  ARGV[2] - end offset (same, should be bigger than start, no error checking)\n  ARGV[3] - value (should be 0 or 1, no error checking)\n]]--\n\n-- A helper function to stringify a binary string to semi-binary format\nlocal function tobits(str)\n  local r = ''\n  for i = 1, string.len(str) do\n    local c = string.byte(str, i)\n    local b = ' '\n    for j = 0, 7 do\n      b = tostring(bit.band(c, 1)) .. b\n      c = bit.rshift(c, 1)\n    end\n    r = r .. b\n  end\n  return r\nend\n\n-- Main\nlocal k = KEYS[1]\nlocal s, e, v = tonumber(ARGV[1]), tonumber(ARGV[2]), tonumber(ARGV[3])\n\n-- First treat the dangling bits in the last byte\nlocal ms, me = s % 8, (e + 1) % 8\nif me > 0 then\n  local t = math.max(e - me + 1, s)\n  for i = e, t, -1 do\n    redis.call('SETBIT', k, i, v)\n  end\n  e = t\nend\n\n-- Then the danglings in the first byte\nif ms > 0 then\n  local t = math.min(s - ms + 7, e)\n  for i = s, t, 1 do\n    redis.call('SETBIT', k, i, v)\n  end\n  s = t + 1\nend\n\n-- Set a range accordingly, if at all\nlocal rs, re = s / 8, (e + 1) / 8\nlocal rl = re - rs\nif rl > 0 then\n  local b = '\\255'\n  if 0 == v then\n    b = '\\0'\n  end\n  redis.call('SETRANGE', k, rs, string.rep(b, rl))\nend\n```\n\n**Note:** the implementation for getting a range of bit offsets from a bitmap is\nleft as an exercise to the reader.\n\n",
            "": "",
            "return_types": [
                {
                    "description": "the original bit value stored at _offset_.",
                    "type": "integer"
                }
            ],
            "summary": "Sets or clears the bit at offset in the string value stored at key",
            "complexity": "O(1)",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "name": "offset",
                    "type": "integer",
                    "value": "offset"
                },
                {
                    "name": "value",
                    "type": "integer",
                    "value": "value"
                }
            ],
            "since": "2.2.0",
            "group": "bitmap",
            "arity": 4,
            "command_flags": [
                "write",
                "denyoom"
            ],
            "acl_categories": [
                "write",
                "bitmap",
                "slow"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "setbitCommand"
        }
    },
    {
        "FAILOVER": {
            "body": "This command will start a coordinated failover between the currently-connected-to master and one of its replicas.\nThe failover is not synchronous, instead a background task will handle coordinating the failover. \nIt is designed to limit data loss and unavailability of the cluster during the failover.\nThis command is analogous to the `CLUSTER FAILOVER` command for non-clustered Redis and is similar to the failover support provided by sentinel.\n\nThe specific details of the default failover flow are as follows:\n\n1. The master will internally start a `CLIENT PAUSE WRITE`, which will pause incoming writes and prevent the accumulation of new data in the replication stream.\n2. The master will monitor its replicas, waiting for a replica to indicate that it has fully consumed the replication stream. If the master has multiple replicas, it will only wait for the first replica to catch up.\n3. The master will then demote itself to a replica. This is done to prevent any dual master scenarios. NOTE: The master will not discard its data, so it will be able to rollback if the replica rejects the failover request in the next step.\n4. The previous master will send a special PSYNC request to the target replica, `PSYNC FAILOVER`, instructing the target replica to become a master.\n5. Once the previous master receives acknowledgement the `PSYNC FAILOVER` was accepted it will unpause its clients. If the PSYNC request is rejected, the master will abort the failover and return to normal.\n\nThe field `master_failover_state` in `INFO replication` can be used to track the current state of the failover, which has the following values:\n\n* `no-failover`: There is no ongoing coordinated failover.\n* `waiting-for-sync`: The master is waiting for the replica to catch up to its replication offset.\n* `failover-in-progress`: The master has demoted itself, and is attempting to hand off ownership to a target replica.\n\nIf the previous master had additional replicas attached to it, they will continue replicating from it as chained replicas. You will need to manually execute a [`REPLICAOF`](./replicaof) on these replicas to start replicating directly from the new master.\n\n## Optional arguments\nThe following optional arguments exist to modify the behavior of the failover flow:\n\n* `TIMEOUT` *milliseconds* -- This option allows specifying a maximum time a master will wait in the `waiting-for-sync` state before aborting the failover attempt and rolling back.\nThis is intended to set an upper bound on the write outage the Redis cluster can experience.\nFailovers typically happen in less than a second, but could take longer if there is a large amount of write traffic or the replica is already behind in consuming the replication stream. \nIf this value is not specified, the timeout can be considered to be \"infinite\".\n\n* `TO` *HOST* *PORT* -- This option allows designating a specific replica, by its host and port, to failover to. The master will wait specifically for this replica to catch up to its replication offset, and then failover to it.\n\n* `FORCE` -- If both the `TIMEOUT` and `TO` options are set, the force flag can also be used to designate that that once the timeout has elapsed, the master should failover to the target replica instead of rolling back.\nThis can be used for a best-effort attempt at a failover without data loss, but limiting write outage.\n\nNOTE: The master will always rollback if the `PSYNC FAILOVER` request is rejected by the target replica. \n\n## Failover abort\n\nThe failover command is intended to be safe from data loss and corruption, but can encounter some scenarios it can not automatically remediate from and may get stuck. \nFor this purpose, the `FAILOVER ABORT` command exists, which will abort an ongoing failover and return the master to its normal state. \nThe command has no side effects if issued in the `waiting-for-sync` state but can introduce multi-master scenarios in the `failover-in-progress` state. \nIf a multi-master scenario is encountered, you will need to manually identify which master has the latest data and designate it as the master and have the other replicas.\n\nNOTE: [`REPLICAOF`](./replicaof) is disabled while a failover is in progress, this is to prevent unintended interactions with the failover that might cause data loss.\n\n",
            "": "",
            "return_types": [
                {
                    "description": "`OK` if the command was accepted and a coordinated failover is in progress. An error if the operation cannot be executed.",
                    "type": "simple-string"
                }
            ],
            "summary": "Start a coordinated failover between this server and one of its replicas.",
            "arguments": [
                {
                    "optional": true,
                    "name": "target",
                    "type": "block",
                    "value": [
                        {
                            "token": "TO",
                            "name": "to"
                        },
                        {
                            "name": "host",
                            "type": "string",
                            "value": "host"
                        },
                        {
                            "name": "port",
                            "type": "integer",
                            "value": "port"
                        },
                        {
                            "token": "FORCE",
                            "optional": true,
                            "name": "force"
                        }
                    ]
                },
                {
                    "token": "ABORT",
                    "optional": true,
                    "name": "abort"
                },
                {
                    "token": "TIMEOUT",
                    "optional": true,
                    "name": "milliseconds",
                    "type": "integer",
                    "value": "milliseconds"
                }
            ],
            "since": "6.2.0",
            "group": "server",
            "arity": -1,
            "command_flags": [
                "admin",
                "noscript",
                "stale"
            ],
            "acl_categories": [
                "admin",
                "slow",
                "dangerous"
            ],
            "function": "failoverCommand"
        }
    },
    {
        "MOVE": {
            "body": "Move `key` from the currently selected database (see [`SELECT`](./select)) to the specified\ndestination database.\nWhen `key` already exists in the destination database, or it does not exist in\nthe source database, it does nothing.\nIt is possible to use `MOVE` as a locking primitive because of this.\n\n",
            "return_summary": "@integer-reply, specifically:\n\n* `1` if `key` was moved.\n* `0` if `key` was not moved.",
            "": "",
            "summary": "Move a key to another database",
            "complexity": "O(1)",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "name": "db",
                    "type": "integer",
                    "value": "db"
                }
            ],
            "since": "1.0.0",
            "group": "generic",
            "arity": 3,
            "command_flags": [
                "write",
                "fast"
            ],
            "acl_categories": [
                "keyspace",
                "write",
                "fast"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "moveCommand"
        }
    },
    {
        "DUMP": {
            "body": "Serialize the value stored at key in a Redis-specific format and return it to\nthe user.\nThe returned value can be synthesized back into a Redis key using the [`RESTORE`](./restore)\ncommand.\n\nThe serialization format is opaque and non-standard, however it has a few\nsemantic characteristics:\n\n* It contains a 64-bit checksum that is used to make sure errors will be\n  detected.\n  The [`RESTORE`](./restore) command makes sure to check the checksum before synthesizing a\n  key using the serialized value.\n* Values are encoded in the same format used by RDB.\n* An RDB version is encoded inside the serialized value, so that different Redis\n  versions with incompatible RDB formats will refuse to process the serialized\n  value.\n\nThe serialized value does NOT contain expire information.\nIn order to capture the time to live of the current value the [`PTTL`](./pttl) command\nshould be used.\n\nIf `key` does not exist a nil bulk reply is returned.\n\n@examples\n\n```cli\nSET mykey 10\nDUMP mykey\n```\n\n",
            "": "",
            "return_types": [
                {
                    "description": "the serialized value.",
                    "type": "bulk-string"
                }
            ],
            "summary": "Return a serialized version of the value stored at the specified key.",
            "complexity": "O(1) to access the key and additional O(N*M) to serialize it, where N is the number of Redis objects composing the value and M their average size. For small string values the time complexity is thus O(1)+O(1*M) where M is small, so simply O(1).",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                }
            ],
            "since": "2.6.0",
            "group": "generic",
            "arity": 2,
            "command_flags": [
                "readonly",
                "random"
            ],
            "acl_categories": [
                "keyspace",
                "read",
                "slow"
            ],
            "key_specs": [
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "dumpCommand"
        }
    },
    {
        "ZREVRANK": {
            "body": "Returns the rank of `member` in the sorted set stored at `key`, with the scores\nordered from high to low.\nThe rank (or index) is 0-based, which means that the member with the highest\nscore has rank `0`.\n\nUse [`ZRANK`](./zrank) to get the rank of an element with the scores ordered from low to\nhigh.\n\n@examples\n\n```cli\nZADD myzset 1 \"one\"\nZADD myzset 2 \"two\"\nZADD myzset 3 \"three\"\nZREVRANK myzset \"one\"\nZREVRANK myzset \"four\"\n```\n\n",
            "return_summary": "* If `member` exists in the sorted set, @integer-reply: the rank of `member`.\n* If `member` does not exist in the sorted set or `key` does not exist,\n  @bulk-string-reply: `nil`.",
            "": "",
            "summary": "Determine the index of a member in a sorted set, with scores ordered from high to low",
            "complexity": "O(log(N))",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "name": "member",
                    "type": "string",
                    "value": "member"
                }
            ],
            "since": "2.0.0",
            "group": "sorted_set",
            "arity": 3,
            "command_flags": [
                "readonly",
                "fast"
            ],
            "acl_categories": [
                "read",
                "sortedset",
                "fast"
            ],
            "key_specs": [
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "zrevrankCommand"
        }
    },
    {
        "GETRANGE": {
            "body": "**Warning**: this command was renamed to `GETRANGE`, it is called [`SUBSTR`](./substr) in\nRedis versions `<= 2.0`.\n\nReturns the substring of the string value stored at `key`, determined by the\noffsets `start` and `end` (both are inclusive).\nNegative offsets can be used in order to provide an offset starting from the end\nof the string.\nSo -1 means the last character, -2 the penultimate and so forth.\n\nThe function handles out of range requests by limiting the resulting range to\nthe actual length of the string.\n\n@examples\n\n```cli\nSET mykey \"This is a string\"\nGETRANGE mykey 0 3\nGETRANGE mykey -3 -1\nGETRANGE mykey 0 -1\nGETRANGE mykey 10 100\n```\n\n",
            "": "",
            "return_types": [
                {
                    "type": "bulk-string"
                }
            ],
            "summary": "Get a substring of the string stored at a key",
            "complexity": "O(N) where N is the length of the returned string. The complexity is ultimately determined by the returned length, but because creating a substring from an existing string is very cheap, it can be considered O(1) for small strings.",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "name": "start",
                    "type": "integer",
                    "value": "start"
                },
                {
                    "name": "end",
                    "type": "integer",
                    "value": "end"
                }
            ],
            "since": "2.4.0",
            "group": "string",
            "arity": 4,
            "command_flags": [
                "readonly"
            ],
            "acl_categories": [
                "read",
                "string",
                "slow"
            ],
            "key_specs": [
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "getrangeCommand"
        }
    },
    {
        "GEOHASH": {
            "body": "Return valid [Geohash](https://en.wikipedia.org/wiki/Geohash) strings representing the position of one or more elements in a sorted set value representing a geospatial index (where elements were added using [`GEOADD`](./geoadd)).\n\nNormally Redis represents positions of elements using a variation of the Geohash\ntechnique where positions are encoded using 52 bit integers. The encoding is\nalso different compared to the standard because the initial min and max\ncoordinates used during the encoding and decoding process are different. This\ncommand however **returns a standard Geohash** in the form of a string as\ndescribed in the [Wikipedia article](https://en.wikipedia.org/wiki/Geohash) and compatible with the [geohash.org](http://geohash.org) web site.\n\nGeohash string properties\n---\n\nThe command returns 11 characters Geohash strings, so no precision is lost\ncompared to the Redis internal 52 bit representation. The returned Geohashes\nhave the following properties:\n\n1. They can be shortened removing characters from the right. It will lose precision but will still point to the same area.\n2. It is possible to use them in `geohash.org` URLs such as `http://geohash.org/<geohash-string>`. This is an [example of such URL](http://geohash.org/sqdtr74hyu0).\n3. Strings with a similar prefix are nearby, but the contrary is not true, it is possible that strings with different prefixes are nearby too.\n\n@examples\n\n```cli\nGEOADD Sicily 13.361389 38.115556 \"Palermo\" 15.087269 37.502669 \"Catania\"\nGEOHASH Sicily Palermo Catania\n```\n\n",
            "return_summary": "@array-reply, specifically:\n\nThe command returns an array where each element is the Geohash corresponding to\neach member name passed as argument to the command.",
            "": "",
            "summary": "Returns members of a geospatial index as standard geohash strings",
            "complexity": "O(log(N)) for each member requested, where N is the number of elements in the sorted set.",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "multiple": true,
                    "multiple_token": true,
                    "name": "member",
                    "type": "string",
                    "value": "member"
                }
            ],
            "since": "3.2.0",
            "group": "geo",
            "arity": -2,
            "command_flags": [
                "readonly"
            ],
            "acl_categories": [
                "read",
                "geo",
                "slow"
            ],
            "key_specs": [
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "geohashCommand"
        }
    },
    {
        "SISMEMBER": {
            "body": "Returns if `member` is a member of the set stored at `key`.\n\n@examples\n\n```cli\nSADD myset \"one\"\nSISMEMBER myset \"one\"\nSISMEMBER myset \"two\"\n```\n\n",
            "return_summary": "@integer-reply, specifically:\n\n* `1` if the element is a member of the set.\n* `0` if the element is not a member of the set, or if `key` does not exist.",
            "": "",
            "summary": "Determine if a given value is a member of a set",
            "complexity": "O(1)",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "name": "member",
                    "type": "string",
                    "value": "member"
                }
            ],
            "since": "1.0.0",
            "group": "set",
            "arity": 3,
            "command_flags": [
                "readonly",
                "fast"
            ],
            "acl_categories": [
                "read",
                "set",
                "fast"
            ],
            "key_specs": [
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "sismemberCommand"
        }
    },
    {
        "BLMOVE": {
            "body": "`BLMOVE` is the blocking variant of [`LMOVE`](./lmove).\nWhen `source` contains elements, this command behaves exactly like [`LMOVE`](./lmove).\nWhen used inside a [`MULTI`](./multi)/[`EXEC`](./exec) block, this command behaves exactly like [`LMOVE`](./lmove).\nWhen `source` is empty, Redis will block the connection until another client\npushes to it or until `timeout` (a double value specifying the maximum number of seconds to block) is reached.\nA `timeout` of zero can be used to block indefinitely.\n\nThis command comes in place of the now deprecated [`BRPOPLPUSH`](./brpoplpush). Doing\n`BLMOVE RIGHT LEFT` is equivalent.\n\nSee [`LMOVE`](./lmove) for more information.\n\n## Pattern: Reliable queue\n\nPlease see the pattern description in the [`LMOVE`](./lmove) documentation.\n\n## Pattern: Circular list\n\nPlease see the pattern description in the [`LMOVE`](./lmove) documentation.\n\n",
            "return_summary": "@bulk-string-reply: the element being popped from `source` and pushed to `destination`.\nIf `timeout` is reached, a @nil-reply is returned.",
            "deprecated": true,
            "": "",
            "summary": "Pop an element from a list, push it to another list and return it; or block until one is available",
            "complexity": "O(1)",
            "arguments": [
                {
                    "name": "source",
                    "type": "key",
                    "value": "source"
                },
                {
                    "name": "destination",
                    "type": "key",
                    "value": "destination"
                },
                {
                    "name": "left_right",
                    "type": "oneof",
                    "value": [
                        {
                            "name": "__TBD__83__",
                            "token": "LEFT"
                        },
                        {
                            "name": "__TBD__84__",
                            "token": "RIGHT"
                        }
                    ]
                },
                {
                    "name": "left_right",
                    "type": "oneof",
                    "value": [
                        {
                            "name": "__TBD__85__",
                            "token": "LEFT"
                        },
                        {
                            "name": "__TBD__86__",
                            "token": "RIGHT"
                        }
                    ]
                },
                {
                    "name": "timeout",
                    "type": "double",
                    "value": "timeout"
                }
            ],
            "since": "6.2.0",
            "group": "list",
            "arity": 6,
            "command_flags": [
                "write",
                "denyoom",
                "noscript"
            ],
            "acl_categories": [
                "write",
                "list",
                "slow",
                "blocking"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write",
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                },
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 2
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "blmoveCommand"
        }
    },
    {
        "PEXPIRE": {
            "body": "This command works exactly like [`EXPIRE`](./expire) but the time to live of the key is\nspecified in milliseconds instead of seconds.\n\n## Options\n\nThe `PEXPIRE` command supports a set of options since Redis 7.0:\n\n* `NX` -- Set expiry only when the key has no expiry\n* `XX` -- Set expiry only when the key has an existing expiry\n* `GT` -- Set expiry only when the new expiry is greater than current one\n* `LT` -- Set expiry only when the new expiry is less than current one\n\nA non-volatile key is treated as an infinite TTL for the purpose of `GT` and `LT`.\nThe `GT`, `LT` and `NX` options are mutually exclusive.\n\n@examples\n\n```cli\nSET mykey \"Hello\"\nPEXPIRE mykey 1500\nTTL mykey\nPTTL mykey\nPEXPIRE mykey 1000 XX\nTTL mykey\nPEXPIRE mykey 1000 NX\nTTL mykey\n```\n\n",
            "history": [
                [
                    "7.0",
                    "Added options: `NX`, `XX`, `GT` and `LT`."
                ]
            ],
            "return_summary": "@integer-reply, specifically:\n\n* `1` if the timeout was set.\n* `0` if the timeout was not set. e.g. key doesn't exist, or operation skipped due to the provided arguments.",
            "": "",
            "summary": "Set a key's time to live in milliseconds",
            "complexity": "O(1)",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "name": "milliseconds",
                    "type": "integer",
                    "value": "milliseconds"
                },
                {
                    "optional": true,
                    "name": "nx_xx_gt_lt",
                    "type": "oneof",
                    "value": [
                        {
                            "name": "__TBD__87__",
                            "token": "NX"
                        },
                        {
                            "name": "__TBD__88__",
                            "token": "XX"
                        },
                        {
                            "name": "__TBD__89__",
                            "token": "GT"
                        },
                        {
                            "name": "__TBD__90__",
                            "token": "LT"
                        }
                    ]
                }
            ],
            "since": "2.6.0",
            "group": "generic",
            "arity": -3,
            "command_flags": [
                "write",
                "fast"
            ],
            "acl_categories": [
                "keyspace",
                "write",
                "fast"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "pexpireCommand"
        }
    },
    {
        "GET": {
            "body": "Get the value of `key`.\nIf the key does not exist the special value `nil` is returned.\nAn error is returned if the value stored at `key` is not a string, because `GET`\nonly handles string values.\n\n@examples\n\n```cli\nGET nonexisting\nSET mykey \"Hello\"\nGET mykey\n```\n\n",
            "": "",
            "return_types": [
                {
                    "description": "the value of `key`, or `nil` when `key` does not exist.",
                    "type": "bulk-string"
                }
            ],
            "summary": "Get the value of a key",
            "complexity": "O(1)",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                }
            ],
            "since": "1.0.0",
            "group": "string",
            "arity": 2,
            "command_flags": [
                "readonly",
                "fast"
            ],
            "acl_categories": [
                "read",
                "string",
                "fast"
            ],
            "key_specs": [
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "getCommand"
        }
    },
    {
        "LINDEX": {
            "body": "Returns the element at index `index` in the list stored at `key`.\nThe index is zero-based, so `0` means the first element, `1` the second element\nand so on.\nNegative indices can be used to designate elements starting at the tail of the\nlist.\nHere, `-1` means the last element, `-2` means the penultimate and so forth.\n\nWhen the value at `key` is not a list, an error is returned.\n\n@examples\n\n```cli\nLPUSH mylist \"World\"\nLPUSH mylist \"Hello\"\nLINDEX mylist 0\nLINDEX mylist -1\nLINDEX mylist 3\n```\n\n",
            "": "",
            "return_types": [
                {
                    "description": "the requested element, or `nil` when `index` is out of range.",
                    "type": "bulk-string"
                }
            ],
            "summary": "Get an element from a list by its index",
            "complexity": "O(N) where N is the number of elements to traverse to get to the element at index. This makes asking for the first or the last element of the list O(1).",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "name": "index",
                    "type": "integer",
                    "value": "index"
                }
            ],
            "since": "1.0.0",
            "group": "list",
            "arity": 3,
            "command_flags": [
                "readonly"
            ],
            "acl_categories": [
                "read",
                "list",
                "slow"
            ],
            "key_specs": [
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "lindexCommand"
        }
    },
    {
        "ZINTER": {
            "body": "This command is similar to [`ZINTERSTORE`](./zinterstore), but instead of storing the resulting\nsorted set, it is returned to the client.\n\nFor a description of the `WEIGHTS` and `AGGREGATE` options, see [`ZUNIONSTORE`](./zunionstore).\n\n@examples\n\n```cli\nZADD zset1 1 \"one\"\nZADD zset1 2 \"two\"\nZADD zset2 1 \"one\"\nZADD zset2 2 \"two\"\nZADD zset2 3 \"three\"\nZINTER 2 zset1 zset2\nZINTER 2 zset1 zset2 WITHSCORES\n```\n\n",
            "": "",
            "return_types": [
                {
                    "description": "the result of intersection (optionally with their scores, in case ",
                    "type": "array"
                }
            ],
            "summary": "Intersect multiple sorted sets",
            "complexity": "O(N*K)+O(M*log(M)) worst case with N being the smallest input sorted set, K being the number of input sorted sets and M being the number of elements in the resulting sorted set.",
            "arguments": [
                {
                    "name": "numkeys",
                    "type": "integer",
                    "value": "numkeys"
                },
                {
                    "multiple": true,
                    "multiple_token": true,
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "token": "WEIGHTS",
                    "optional": true,
                    "multiple": true,
                    "name": "weight",
                    "type": "integer",
                    "value": "weight"
                },
                {
                    "token": "AGGREGATE",
                    "optional": true,
                    "name": "sum_min_max",
                    "type": "oneof",
                    "value": [
                        {
                            "name": "__TBD__91__",
                            "token": "SUM"
                        },
                        {
                            "name": "__TBD__92__",
                            "token": "MIN"
                        },
                        {
                            "name": "__TBD__93__",
                            "token": "MAX"
                        }
                    ]
                },
                {
                    "optional": true,
                    "name": "withscores",
                    "token": "WITHSCORES"
                }
            ],
            "since": "6.2.0",
            "group": "sorted_set",
            "arity": -3,
            "command_flags": [
                "readonly"
            ],
            "acl_categories": [
                "read",
                "sortedset",
                "slow"
            ],
            "key_specs": [
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "keynum": {
                            "keynumidx": 0,
                            "firstkey": 1,
                            "step": 1
                        }
                    }
                }
            ],
            "function": "zinterCommand",
            "get_keys_function": "zunionInterDiffGetKeys"
        }
    },
    {
        "CLIENT": {
            "arity": -2,
            "command_flags": [],
            "acl_categories": [
                "slow"
            ],
            "subcommands": [
                {
                    "NO-EVICT": {
                        "body": "The `CLIENT NO-EVICT` command sets the [client eviction](/topics/clients#client-eviction) mode for the current connection.\n\nWhen turned on and client eviction is configured, the current connection will be excluded from the client eviction process even if we're above the configured client eviction threshold.\n\nWhen turned off, the current client will be re-included in the pool of potential clients to be evicted (and evicted if needed).\n\nSee [client eviction](/topics/clients#client-eviction) for more details.\n\n",
                        "": "",
                        "return_types": [
                            {
                                "description": "`OK`.",
                                "type": "simple-string"
                            }
                        ],
                        "summary": "Set client eviction mode for the current connection",
                        "complexity": "O(1)",
                        "since": "7.0.0",
                        "arguments": [
                            {
                                "name": "on_off",
                                "type": "oneof",
                                "value": [
                                    {
                                        "name": "__TBD__94__",
                                        "token": "ON"
                                    },
                                    {
                                        "name": "__TBD__95__",
                                        "token": "OFF"
                                    }
                                ]
                            }
                        ],
                        "group": "connection",
                        "arity": 3,
                        "command_flags": [
                            "admin",
                            "noscript",
                            "loading",
                            "stale"
                        ],
                        "acl_categories": [
                            "admin",
                            "slow",
                            "dangerous",
                            "connection"
                        ],
                        "function": "clientCommand",
                        "container": "CLIENT"
                    }
                },
                {
                    "SETNAME": {
                        "body": "The `CLIENT SETNAME` command assigns a name to the current connection.\n\nThe assigned name is displayed in the output of `CLIENT LIST` so that it is possible to identify the client that performed a given connection.\n\nFor instance when Redis is used in order to implement a queue, producers and consumers of messages may want to set the name of the connection according to their role.\n\nThere is no limit to the length of the name that can be assigned if not the usual limits of the Redis string type (512 MB). However it is not possible to use spaces in the connection name as this would violate the format of the `CLIENT LIST` reply.\n\nIt is possible to entirely remove the connection name setting it to the empty string, that is not a valid connection name since it serves to this specific purpose.\n\nThe connection name can be inspected using `CLIENT GETNAME`.\n\nEvery new connection starts without an assigned name.\n\nTip: setting names to connections is a good way to debug connection leaks due to bugs in the application using Redis.\n\n",
                        "": "",
                        "return_types": [
                            {
                                "description": "`OK` if the connection name was successfully set.",
                                "type": "simple-string"
                            }
                        ],
                        "summary": "Set the current connection name",
                        "complexity": "O(1)",
                        "since": "2.6.9",
                        "arguments": [
                            {
                                "name": "connection-name",
                                "type": "string",
                                "value": "connection-name"
                            }
                        ],
                        "group": "connection",
                        "arity": 3,
                        "command_flags": [
                            "noscript",
                            "loading",
                            "stale"
                        ],
                        "acl_categories": [
                            "slow",
                            "connection"
                        ],
                        "function": "clientCommand",
                        "container": "CLIENT"
                    }
                },
                {
                    "KILL": {
                        "body": "The `CLIENT KILL` command closes a given client connection. This command support two formats, the old format:\n\n    CLIENT KILL addr:port\n\nThe `ip:port` should match a line returned by the `CLIENT LIST` command (`addr` field).\n\nThe new format:\n\n    CLIENT KILL <filter> <value> ... ... <filter> <value>\n\nWith the new form it is possible to kill clients by different attributes\ninstead of killing just by address. The following filters are available:\n\n* `CLIENT KILL ADDR ip:port`. This is exactly the same as the old three-arguments behavior.\n* `CLIENT KILL LADDR ip:port`. Kill all clients connected to specified local (bind) address.\n* `CLIENT KILL ID client-id`. Allows to kill a client by its unique `ID` field. Client `ID`'s are retrieved using the `CLIENT LIST` command.\n* `CLIENT KILL TYPE type`, where *type* is one of `normal`, `master`, `replica` and `pubsub`. This closes the connections of **all the clients** in the specified class. Note that clients blocked into the [`MONITOR`](./monitor) command are considered to belong to the `normal` class.\n* `CLIENT KILL USER username`. Closes all the connections that are authenticated with the specified [ACL](/topics/acl) username, however it returns an error if the username does not map to an existing ACL user.\n* `CLIENT KILL SKIPME yes/no`. By default this option is set to `yes`, that is, the client calling the command will not get killed, however setting this option to `no` will have the effect of also killing the client calling the command.\n\nIt is possible to provide multiple filters at the same time. The command will handle multiple filters via logical AND. For example:\n\n    CLIENT KILL addr 127.0.0.1:12345 type pubsub\n\nis valid and will kill only a pubsub client with the specified address. This format containing multiple filters is rarely useful currently.\n\nWhen the new form is used the command no longer returns `OK` or an error, but instead the number of killed clients, that may be zero.\n\n## CLIENT KILL and Redis Sentinel\n\nRecent versions of Redis Sentinel (Redis 2.8.12 or greater) use CLIENT KILL\nin order to kill clients when an instance is reconfigured, in order to\nforce clients to perform the handshake with one Sentinel again and update\nits configuration.\n\n## Notes\n\nDue to the single-threaded nature of Redis, it is not possible to\nkill a client connection while it is executing a command. From\nthe client point of view, the connection can never be closed\nin the middle of the execution of a command. However, the client\nwill notice the connection has been closed only when the\nnext command is sent (and results in network error).\n\n",
                        "history": [
                            [
                                "2.8.12",
                                "Added new filter format. "
                            ],
                            [
                                "2.8.12",
                                "`ID` option."
                            ],
                            [
                                "3.2",
                                "Added `master` type in for [`TYPE`](./type) option."
                            ],
                            [
                                "5",
                                "Replaced `slave` [`TYPE`](./type) with `replica`. `slave` still supported for backward compatibility."
                            ],
                            [
                                "6.2",
                                "`LADDR` option."
                            ]
                        ],
                        "return_summary": "When called with the three arguments format:\n\n@simple-string-reply: `OK` if the connection exists and has been closed\n\nWhen called with the filter / value format:\n\n@integer-reply: the number of clients killed.",
                        "": "",
                        "summary": "Kill the connection of a client",
                        "complexity": "O(N) where N is the number of client connections",
                        "arguments": [
                            {
                                "optional": true,
                                "name": "ip:port",
                                "type": "string",
                                "value": "ip:port"
                            },
                            {
                                "token": "ID",
                                "optional": true,
                                "name": "client-id",
                                "type": "integer",
                                "value": "client-id"
                            },
                            {
                                "token": "TYPE",
                                "optional": true,
                                "name": "normal_master_slave_pubsub",
                                "type": "oneof",
                                "value": [
                                    {
                                        "name": "__TBD__96__",
                                        "token": "normal"
                                    },
                                    {
                                        "name": "__TBD__97__",
                                        "token": "master"
                                    },
                                    {
                                        "name": "__TBD__98__",
                                        "token": "slave"
                                    },
                                    {
                                        "name": "__TBD__99__",
                                        "token": "pubsub"
                                    }
                                ]
                            },
                            {
                                "token": "USER",
                                "optional": true,
                                "name": "username",
                                "type": "string",
                                "value": "username"
                            },
                            {
                                "token": "ADDR",
                                "optional": true,
                                "name": "ip:port",
                                "type": "string",
                                "value": "ip:port"
                            },
                            {
                                "token": "LADDR",
                                "optional": true,
                                "name": "ip:port",
                                "type": "string",
                                "value": "ip:port"
                            },
                            {
                                "token": "SKIPME",
                                "optional": true,
                                "name": "yes/no",
                                "type": "string",
                                "value": "yes/no"
                            }
                        ],
                        "since": "2.4.0",
                        "group": "connection",
                        "arity": -3,
                        "command_flags": [
                            "admin",
                            "noscript",
                            "loading",
                            "stale"
                        ],
                        "acl_categories": [
                            "admin",
                            "slow",
                            "dangerous",
                            "connection"
                        ],
                        "function": "clientCommand",
                        "container": "CLIENT"
                    }
                },
                {
                    "GETREDIR": {
                        "body": "This command returns the client ID we are redirecting our\n[tracking](/topics/client-side-caching) notifications to. We set a client\nto redirect to when using `CLIENT TRACKING` to enable tracking. However in\norder to avoid forcing client libraries implementations to remember the\nID notifications are redirected to, this command exists in order to improve\nintrospection and allow clients to check later if redirection is active\nand towards which client ID.\n\n",
                        "": "",
                        "return_types": [
                            {
                                "description": "the ID of the client we are redirecting the notifications to. The command returns `-1` if client tracking is not enabled, or `0` if client tracking is enabled but we are not redirecting the notifications to any client.",
                                "type": "integer"
                            }
                        ],
                        "summary": "Get tracking notifications redirection client ID if any",
                        "complexity": "O(1)",
                        "since": "6.0.0",
                        "group": "connection",
                        "arity": 2,
                        "command_flags": [
                            "noscript",
                            "loading",
                            "stale"
                        ],
                        "acl_categories": [
                            "slow",
                            "connection"
                        ],
                        "function": "clientCommand",
                        "container": "CLIENT"
                    }
                },
                {
                    "PAUSE": {
                        "body": "`CLIENT PAUSE` is a connections control command able to suspend all the Redis clients for the specified amount of time (in milliseconds).\n\nThe command performs the following actions:\n\n* It stops processing all the pending commands from normal and pub/sub clients for the given mode. However interactions with replicas will continue normally. Note that clients are formally paused when they try to execute a command, so no work is taken on the server side for inactive clients.\n* However it returns OK to the caller ASAP, so the `CLIENT PAUSE` command execution is not paused by itself.\n* When the specified amount of time has elapsed, all the clients are unblocked: this will trigger the processing of all the commands accumulated in the query buffer of every client during the pause.\n\nClient pause currently supports two modes:\n\n* `ALL`: This is the default mode. All client commands are blocked.\n* `WRITE`: Clients are only blocked if they attempt to execute a write command.\n\nFor the `WRITE` mode, some commands have special behavior:\n\n* [`EVAL`](./eval)/[`EVALSHA`](./evalsha): Will block client for all scripts.\n* [`PUBLISH`](./publish): Will block client.\n* [`PFCOUNT`](./pfcount): Will block client.\n* [`WAIT`](./wait): Acknowledgments will be delayed, so this command will appear blocked.\n\nThis command is useful as it makes able to switch clients from a Redis instance to another one in a controlled way. For example during an instance upgrade the system administrator could do the following:\n\n* Pause the clients using `CLIENT PAUSE`\n* Wait a few seconds to make sure the replicas processed the latest replication stream from the master.\n* Turn one of the replicas into a master.\n* Reconfigure clients to connect with the new master.\n\nSince Redis 6.2, the recommended mode for client pause is `WRITE`. This mode will stop all replication traffic, can be\naborted with the `CLIENT UNPAUSE` command, and allows reconfiguring the old master without risking accepting writes after the\nfailover. This is also the mode used during cluster failover.\n\nFor versions before 6.2, it is possible to send `CLIENT PAUSE` in a MULTI/EXEC block together with the `INFO replication` command in order to get the current master offset at the time the clients are blocked. This way it is possible to wait for a specific offset in the replica side in order to make sure all the replication stream was processed.\n\nSince Redis 3.2.10 / 4.0.0, this command also prevents keys to be evicted or\nexpired during the time clients are paused. This way the dataset is guaranteed\nto be static not just from the point of view of clients not being able to write, but also from the point of view of internal operations.\n\n",
                        "history": [
                            [
                                "3.2.10",
                                "Client pause prevents client pause and key eviction as well."
                            ],
                            [
                                "6.2",
                                "CLIENT PAUSE WRITE mode added along with the `mode` option."
                            ]
                        ],
                        "": "",
                        "return_types": [
                            {
                                "description": "The command returns OK or an error if the timeout is invalid.",
                                "type": "simple-string"
                            }
                        ],
                        "summary": "Stop processing commands from clients for some time",
                        "complexity": "O(1)",
                        "arguments": [
                            {
                                "name": "timeout",
                                "type": "integer",
                                "value": "timeout"
                            },
                            {
                                "optional": true,
                                "name": "write_all",
                                "type": "oneof",
                                "value": [
                                    {
                                        "name": "__TBD__100__",
                                        "token": "WRITE"
                                    },
                                    {
                                        "name": "__TBD__101__",
                                        "token": "ALL"
                                    }
                                ]
                            }
                        ],
                        "since": "2.9.50",
                        "group": "connection",
                        "arity": -3,
                        "command_flags": [
                            "admin",
                            "noscript",
                            "loading",
                            "stale"
                        ],
                        "acl_categories": [
                            "admin",
                            "slow",
                            "dangerous",
                            "connection"
                        ],
                        "function": "clientCommand",
                        "container": "CLIENT"
                    }
                },
                {
                    "HELP": {
                        "arity": 2,
                        "command_flags": [
                            "loading",
                            "stale"
                        ],
                        "acl_categories": [
                            "slow",
                            "connection"
                        ],
                        "function": "clientCommand",
                        "container": "CLIENT",
                        "group": "connection"
                    }
                },
                {
                    "TRACKING": {
                        "body": "This command enables the tracking feature of the Redis server, that is used\nfor [server assisted client side caching](/topics/client-side-caching).\n\nWhen tracking is enabled Redis remembers the keys that the connection\nrequested, in order to send later invalidation messages when such keys are\nmodified. Invalidation messages are sent in the same connection (only available\nwhen the RESP3 protocol is used) or redirected in a different connection\n(available also with RESP2 and Pub/Sub). A special *broadcasting* mode is\navailable where clients participating in this protocol receive every\nnotification just subscribing to given key prefixes, regardless of the\nkeys that they requested. Given the complexity of the argument please\nrefer to [the main client side caching documentation](/topics/client-side-caching) for the details. This manual page is only a reference for the options of this subcommand.\n\nIn order to enable tracking, use:\n\n    CLIENT TRACKING on ... options ...\n\nThe feature will remain active in the current connection for all its life,\nunless tracking is turned on with `CLIENT TRACKING off` at some point.\n\nThe following are the list of options that modify the behavior of the\ncommand when enabling tracking:\n\n* `REDIRECT <id>`: send invalidation messages to the connection with the specified ID. The connection must exist. You can get the ID of a connection using `CLIENT ID`. If the connection we are redirecting to is terminated, when in RESP3 mode the connection with tracking enabled will receive `tracking-redir-broken` push messages in order to signal the condition.\n* `BCAST`: enable tracking in broadcasting mode. In this mode invalidation messages are reported for all the prefixes specified, regardless of the keys requested by the connection. Instead when the broadcasting mode is not enabled, Redis will track which keys are fetched using read-only commands, and will report invalidation messages only for such keys.\n* `PREFIX <prefix>`: for broadcasting, register a given key prefix, so that notifications will be provided only for keys starting with this string. This option can be given multiple times to register multiple prefixes. If broadcasting is enabled without this option, Redis will send notifications for every key. You can't delete a single prefix, but you can delete all prefixes by disabling and re-enabling tracking. Using this option adds the additional time complexity of O(N^2), where N is the total number of prefixes tracked. \n* `OPTIN`: when broadcasting is NOT active, normally don't track keys in read only commands, unless they are called immediately after a `CLIENT CACHING yes` command.\n* `OPTOUT`: when broadcasting is NOT active, normally track keys in read only commands, unless they are called immediately after a `CLIENT CACHING no` command.\n* `NOLOOP`: don't send notifications about keys modified by this connection itself.\n\n",
                        "": "",
                        "return_types": [
                            {
                                "description": "`OK` if the connection was successfully put in tracking mode or if the tracking mode was successfully disabled. Otherwise an error is returned.",
                                "type": "simple-string"
                            }
                        ],
                        "summary": "Enable or disable server assisted client side caching support",
                        "complexity": "O(1). Some options may introduce additional complexity.",
                        "arguments": [
                            {
                                "name": "on_off",
                                "type": "oneof",
                                "value": [
                                    {
                                        "name": "__TBD__102__",
                                        "token": "ON"
                                    },
                                    {
                                        "name": "__TBD__103__",
                                        "token": "OFF"
                                    }
                                ]
                            },
                            {
                                "token": "REDIRECT",
                                "optional": true,
                                "name": "client-id",
                                "type": "integer",
                                "value": "client-id"
                            },
                            {
                                "token": "PREFIX",
                                "optional": true,
                                "multiple": true,
                                "multiple_token": true,
                                "name": "prefix",
                                "type": "string",
                                "value": "prefix"
                            },
                            {
                                "optional": true,
                                "name": "BCAST",
                                "token": "BCAST"
                            },
                            {
                                "optional": true,
                                "name": "OPTIN",
                                "token": "OPTIN"
                            },
                            {
                                "optional": true,
                                "name": "OPTOUT",
                                "token": "OPTOUT"
                            },
                            {
                                "optional": true,
                                "name": "NOLOOP",
                                "token": "NOLOOP"
                            }
                        ],
                        "since": "6.0.0",
                        "group": "connection",
                        "arity": -3,
                        "command_flags": [
                            "noscript",
                            "loading",
                            "stale"
                        ],
                        "acl_categories": [
                            "slow",
                            "connection"
                        ],
                        "function": "clientCommand",
                        "container": "CLIENT"
                    }
                },
                {
                    "REPLY": {
                        "body": "Sometimes it can be useful for clients to completely disable replies from the Redis server. For example when the client sends fire and forget commands or performs a mass loading of data, or in caching contexts where new data is streamed constantly. In such contexts to use server time and bandwidth in order to send back replies to clients, which are going to be ignored, is considered wasteful.\n\nThe `CLIENT REPLY` command controls whether the server will reply the client's commands. The following modes are available:\n\n* `ON`. This is the default mode in which the server returns a reply to every command.\n* `OFF`. In this mode the server will not reply to client commands.\n* `SKIP`. This mode skips the reply of command immediately after it.\n\n",
                        "": "",
                        "return_types": [
                            {
                                "description": "`OK`.",
                                "type": "simple-string"
                            }
                        ],
                        "summary": "Instruct the server whether to reply to commands",
                        "complexity": "O(1)",
                        "arguments": [
                            {
                                "name": "on_off_skip",
                                "type": "oneof",
                                "value": [
                                    {
                                        "name": "__TBD__104__",
                                        "token": "ON"
                                    },
                                    {
                                        "name": "__TBD__105__",
                                        "token": "OFF"
                                    },
                                    {
                                        "name": "__TBD__106__",
                                        "token": "SKIP"
                                    }
                                ]
                            }
                        ],
                        "since": "3.2.0",
                        "group": "connection",
                        "arity": 3,
                        "command_flags": [
                            "noscript",
                            "loading",
                            "stale"
                        ],
                        "acl_categories": [
                            "slow",
                            "connection"
                        ],
                        "function": "clientCommand",
                        "container": "CLIENT"
                    }
                },
                {
                    "GETNAME": {
                        "body": "The `CLIENT GETNAME` returns the name of the current connection as set by `CLIENT SETNAME`. Since every new connection starts without an associated name, if no name was assigned a null bulk reply is returned.\n\n",
                        "": "",
                        "return_types": [
                            {
                                "description": "The connection name, or a null bulk reply if no name is set.",
                                "type": "bulk-string"
                            }
                        ],
                        "summary": "Get the current connection name",
                        "complexity": "O(1)",
                        "since": "2.6.9",
                        "group": "connection",
                        "arity": 2,
                        "command_flags": [
                            "noscript",
                            "loading",
                            "stale"
                        ],
                        "acl_categories": [
                            "slow",
                            "connection"
                        ],
                        "function": "clientCommand",
                        "container": "CLIENT"
                    }
                },
                {
                    "TRACKINGINFO": {
                        "body": "The command returns information about the current client connection's use of the [server assisted client side caching](/topics/client-side-caching) feature.\n\n",
                        "": "",
                        "return_types": [
                            {
                                "description": "a list of tracking information sections and their respective values, specifically:",
                                "type": "array"
                            }
                        ],
                        "summary": "Return information about server assisted client side caching for the current connection",
                        "complexity": "O(1)",
                        "since": "6.2.0",
                        "group": "connection",
                        "arity": 2,
                        "command_flags": [
                            "noscript",
                            "loading",
                            "stale"
                        ],
                        "acl_categories": [
                            "slow",
                            "connection"
                        ],
                        "function": "clientCommand",
                        "container": "CLIENT"
                    }
                },
                {
                    "LIST": {
                        "body": "The `CLIENT LIST` command returns information and statistics about the client\nconnections server in a mostly human readable format.\n\nYou can use one of the optional subcommands to filter the list. The `TYPE type` subcommand filters the list by clients' type, where *type* is one of `normal`, `master`, `replica`, and `pubsub`. Note that clients blocked by the [`MONITOR`](./monitor) command belong to the `normal` class.\n\nThe `ID` filter only returns entries for clients with IDs matching the `client-id` arguments.\n\n## Notes\n\nNew fields are regularly added for debugging purpose. Some could be removed\nin the future. A version safe Redis client using this command should parse\nthe output accordingly (i.e. handling gracefully missing fields, skipping\nunknown fields).\n\n",
                        "history": [
                            [
                                "2.8.12",
                                "Added unique client `id` field."
                            ],
                            [
                                "5.0",
                                "Added optional [`TYPE`](./type) filter."
                            ],
                            [
                                "6.2",
                                "Added `laddr` field and the optional `ID` filter."
                            ]
                        ],
                        "": "",
                        "return_types": [
                            {
                                "description": "a unique string, formatted as follows:",
                                "type": "bulk-string"
                            }
                        ],
                        "summary": "Get the list of client connections",
                        "complexity": "O(N) where N is the number of client connections",
                        "arguments": [
                            {
                                "token": "TYPE",
                                "optional": true,
                                "name": "normal_master_replica_pubsub",
                                "type": "oneof",
                                "value": [
                                    {
                                        "name": "__TBD__107__",
                                        "token": "normal"
                                    },
                                    {
                                        "name": "__TBD__108__",
                                        "token": "master"
                                    },
                                    {
                                        "name": "__TBD__109__",
                                        "token": "replica"
                                    },
                                    {
                                        "name": "__TBD__110__",
                                        "token": "pubsub"
                                    }
                                ]
                            },
                            {
                                "optional": true,
                                "name": "id",
                                "type": "block",
                                "value": [
                                    {
                                        "token": "ID",
                                        "name": "id"
                                    },
                                    {
                                        "multiple": true,
                                        "multiple_token": true,
                                        "name": "client-id",
                                        "type": "integer",
                                        "value": "client-id"
                                    }
                                ]
                            }
                        ],
                        "since": "2.4.0",
                        "group": "connection",
                        "arity": -2,
                        "command_flags": [
                            "admin",
                            "noscript",
                            "random",
                            "loading",
                            "stale"
                        ],
                        "acl_categories": [
                            "admin",
                            "slow",
                            "dangerous",
                            "connection"
                        ],
                        "function": "clientCommand",
                        "container": "CLIENT"
                    }
                },
                {
                    "INFO": {
                        "body": "The command returns information and statistics about the current client connection in a mostly human readable format.\n\nThe reply format is identical to that of `CLIENT LIST`, and the content consists only of information about the current client.\n\n@examples\n\n```cli\nCLIENT INFO\n```\n\n",
                        "": "",
                        "return_types": [
                            {
                                "description": "a unique string, as described at the `CLIENT LIST` page, for the current client.",
                                "type": "bulk-string"
                            }
                        ],
                        "summary": "Returns information about the current client connection.",
                        "complexity": "O(1)",
                        "since": "6.2.0",
                        "group": "connection",
                        "arity": 2,
                        "command_flags": [
                            "noscript",
                            "random",
                            "loading",
                            "stale"
                        ],
                        "acl_categories": [
                            "slow",
                            "connection"
                        ],
                        "function": "clientCommand",
                        "container": "CLIENT"
                    }
                },
                {
                    "CACHING": {
                        "body": "This command controls the tracking of the keys in the next command executed\nby the connection, when tracking is enabled in `OPTIN` or `OPTOUT` mode.\nPlease check the\n[client side caching documentation](/topics/client-side-caching) for\nbackground information.\n\nWhen tracking is enabled Redis, using the `CLIENT TRACKING` command, it is\npossible to specify the `OPTIN` or `OPTOUT` options, so that keys\nin read only commands are not automatically remembered by the server to\nbe invalidated later. When we are in `OPTIN` mode, we can enable the\ntracking of the keys in the next command by calling `CLIENT CACHING yes`\nimmediately before it. Similarly when we are in `OPTOUT` mode, and keys\nare normally tracked, we can avoid the keys in the next command to be\ntracked using `CLIENT CACHING no`.\n\nBasically the command sets a state in the connection, that is valid only\nfor the next command execution, that will modify the behavior of client\ntracking.\n\n",
                        "": "",
                        "return_types": [
                            {
                                "description": "`OK` or an error if the argument is not yes or no.",
                                "type": "simple-string"
                            }
                        ],
                        "summary": "Instruct the server about tracking or not keys in the next request",
                        "complexity": "O(1)",
                        "arguments": [
                            {
                                "name": "yes_no",
                                "type": "oneof",
                                "value": [
                                    {
                                        "name": "__TBD__111__",
                                        "token": "YES"
                                    },
                                    {
                                        "name": "__TBD__112__",
                                        "token": "NO"
                                    }
                                ]
                            }
                        ],
                        "since": "6.0.0",
                        "group": "connection",
                        "arity": 3,
                        "command_flags": [
                            "noscript",
                            "loading",
                            "stale"
                        ],
                        "acl_categories": [
                            "slow",
                            "connection"
                        ],
                        "function": "clientCommand",
                        "container": "CLIENT"
                    }
                },
                {
                    "ID": {
                        "body": "The command just returns the ID of the current connection. Every connection\nID has certain guarantees:\n\n1. It is never repeated, so if `CLIENT ID` returns the same number, the caller can be sure that the underlying client did not disconnect and reconnect the connection, but it is still the same connection.\n2. The ID is monotonically incremental. If the ID of a connection is greater than the ID of another connection, it is guaranteed that the second connection was established with the server at a later time.\n\nThis command is especially useful together with `CLIENT UNBLOCK` which was\nintroduced also in Redis 5 together with `CLIENT ID`. Check the `CLIENT UNBLOCK` command page for a pattern involving the two commands.\n\n@examples\n\n```cli\nCLIENT ID\n```\n\n",
                        "": "",
                        "return_types": [
                            {
                                "type": "integer"
                            }
                        ],
                        "summary": "Returns the client ID for the current connection",
                        "complexity": "O(1)",
                        "since": "5.0.0",
                        "group": "connection",
                        "arity": 2,
                        "command_flags": [
                            "noscript",
                            "loading",
                            "stale"
                        ],
                        "acl_categories": [
                            "slow",
                            "connection"
                        ],
                        "function": "clientCommand",
                        "container": "CLIENT"
                    }
                },
                {
                    "UNBLOCK": {
                        "body": "This command can unblock, from a different connection, a client blocked in a blocking operation, such as for instance [`BRPOP`](./brpop) or [`XREAD`](./xread) or [`WAIT`](./wait).\n\nBy default the client is unblocked as if the timeout of the command was\nreached, however if an additional (and optional) argument is passed, it is possible to specify the unblocking behavior, that can be **TIMEOUT** (the default) or **ERROR**. If **ERROR** is specified, the behavior is to unblock the client returning as error the fact that the client was force-unblocked. Specifically the client will receive the following error:\n\n    -UNBLOCKED client unblocked via CLIENT UNBLOCK\n\nNote: of course as usually it is not guaranteed that the error text remains\nthe same, however the error code will remain `-UNBLOCKED`.\n\nThis command is useful especially when we are monitoring many keys with\na limited number of connections. For instance we may want to monitor multiple\nstreams with [`XREAD`](./xread) without using more than N connections. However at some\npoint the consumer process is informed that there is one more stream key\nto monitor. In order to avoid using more connections, the best behavior would\nbe to stop the blocking command from one of the connections in the pool, add\nthe new key, and issue the blocking command again.\n\nTo obtain this behavior the following pattern is used. The process uses\nan additional *control connection* in order to send the `CLIENT UNBLOCK` command\nif needed. In the meantime, before running the blocking operation on the other\nconnections, the process runs `CLIENT ID` in order to get the ID associated\nwith that connection. When a new key should be added, or when a key should\nno longer be monitored, the relevant connection blocking command is aborted\nby sending `CLIENT UNBLOCK` in the control connection. The blocking command\nwill return and can be finally reissued.\n\nThis example shows the application in the context of Redis streams, however\nthe pattern is a general one and can be applied to other cases.\n\n@example\n\n```\nConnection A (blocking connection):\n> CLIENT ID\n2934\n> BRPOP key1 key2 key3 0\n(client is blocked)\n\n... Now we want to add a new key ...\n\nConnection B (control connection):\n> CLIENT UNBLOCK 2934\n1\n\nConnection A (blocking connection):\n... BRPOP reply with timeout ...\nNULL\n> BRPOP key1 key2 key3 key4 0\n(client is blocked again)\n```\n\n",
                        "return_summary": "@integer-reply, specifically:\n\n* `1` if the client was unblocked successfully.\n* `0` if the client wasn't unblocked.",
                        "": "",
                        "summary": "Unblock a client blocked in a blocking command from a different connection",
                        "complexity": "O(log N) where N is the number of client connections",
                        "arguments": [
                            {
                                "name": "client-id",
                                "type": "integer",
                                "value": "client-id"
                            },
                            {
                                "optional": true,
                                "name": "timeout_error",
                                "type": "oneof",
                                "value": [
                                    {
                                        "name": "__TBD__113__",
                                        "token": "TIMEOUT"
                                    },
                                    {
                                        "name": "__TBD__114__",
                                        "token": "ERROR"
                                    }
                                ]
                            }
                        ],
                        "since": "5.0.0",
                        "group": "connection",
                        "arity": -3,
                        "command_flags": [
                            "admin",
                            "noscript",
                            "loading",
                            "stale"
                        ],
                        "acl_categories": [
                            "admin",
                            "slow",
                            "dangerous",
                            "connection"
                        ],
                        "function": "clientCommand",
                        "container": "CLIENT"
                    }
                },
                {
                    "UNPAUSE": {
                        "body": "`CLIENT UNPAUSE` is used to resume command processing for all clients that were paused by `CLIENT PAUSE`.\n\n",
                        "": "",
                        "return_types": [
                            {
                                "description": "The command returns `OK`",
                                "type": "simple-string"
                            }
                        ],
                        "summary": "Resume processing of clients that were paused",
                        "complexity": "O(N) Where N is the number of paused clients",
                        "since": "6.2.0",
                        "group": "connection",
                        "arity": 2,
                        "command_flags": [
                            "admin",
                            "noscript",
                            "loading",
                            "stale"
                        ],
                        "acl_categories": [
                            "admin",
                            "slow",
                            "dangerous",
                            "connection"
                        ],
                        "function": "clientCommand",
                        "container": "CLIENT"
                    }
                }
            ],
            "group": "connection",
            "since": "2.4.0"
        }
    },
    {
        "SADD": {
            "body": "Add the specified members to the set stored at `key`.\nSpecified members that are already a member of this set are ignored.\nIf `key` does not exist, a new set is created before adding the specified\nmembers.\n\nAn error is returned when the value stored at `key` is not a set.\n\n@examples\n\n```cli\nSADD myset \"Hello\"\nSADD myset \"World\"\nSADD myset \"World\"\nSMEMBERS myset\n```\n\n",
            "history": [
                [
                    "2.4",
                    "Accepts multiple `member` arguments."
                ]
            ],
            "": "",
            "return_types": [
                {
                    "description": "the number of elements that were added to the set, not including",
                    "type": "integer"
                }
            ],
            "summary": "Add one or more members to a set",
            "complexity": "O(1) for each element added, so O(N) to add N elements when the command is called with multiple arguments.",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "multiple": true,
                    "multiple_token": true,
                    "name": "member",
                    "type": "string",
                    "value": "member"
                }
            ],
            "since": "1.0.0",
            "group": "set",
            "arity": -3,
            "command_flags": [
                "write",
                "denyoom",
                "fast"
            ],
            "acl_categories": [
                "write",
                "set",
                "fast"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "saddCommand"
        }
    },
    {
        "SLOWLOG": {
            "arity": -2,
            "command_flags": [],
            "acl_categories": [
                "slow"
            ],
            "subcommands": [
                {
                    "HELP": {
                        "body": "The `SLOWLOG HELP` command returns a helpful text describing the different subcommands.\n\n",
                        "": "",
                        "return_types": [
                            {
                                "description": "a list of subcommands and their descriptions",
                                "type": "array"
                            }
                        ],
                        "summary": "Show helpful text about the different subcommands",
                        "complexity": "O(1)",
                        "since": "6.2.0",
                        "group": "server",
                        "arity": 2,
                        "command_flags": [
                            "loading",
                            "stale"
                        ],
                        "acl_categories": [
                            "slow"
                        ],
                        "function": "slowlogCommand",
                        "container": "SLOWLOG"
                    }
                },
                {
                    "GET": {
                        "body": "The `SLOWLOG GET` command returns entries from the slow log in chronological order.\n\nThe Redis Slow Log is a system to log queries that exceeded a specified execution time.\nThe execution time does not include I/O operations like talking with the client, sending the reply and so forth, but just the time needed to actually execute the command (this is the only stage of command execution where the thread is blocked and can not serve other requests in the meantime).\n\nA new entry is added to the slow log whenever a command exceeds the execution time threshold defined by the `slowlog-log-slower-than` configuration directive.\nThe maximum number of entries in the slow log is governed by the `slowlog-max-len` configuration directive.\n\nBy default the command returns all of the entries in the log. The optional `count` argument limits the number of returned entries, so the command returns at most up to `count` entries.\n\nEach entry from the slow log is comprised of the following six values:\n\n1. A unique progressive identifier for every slow log entry.\n2. The unix timestamp at which the logged command was processed.\n3. The amount of time needed for its execution, in microseconds.\n4. The array composing the arguments of the command.\n5. Client IP address and port.\n6. Client name if set via the `CLIENT SETNAME` command.\n\nThe entry's unique ID can be used in order to avoid processing slow log entries multiple times (for instance you may have a script sending you an email alert for every new slow log entry).\nThe ID is never reset in the course of the Redis server execution, only a server\nrestart will reset it.\n\n@reply\n\n@array-reply: a list of slow log entries.\n\n",
                        "history": [
                            [
                                "4.0",
                                "Added client IP address, port and name to the reply."
                            ]
                        ],
                        "return_summary": "",
                        "summary": "Get the slow log's entries",
                        "complexity": "O(N) where N is the number of entries returned",
                        "since": "2.2.12",
                        "group": "server",
                        "arguments": [
                            {
                                "optional": true,
                                "name": "count",
                                "type": "integer",
                                "value": "count"
                            }
                        ],
                        "arity": -2,
                        "command_flags": [
                            "admin",
                            "random",
                            "loading",
                            "stale"
                        ],
                        "acl_categories": [
                            "admin",
                            "slow",
                            "dangerous"
                        ],
                        "function": "slowlogCommand",
                        "container": "SLOWLOG"
                    }
                },
                {
                    "RESET": {
                        "body": "This command resets the slow log, clearing all entries in it.\n\nOnce deleted the information is lost forever.\n\n@reply\n\n@simple-string-reply: `OK`\n\n",
                        "return_summary": "",
                        "summary": "Clear all entries from the slow log",
                        "complexity": "O(N) where N is the number of entries in the slowlog",
                        "since": "2.2.12",
                        "group": "server",
                        "arity": 2,
                        "command_flags": [
                            "admin",
                            "loading",
                            "stale"
                        ],
                        "acl_categories": [
                            "admin",
                            "slow",
                            "dangerous"
                        ],
                        "function": "slowlogCommand",
                        "container": "SLOWLOG"
                    }
                },
                {
                    "LEN": {
                        "body": "This command returns the current number of entries in the slow log.\n\nA new entry is added to the slow log whenever a command exceeds the execution time threshold defined by the `slowlog-log-slower-than` configuration directive.\nThe maximum number of entries in the slow log is governed by the `slowlog-max-len` configuration directive.\nOnce the slog log reaches its maximal size, the oldest entry is removed whenever a new entry is created.\nThe slow log can be cleared with the `SLOWLOG RESET` command.\n\n@reply\n\n@integer-reply\n\nThe number of entries in the slow log.\n\n",
                        "return_summary": "",
                        "summary": "Get the slow log's length",
                        "complexity": "O(1)",
                        "since": "2.2.12",
                        "group": "server",
                        "arity": 2,
                        "command_flags": [
                            "admin",
                            "random",
                            "loading",
                            "stale"
                        ],
                        "acl_categories": [
                            "admin",
                            "slow",
                            "dangerous"
                        ],
                        "function": "slowlogCommand",
                        "container": "SLOWLOG"
                    }
                }
            ],
            "group": "server",
            "since": "2.2.12"
        }
    },
    {
        "BGSAVE": {
            "body": "Save the DB in background.\n\nNormally the OK code is immediately returned.\nRedis forks, the parent continues to serve the clients, the child saves the DB\non disk then exits.\n\nAn error is returned if there is already a background save running or if there\nis another non-background-save process running, specifically an in-progress AOF\nrewrite.\n\nIf `BGSAVE SCHEDULE` is used, the command will immediately return `OK` when an\nAOF rewrite is in progress and schedule the background save to run at the next\nopportunity.\n\nA client may be able to check if the operation succeeded using the [`LASTSAVE`](./lastsave)\ncommand.\n\nPlease refer to the [persistence documentation][tp] for detailed information.\n\n[tp]: /topics/persistence\n\n",
            "history": [
                [
                    "3.2.2",
                    "Added the `SCHEDULE` option."
                ]
            ],
            "": "",
            "return_types": [
                {
                    "description": "`Background saving started` if `BGSAVE` started correctly or `Background saving scheduled` when used with the `SCHEDULE` subcommand.",
                    "type": "simple-string"
                }
            ],
            "summary": "Asynchronously save the dataset to disk",
            "arguments": [
                {
                    "optional": true,
                    "name": "schedule",
                    "token": "SCHEDULE"
                }
            ],
            "since": "1.0.0",
            "group": "server",
            "arity": -1,
            "command_flags": [
                "admin",
                "noscript"
            ],
            "acl_categories": [
                "admin",
                "slow",
                "dangerous"
            ],
            "function": "bgsaveCommand"
        }
    },
    {
        "UNWATCH": {
            "body": "Flushes all the previously watched keys for a [transaction][tt].\n\n[tt]: /topics/transactions\n\nIf you call [`EXEC`](./exec) or [`DISCARD`](./discard), there's no need to manually call `UNWATCH`.\n\n",
            "": "",
            "return_types": [
                {
                    "description": "always `OK`.",
                    "type": "simple-string"
                }
            ],
            "summary": "Forget about all watched keys",
            "complexity": "O(1)",
            "since": "2.2.0",
            "group": "transactions",
            "arity": 1,
            "command_flags": [
                "noscript",
                "loading",
                "stale",
                "fast"
            ],
            "acl_categories": [
                "fast",
                "transaction"
            ],
            "function": "unwatchCommand"
        }
    },
    {
        "TOUCH": {
            "body": "Alters the last access time of a key(s).\nA key is ignored if it does not exist.\n\n@examples\n\n```cli\nSET key1 \"Hello\"\nSET key2 \"World\"\nTOUCH key1 key2\n```\n\n",
            "": "",
            "return_types": [
                {
                    "description": "The number of keys that were touched.",
                    "type": "integer"
                }
            ],
            "summary": "Alters the last access time of a key(s). Returns the number of existing keys specified.",
            "complexity": "O(N) where N is the number of keys that will be touched.",
            "arguments": [
                {
                    "multiple": true,
                    "multiple_token": true,
                    "name": "key",
                    "type": "key",
                    "value": "key"
                }
            ],
            "since": "3.2.1",
            "group": "generic",
            "arity": -2,
            "command_flags": [
                "readonly",
                "fast"
            ],
            "acl_categories": [
                "keyspace",
                "read",
                "fast"
            ],
            "key_specs": [
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": -1,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "touchCommand"
        }
    },
    {
        "EXISTS": {
            "body": "Returns if `key` exists.\n\nSince Redis 3.0.3 it is possible to specify multiple keys instead of a single one. In such a case, it returns the total number of keys existing. Note that returning 1 or 0 for a single key is just a special case of the variadic usage, so the command is completely backward compatible.\n\nThe user should be aware that if the same existing key is mentioned in the arguments multiple times, it will be counted multiple times. So if `somekey` exists, `EXISTS somekey somekey` will return 2.\n\n@examples\n\n```cli\nSET key1 \"Hello\"\nEXISTS key1\nEXISTS nosuchkey\nSET key2 \"World\"\nEXISTS key1 key2 nosuchkey\n```\n\n",
            "return_summary": "@integer-reply, specifically:\n\n* `1` if the key exists.\n* `0` if the key does not exist.\n\nSince Redis 3.0.3 the command accepts a variable number of keys and the return value is generalized:\n\n* The number of keys existing among the ones specified as arguments. Keys mentioned multiple times and existing are counted multiple times.",
            "": "",
            "summary": "Determine if a key exists",
            "complexity": "O(N) where N is the number of keys to check.",
            "arguments": [
                {
                    "multiple": true,
                    "multiple_token": true,
                    "name": "key",
                    "type": "key",
                    "value": "key"
                }
            ],
            "since": "1.0.0",
            "group": "generic",
            "arity": -2,
            "command_flags": [
                "readonly",
                "fast"
            ],
            "acl_categories": [
                "keyspace",
                "read",
                "fast"
            ],
            "key_specs": [
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": -1,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "existsCommand"
        }
    },
    {
        "UNSUBSCRIBE": {
            "body": "Unsubscribes the client from the given channels, or from all of them if none is\ngiven.\n\nWhen no channels are specified, the client is unsubscribed from all the\npreviously subscribed channels.\nIn this case, a message for every unsubscribed channel will be sent to the\nclient.\n\n",
            "return_summary": "",
            "summary": "Stop listening for messages posted to the given channels",
            "complexity": "O(N) where N is the number of clients already subscribed to a channel.",
            "arguments": [
                {
                    "optional": true,
                    "multiple": true,
                    "multiple_token": true,
                    "name": "channel",
                    "type": "string",
                    "value": "channel"
                }
            ],
            "since": "2.0.0",
            "group": "pubsub",
            "arity": -1,
            "command_flags": [
                "pubsub",
                "noscript",
                "loading",
                "stale"
            ],
            "acl_categories": [
                "pubsub",
                "slow"
            ],
            "function": "unsubscribeCommand"
        }
    },
    {
        "ZREVRANGEBYSCORE": {
            "body": "Returns all the elements in the sorted set at `key` with a score between `max`\nand `min` (including elements with score equal to `max` or `min`).\nIn contrary to the default ordering of sorted sets, for this command the\nelements are considered to be ordered from high to low scores.\n\nThe elements having the same score are returned in reverse lexicographical\norder.\n\nApart from the reversed ordering, `ZREVRANGEBYSCORE` is similar to\n[`ZRANGEBYSCORE`](./zrangebyscore).\n\nAs per Redis 6.2.0, this command is considered deprecated. Please prefer using the [`ZRANGE`](./zrange) command with the `BYSCORE` and `REV` arguments in new code.\n\n@examples\n\n```cli\nZADD myzset 1 \"one\"\nZADD myzset 2 \"two\"\nZADD myzset 3 \"three\"\nZREVRANGEBYSCORE myzset +inf -inf\nZREVRANGEBYSCORE myzset 2 1\nZREVRANGEBYSCORE myzset 2 (1\nZREVRANGEBYSCORE myzset (2 (1\n```\n\n",
            "deprecated": true,
            "": "",
            "return_types": [
                {
                    "description": "list of elements in the specified score range (optionally",
                    "type": "array"
                }
            ],
            "summary": "Return a range of members in a sorted set, by score, with scores ordered from high to low",
            "complexity": "O(log(N)+M) with N being the number of elements in the sorted set and M the number of elements being returned. If M is constant (e.g. always asking for the first 10 elements with LIMIT), you can consider it O(log(N)).",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "name": "max",
                    "type": "double",
                    "value": "max"
                },
                {
                    "name": "min",
                    "type": "double",
                    "value": "min"
                },
                {
                    "optional": true,
                    "name": "withscores",
                    "token": "WITHSCORES"
                },
                {
                    "token": "LIMIT",
                    "optional": true,
                    "name": "offset_count",
                    "type": "block",
                    "value": [
                        {
                            "name": "offset",
                            "type": "integer",
                            "value": "offset"
                        },
                        {
                            "name": "count",
                            "type": "integer",
                            "value": "count"
                        }
                    ]
                }
            ],
            "since": "2.2.0",
            "group": "sorted_set",
            "arity": -4,
            "command_flags": [
                "readonly"
            ],
            "acl_categories": [
                "read",
                "sortedset",
                "slow"
            ],
            "key_specs": [
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "zrevrangebyscoreCommand"
        }
    },
    {
        "BZPOPMAX": {
            "body": "`BZPOPMAX` is the blocking variant of the sorted set [`ZPOPMAX`](./zpopmax) primitive.\n\nIt is the blocking version because it blocks the connection when there are no\nmembers to pop from any of the given sorted sets.\nA member with the highest score is popped from first sorted set that is\nnon-empty, with the given keys being checked in the order that they are given.\n\nThe `timeout` argument is interpreted as a double value specifying the maximum\nnumber of seconds to block. A timeout of zero can be used to block indefinitely.\n\nSee the [BZPOPMIN documentation][cb] for the exact semantics, since `BZPOPMAX`\nis identical to [`BZPOPMIN`](./bzpopmin) with the only difference being that it pops members\nwith the highest scores instead of popping the ones with the lowest scores.\n\n[cb]: /commands/bzpopmin\n\n@examples\n\n```\nredis> DEL zset1 zset2\n(integer) 0\nredis> ZADD zset1 0 a 1 b 2 c\n(integer) 3\nredis> BZPOPMAX zset1 zset2 0\n1) \"zset1\"\n2) \"c\"\n3) \"2\"\n```\n\n",
            "history": [
                [
                    "6.0",
                    "`timeout` is interpreted as a double instead of an integer."
                ]
            ],
            "": "",
            "return_types": [
                {
                    "description": "specifically:",
                    "type": "array"
                }
            ],
            "summary": "Remove and return the member with the highest score from one or more sorted sets, or block until one is available",
            "complexity": "O(log(N)) with N being the number of elements in the sorted set.",
            "arguments": [
                {
                    "multiple": true,
                    "multiple_token": true,
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "name": "timeout",
                    "type": "double",
                    "value": "timeout"
                }
            ],
            "since": "5.0.0",
            "group": "sorted_set",
            "arity": -3,
            "command_flags": [
                "write",
                "noscript",
                "fast"
            ],
            "acl_categories": [
                "write",
                "sortedset",
                "fast",
                "blocking"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": -2,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "bzpopmaxCommand"
        }
    },
    {
        "RESTORE-ASKING": {
            "arity": -4,
            "command_flags": [
                "write",
                "denyoom",
                "asking"
            ],
            "acl_categories": [
                "keyspace",
                "write",
                "slow",
                "dangerous"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "restoreCommand",
            "group": "server",
            "internal": true
        }
    },
    {
        "LPOS": {
            "body": "The command returns the index of matching elements inside a Redis list.\nBy default, when no options are given, it will scan the list from head to tail,\nlooking for the first match of \"element\". If the element is found, its index (the zero-based position in the list) is returned. Otherwise, if no match is found, `nil` is returned.\n\n```\n> RPUSH mylist a b c 1 2 3 c c\n> LPOS mylist c\n2\n```\n\nThe optional arguments and options can modify the command's behavior.\nThe `RANK` option specifies the \"rank\" of the first element to return, in case there are multiple matches. A rank of 1 means to return the first match, 2 to return the second match, and so forth.\n\nFor instance, in the above example the element \"c\" is present multiple times, if I want the index of the second match, I'll write:\n\n```\n> LPOS mylist c RANK 2\n6\n```\n\nThat is, the second occurrence of \"c\" is at position 6.\nA negative \"rank\" as the `RANK` argument tells `LPOS` to invert the search direction, starting from the tail to the head.\n\nSo, we want to say, give me the first element starting from the tail of the list:\n\n```\n> LPOS mylist c RANK -1\n7\n```\n\nNote that the indexes are still reported in the \"natural\" way, that is, considering the first element starting from the head of the list at index 0, the next element at index 1, and so forth. This basically means that the returned indexes are stable whatever the rank is positive or negative.\n\nSometimes we want to return not just the Nth matching element, but the position of all the first N matching elements. This can be achieved using the `COUNT` option.\n\n```\n> LPOS mylist c COUNT 2\n[2,6]\n```\n\nWe can combine `COUNT` and `RANK`, so that `COUNT` will try to return up to the specified number of matches, but starting from the Nth match, as specified by the `RANK` option.\n\n```\n> LPOS mylist c RANK -1 COUNT 2\n[7,6]\n```\n\nWhen `COUNT` is used, it is possible to specify 0 as the number of matches, as a way to tell the command we want all the matches found returned as an array of indexes. This is better than giving a very large `COUNT` option because it is more general.\n\n```\n> LPOS mylist c COUNT 0\n[2,6,7]\n```\n\nWhen `COUNT` is used and no match is found, an empty array is returned. However when `COUNT` is not used and there are no matches, the command returns `nil`.\n\nFinally, the `MAXLEN` option tells the command to compare the provided element only with a given maximum number of list items. So for instance specifying `MAXLEN 1000` will make sure that the command performs only 1000 comparisons, effectively running the algorithm on a subset of the list (the first part or the last part depending on the fact we use a positive or negative rank). This is useful to limit the maximum complexity of the command. It is also useful when we expect the match to be found very early, but want to be sure that in case this is not true, the command does not take too much time to run.\n\nWhen `MAXLEN` is used, it is possible to specify 0 as the maximum number of comparisons, as a way to tell the command we want unlimited comparisons. This is better than giving a very large `MAXLEN` option because it is more general.\n\n@examples\n\n```cli\nRPUSH mylist a b c d 1 2 3 4 3 3 3\nLPOS mylist 3\nLPOS mylist 3 COUNT 0 RANK 2\n```\n\n",
            "return_summary": "The command returns the integer representing the matching element, or `nil` if there is no match. However, if the `COUNT` option is given the command returns an array (empty if there are no matches).",
            "": "",
            "summary": "Return the index of matching elements on a list",
            "complexity": "O(N) where N is the number of elements in the list, for the average case. When searching for elements near the head or the tail of the list, or when the MAXLEN option is provided, the command may run in constant time.",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "name": "element",
                    "type": "string",
                    "value": "element"
                },
                {
                    "token": "RANK",
                    "optional": true,
                    "name": "rank",
                    "type": "integer",
                    "value": "rank"
                },
                {
                    "token": "COUNT",
                    "optional": true,
                    "name": "num-matches",
                    "type": "integer",
                    "value": "num-matches"
                },
                {
                    "token": "MAXLEN",
                    "optional": true,
                    "name": "len",
                    "type": "integer",
                    "value": "len"
                }
            ],
            "since": "6.0.6",
            "group": "list",
            "arity": -3,
            "command_flags": [
                "readonly"
            ],
            "acl_categories": [
                "read",
                "list",
                "slow"
            ],
            "key_specs": [
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "lposCommand"
        }
    },
    {
        "BLPOP": {
            "body": "`BLPOP` is a blocking list pop primitive.\nIt is the blocking version of [`LPOP`](./lpop) because it blocks the connection when there\nare no elements to pop from any of the given lists.\nAn element is popped from the head of the first list that is non-empty, with the\ngiven keys being checked in the order that they are given.\n\n## Non-blocking behavior\n\nWhen `BLPOP` is called, if at least one of the specified keys contains a\nnon-empty list, an element is popped from the head of the list and returned to\nthe caller together with the `key` it was popped from.\n\nKeys are checked in the order that they are given.\nLet's say that the key `list1` doesn't exist and `list2` and `list3` hold\nnon-empty lists.\nConsider the following command:\n\n```\nBLPOP list1 list2 list3 0\n```\n\n`BLPOP` guarantees to return an element from the list stored at `list2` (since\nit is the first non empty list when checking `list1`, `list2` and `list3` in\nthat order).\n\n## Blocking behavior\n\nIf none of the specified keys exist, `BLPOP` blocks the connection until another\nclient performs an [`LPUSH`](./lpush) or [`RPUSH`](./rpush) operation against one of the keys.\n\nOnce new data is present on one of the lists, the client returns with the name\nof the key unblocking it and the popped value.\n\nWhen `BLPOP` causes a client to block and a non-zero timeout is specified,\nthe client will unblock returning a `nil` multi-bulk value when the specified\ntimeout has expired without a push operation against at least one of the\nspecified keys.\n\n**The timeout argument is interpreted as a double value specifying the maximum number of seconds to block**. A timeout of zero can be used to block indefinitely.\n\n## What key is served first? What client? What element? Priority ordering details.\n\n* If the client tries to blocks for multiple keys, but at least one key contains elements, the returned key / element pair is the first key from left to right that has one or more elements. In this case the client is not blocked. So for instance `BLPOP key1 key2 key3 key4 0`, assuming that both `key2` and `key4` are non-empty, will always return an element from `key2`.\n* If multiple clients are blocked for the same key, the first client to be served is the one that was waiting for more time (the first that blocked for the key). Once a client is unblocked it does not retain any priority, when it blocks again with the next call to `BLPOP` it will be served accordingly to the number of clients already blocked for the same key, that will all be served before it (from the first to the last that blocked).\n* When a client is blocking for multiple keys at the same time, and elements are available at the same time in multiple keys (because of a transaction or a Lua script added elements to multiple lists), the client will be unblocked using the first key that received a push operation (assuming it has enough elements to serve our client, as there may be other clients as well waiting for this key). Basically after the execution of every command Redis will run a list of all the keys that received data AND that have at least a client blocked. The list is ordered by new element arrival time, from the first key that received data to the last. For every key processed, Redis will serve all the clients waiting for that key in a FIFO fashion, as long as there are elements in this key. When the key is empty or there are no longer clients waiting for this key, the next key that received new data in the previous command / transaction / script is processed, and so forth.\n\n## Behavior of `BLPOP` when multiple elements are pushed inside a list.\n\nThere are times when a list can receive multiple elements in the context of the same conceptual command:\n\n* Variadic push operations such as `LPUSH mylist a b c`.\n* After an [`EXEC`](./exec) of a [`MULTI`](./multi) block with multiple push operations against the same list.\n* Executing a Lua Script with Redis 2.6 or newer.\n\nWhen multiple elements are pushed inside a list where there are clients blocking, the behavior is different for Redis 2.4 and Redis 2.6 or newer.\n\nFor Redis 2.6 what happens is that the command performing multiple pushes is executed, and *only after* the execution of the command the blocked clients are served. Consider this sequence of commands.\n\n    Client A:   BLPOP foo 0\n    Client B:   LPUSH foo a b c\n\nIf the above condition happens using a Redis 2.6 server or greater, Client **A** will be served with the `c` element, because after the [`LPUSH`](./lpush) command the list contains `c,b,a`, so taking an element from the left means to return `c`.\n\nInstead Redis 2.4 works in a different way: clients are served *in the context* of the push operation, so as long as `LPUSH foo a b c` starts pushing the first element to the list, it will be delivered to the Client **A**, that will receive `a` (the first element pushed).\n\nThe behavior of Redis 2.4 creates a lot of problems when replicating or persisting data into the AOF file, so the much more generic and semantically simpler behavior was introduced into Redis 2.6 to prevent problems.\n\nNote that for the same reason a Lua script or a `MULTI/EXEC` block may push elements into a list and afterward **delete the list**. In this case the blocked clients will not be served at all and will continue to be blocked as long as no data is present on the list after the execution of a single command, transaction, or script.\n\n## `BLPOP` inside a `MULTI` / `EXEC` transaction\n\n`BLPOP` can be used with pipelining (sending multiple commands and\nreading the replies in batch), however this setup makes sense almost solely\nwhen it is the last command of the pipeline.\n\nUsing `BLPOP` inside a [`MULTI`](./multi) / [`EXEC`](./exec) block does not make a lot of sense\nas it would require blocking the entire server in order to execute the block\natomically, which in turn does not allow other clients to perform a push\noperation. For this reason the behavior of `BLPOP` inside [`MULTI`](./multi) / [`EXEC`](./exec) when the list is empty is to return a `nil` multi-bulk reply, which is the same\nthing that happens when the timeout is reached.\n\nIf you like science fiction, think of time flowing at infinite speed inside a\n[`MULTI`](./multi) / [`EXEC`](./exec) block...\n\n@examples\n\n```\nredis> DEL list1 list2\n(integer) 0\nredis> RPUSH list1 a b c\n(integer) 3\nredis> BLPOP list1 list2 0\n1) \"list1\"\n2) \"a\"\n```\n\n## Reliable queues\n\nWhen `BLPOP` returns an element to the client, it also removes the element from the list. This means that the element only exists in the context of the client: if the client crashes while processing the returned element, it is lost forever.\n\nThis can be a problem with some application where we want a more reliable messaging system. When this is the case, please check the [`BRPOPLPUSH`](./brpoplpush) command, that is a variant of `BLPOP` that adds the returned element to a target list before returning it to the client.\n\n## Pattern: Event notification\n\nUsing blocking list operations it is possible to mount different blocking\nprimitives.\nFor instance for some application you may need to block waiting for elements\ninto a Redis Set, so that as far as a new element is added to the Set, it is\npossible to retrieve it without resort to polling.\nThis would require a blocking version of [`SPOP`](./spop) that is not available, but using\nblocking list operations we can easily accomplish this task.\n\nThe consumer will do:\n\n```\nLOOP forever\n    WHILE SPOP(key) returns elements\n        ... process elements ...\n    END\n    BRPOP helper_key\nEND\n```\n\nWhile in the producer side we'll use simply:\n\n```\nMULTI\nSADD key element\nLPUSH helper_key x\nEXEC\n```\n\n",
            "history": [
                [
                    "6.0",
                    "`timeout` is interpreted as a double instead of an integer."
                ]
            ],
            "": "",
            "return_types": [
                {
                    "description": "specifically:",
                    "type": "array"
                }
            ],
            "summary": "Remove and get the first element in a list, or block until one is available",
            "complexity": "O(N) where N is the number of provided keys.",
            "arguments": [
                {
                    "multiple": true,
                    "multiple_token": true,
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "name": "timeout",
                    "type": "double",
                    "value": "timeout"
                }
            ],
            "since": "2.0.0",
            "group": "list",
            "arity": -3,
            "command_flags": [
                "write",
                "noscript"
            ],
            "acl_categories": [
                "write",
                "list",
                "slow",
                "blocking"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": -2,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "blpopCommand"
        }
    },
    {
        "LASTSAVE": {
            "body": "Return the UNIX TIME of the last DB save executed with success.\nA client may check if a [`BGSAVE`](./bgsave) command succeeded reading the `LASTSAVE` value,\nthen issuing a [`BGSAVE`](./bgsave) command and checking at regular intervals every N\nseconds if `LASTSAVE` changed.\n\n",
            "": "",
            "return_types": [
                {
                    "description": "an UNIX time stamp.",
                    "type": "integer"
                }
            ],
            "summary": "Get the UNIX time stamp of the last successful save to disk",
            "since": "1.0.0",
            "group": "server",
            "arity": 1,
            "command_flags": [
                "random",
                "loading",
                "stale",
                "fast"
            ],
            "acl_categories": [
                "admin",
                "fast",
                "dangerous"
            ],
            "function": "lastsaveCommand"
        }
    },
    {
        "XPENDING": {
            "body": "Fetching data from a stream via a consumer group, and not acknowledging\nsuch data, has the effect of creating *pending entries*. This is\nwell explained in the [`XREADGROUP`](./xreadgroup) command, and even better in our\n[introduction to Redis Streams](/topics/streams-intro). The [`XACK`](./xack) command\nwill immediately remove the pending entry from the Pending Entries List (PEL)\nsince once a message is successfully processed, there is no longer need\nfor the consumer group to track it and to remember the current owner\nof the message.\n\nThe `XPENDING` command is the interface to inspect the list of pending\nmessages, and is as thus a very important command in order to observe\nand understand what is happening with a streams consumer groups: what\nclients are active, what messages are pending to be consumed, or to see\nif there are idle messages. Moreover this command, together with [`XCLAIM`](./xclaim)\nis used in order to implement recovering of consumers that are failing\nfor a long time, and as a result certain messages are not processed: a\ndifferent consumer can claim the message and continue. This is better\nexplained in the [streams intro](/topics/streams-intro) and in the\n[`XCLAIM`](./xclaim) command page, and is not covered here.\n\n## Summary form of XPENDING\n\nWhen `XPENDING` is called with just a key name and a consumer group\nname, it just outputs a summary about the pending messages in a given\nconsumer group. In the following example, we create a consumer group and\nimmediately create a pending message by reading from the group with\n[`XREADGROUP`](./xreadgroup).\n\n```\n> XGROUP CREATE mystream group55 0-0\nOK\n\n> XREADGROUP GROUP group55 consumer-123 COUNT 1 STREAMS mystream >\n1) 1) \"mystream\"\n   2) 1) 1) 1526984818136-0\n         2) 1) \"duration\"\n            2) \"1532\"\n            3) \"event-id\"\n            4) \"5\"\n            5) \"user-id\"\n            6) \"7782813\"\n```\n\nWe expect the pending entries list for the consumer group `group55` to\nhave a message right now: consumer named `consumer-123` fetched the\nmessage without acknowledging its processing. The simple `XPENDING`\nform will give us this information:\n\n```\n> XPENDING mystream group55\n1) (integer) 1\n2) 1526984818136-0\n3) 1526984818136-0\n4) 1) 1) \"consumer-123\"\n      2) \"1\"\n```\n\nIn this form, the command outputs the total number of pending messages for this\nconsumer group, which is one, followed by the smallest and greatest ID among the\npending messages, and then list every consumer in the consumer group with\nat least one pending message, and the number of pending messages it has.\n\n## Extended form of XPENDING\n\nThe summary provides a good overview, but sometimes we are interested in the\ndetails. In order to see all the pending messages with more associated\ninformation we need to also pass a range of IDs, in a similar way we do it with\n[`XRANGE`](./xrange), and a non optional *count* argument, to limit the number\nof messages returned per call:\n\n```\n> XPENDING mystream group55 - + 10\n1) 1) 1526984818136-0\n   2) \"consumer-123\"\n   3) (integer) 196415\n   4) (integer) 1\n```\n\nIn the extended form we no longer see the summary information, instead there\nis detailed information for each message in the pending entries list. For\neach message four attributes are returned:\n\n1. The ID of the message.\n2. The name of the consumer that fetched the message and has still to acknowledge it. We call it the current *owner* of the message.\n3. The number of milliseconds that elapsed since the last time this message was delivered to this consumer.\n4. The number of times this message was delivered.\n\nThe deliveries counter, that is the fourth element in the array, is incremented\nwhen some other consumer *claims* the message with [`XCLAIM`](./xclaim), or when the\nmessage is delivered again via [`XREADGROUP`](./xreadgroup), when accessing the history\nof a consumer in a consumer group (see the [`XREADGROUP`](./xreadgroup) page for more info).\n\nIt is possible to pass an additional argument to the command, in order\nto see the messages having a specific owner:\n\n```\n> XPENDING mystream group55 - + 10 consumer-123\n```\n\nBut in the above case the output would be the same, since we have pending\nmessages only for a single consumer. However what is important to keep in\nmind is that this operation, filtering by a specific consumer, is not\ninefficient even when there are many pending messages from many consumers:\nwe have a pending entries list data structure both globally, and for\nevery consumer, so we can very efficiently show just messages pending for\na single consumer.\n\n## Idle time filter\n\nSince version 6.2 it is possible to filter entries by their idle-time,\ngiven in milliseconds (useful for [`XCLAIM`](./xclaim)ing entries that have not been\nprocessed for some time):\n\n```\n> XPENDING mystream group55 IDLE 9000 - + 10\n> XPENDING mystream group55 IDLE 9000 - + 10 consumer-123\n```\n\nThe first case will return the first 10 (or less) PEL entries of the entire group\nthat are idle for over 9 seconds, whereas in the second case only those of\n`consumer-123`.\n\n## Exclusive ranges and iterating the PEL\n\nThe `XPENDING` command allows iterating over the pending entries just like\n[`XRANGE`](./xrange) and [`XREVRANGE`](./xrevrange) allow for the stream's entries. You can do this by\nprefixing the ID of the last-read pending entry with the `(` character that\ndenotes an open (exclusive) range, and proving it to the subsequent call to the\ncommand.\n\n",
            "history": [
                [
                    "6.2.0",
                    "Added the `IDLE` option and exclusive range intervals."
                ]
            ],
            "return_summary": "@array-reply, specifically:\n\nThe command returns data in different format depending on the way it is\ncalled, as previously explained in this page. However the reply is always\nan array of items.",
            "": "",
            "summary": "Return information and entries from a stream consumer group pending entries list, that are messages fetched but never acknowledged.",
            "complexity": "O(N) with N being the number of elements returned, so asking for a small fixed number of entries per call is O(1). O(M), where M is the total number of entries scanned when used with the IDLE filter. When the command returns just the summary and the list of consumers is small, it runs in O(1) time; otherwise, an additional O(N) time for iterating every consumer.",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "name": "group",
                    "type": "string",
                    "value": "group"
                },
                {
                    "optional": true,
                    "name": "filters",
                    "type": "block",
                    "value": [
                        {
                            "token": "IDLE",
                            "optional": true,
                            "name": "min-idle-time",
                            "type": "integer",
                            "value": "min-idle-time"
                        },
                        {
                            "name": "start",
                            "type": "string",
                            "value": "start"
                        },
                        {
                            "name": "end",
                            "type": "string",
                            "value": "end"
                        },
                        {
                            "name": "count",
                            "type": "integer",
                            "value": "count"
                        },
                        {
                            "optional": true,
                            "name": "consumer",
                            "type": "string",
                            "value": "consumer"
                        }
                    ]
                }
            ],
            "since": "5.0.0",
            "group": "stream",
            "arity": -3,
            "command_flags": [
                "readonly",
                "random"
            ],
            "acl_categories": [
                "read",
                "stream",
                "slow"
            ],
            "key_specs": [
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "xpendingCommand"
        }
    },
    {
        "INFO": {
            "body": "The `INFO` command returns information and statistics about the server in a\nformat that is simple to parse by computers and easy to read by humans.\n\nThe optional parameter can be used to select a specific section of information:\n\n*   `server`: General information about the Redis server\n*   `clients`: Client connections section\n*   `memory`: Memory consumption related information\n*   `persistence`: RDB and AOF related information\n*   `stats`: General statistics\n*   `replication`: Master/replica replication information\n*   `cpu`: CPU consumption statistics\n*   `commandstats`: Redis command statistics\n*   `cluster`: Redis Cluster section\n*   `modules`: Modules section\n*   `keyspace`: Database related statistics\n*   `modules`: Module related sections\n*   `errorstats`: Redis error statistics\n\nIt can also take the following values:\n\n*   `all`: Return all sections (excluding module generated ones)\n*   `default`: Return only the default set of sections\n*   `everything`: Includes `all` and `modules`\n\nWhen no parameter is provided, the `default` option is assumed.\n\n## Notes\n\nPlease note depending on the version of Redis some of the fields have been\nadded or removed. A robust client application should therefore parse the\nresult of this command by skipping unknown properties, and gracefully handle\nmissing fields.\n\nHere is the description of fields for Redis >= 2.4.\n\n\nHere is the meaning of all fields in the **server** section:\n\n*   `redis_version`: Version of the Redis server\n*   `redis_git_sha1`:  Git SHA1\n*   `redis_git_dirty`: Git dirty flag\n*   `redis_build_id`: The build id\n*   `redis_mode`: The server's mode (\"standalone\", \"sentinel\" or \"cluster\")\n*   `os`: Operating system hosting the Redis server\n*   `arch_bits`: Architecture (32 or 64 bits)\n*   `multiplexing_api`: Event loop mechanism used by Redis\n*   `atomicvar_api`: Atomicvar API used by Redis\n*   `gcc_version`: Version of the GCC compiler used to compile the Redis server\n*   `process_id`: PID of the server process\n*   `process_supervised`: Supervised system (\"upstart\", \"systemd\", \"unknown\" or \"no\")\n*   `run_id`: Random value identifying the Redis server (to be used by Sentinel\n     and Cluster)\n*   `tcp_port`: TCP/IP listen port\n*   `server_time_in_usec`: Epoch-based system time with microsecond precision\n*   `uptime_in_seconds`: Number of seconds since Redis server start\n*   `uptime_in_days`: Same value expressed in days\n*   `hz`: The server's current frequency setting\n*   `configured_hz`: The server's configured frequency setting\n*   `lru_clock`: Clock incrementing every minute, for LRU management\n*   `executable`: The path to the server's executable\n*   `config_file`: The path to the config file\n\nHere is the meaning of all fields in the **clients** section:\n\n*   `connected_clients`: Number of client connections (excluding connections\n     from replicas)\n*   `cluster_connections`: An approximation of the number of sockets used by the\n     cluster's bus\n*   `maxclients`: The value of the `maxclients` configuration directive. This is\n    the upper limit for the sum of `connected_clients`, `connected_slaves` and\n    `cluster_connections`.\n*   `client_longest_output_list`: Longest output list among current client\n     connections\n*   `client_biggest_input_buf`: Biggest input buffer among current client\n     connections\n*   `blocked_clients`: Number of clients pending on a blocking call ([`BLPOP`](./blpop),\n     [`BRPOP`](./brpop), [`BRPOPLPUSH`](./brpoplpush), [`BLMOVE`](./blmove), [`BZPOPMIN`](./bzpopmin), [`BZPOPMAX`](./bzpopmax))\n*   `tracking_clients`: Number of clients being tracked (`CLIENT TRACKING`)\n*   `clients_in_timeout_table`: Number of clients in the clients timeout table\n*    `io_threads_active`: Flag indicating if I/O threads are active\n\nHere is the meaning of all fields in the **memory** section:\n\n*   `used_memory`: Total number of bytes allocated by Redis using its\n     allocator (either standard **libc**, **jemalloc**, or an alternative\n     allocator such as [**tcmalloc**][hcgcpgp])\n*   `used_memory_human`: Human readable representation of previous value\n*   `used_memory_rss`: Number of bytes that Redis allocated as seen by the\n     operating system (a.k.a resident set size). This is the number reported by\n     tools such as `top(1)` and `ps(1)`\n*   `used_memory_rss_human`: Human readable representation of previous value\n*   `used_memory_peak`: Peak memory consumed by Redis (in bytes)\n*   `used_memory_peak_human`: Human readable representation of previous value\n*   `used_memory_peak_perc`: The percentage of `used_memory_peak` out of\n     `used_memory`\n*   `used_memory_overhead`: The sum in bytes of all overheads that the server\n     allocated for managing its internal data structures\n*   `used_memory_startup`: Initial amount of memory consumed by Redis at startup\n     in bytes\n*   `used_memory_dataset`: The size in bytes of the dataset\n     (`used_memory_overhead` subtracted from `used_memory`)\n*   `used_memory_dataset_perc`: The percentage of `used_memory_dataset` out of\n     the net memory usage (`used_memory` minus `used_memory_startup`)\n*   `total_system_memory`: The total amount of memory that the Redis host has\n*   `total_system_memory_human`: Human readable representation of previous value\n*   `used_memory_lua`: Number of bytes used by the Lua engine\n*   `used_memory_lua_human`: Human readable representation of previous value\n*   `used_memory_scripts`: Number of bytes used by cached Lua scripts\n*   `used_memory_scripts_human`: Human readable representation of previous value\n*   `maxmemory`: The value of the `maxmemory` configuration directive\n*   `maxmemory_human`: Human readable representation of previous value\n*   `maxmemory_policy`: The value of the `maxmemory-policy` configuration\n     directive\n*   `mem_fragmentation_ratio`: Ratio between `used_memory_rss` and `used_memory`.\n    Note that this doesn't only includes fragmentation, but also other process overheads (see the `allocator_*` metrics), and also overheads like code, shared libraries, stack, etc.\n*   `mem_fragmentation_bytes`: Delta between `used_memory_rss` and `used_memory`.\n    Note that when the total fragmentation bytes is low (few megabytes), a high ratio (e.g. 1.5 and above) is not an indication of an issue.\n*   `allocator_frag_ratio:`: Ratio between `allocator_active` and `allocator_allocated`. This is the true (external) fragmentation metric (not `mem_fragmentation_ratio`).\n*   `allocator_frag_bytes` Delta between `allocator_active` and `allocator_allocated`. See note about `mem_fragmentation_bytes`.\n*   `allocator_rss_ratio`: Ratio between `allocator_resident` and `allocator_active`. This usually indicates pages that the allocator can and probably will soon release back to the OS.\n*   `allocator_rss_bytes`: Delta between `allocator_resident` and `allocator_active`\n*   `rss_overhead_ratio`: Ratio between `used_memory_rss` (the process RSS) and `allocator_resident`. This includes RSS overheads that are not allocator or heap related.\n*   `rss_overhead_bytes`: Delta between `used_memory_rss` (the process RSS) and `allocator_resident`\n*   `allocator_allocated`: Total bytes allocated form the allocator, including internal-fragmentation. Normally the same as `used_memory`.\n*   `allocator_active`: Total bytes in the allocator active pages, this includes external-fragmentation.\n*   `allocator_resident`: Total bytes resident (RSS) in the allocator, this includes pages that can be released to the OS (by `MEMORY PURGE`, or just waiting).\n*   `mem_not_counted_for_evict`: Used memory that's not counted for key eviction. This is basically transient replica and AOF buffers.\n*   `mem_clients_normal`: Memory used by normal clients\n*   `mem_clients_slaves`: Memory used by replica clients - Starting Redis 7.0, replica buffers share memory with the replication backlog, so this field can show 0 when replicas don't trigger an increase of memory usage.\n*   `mem_aof_buffer`: Transient memory used for AOF and AOF rewrite buffers\n*   `mem_replication_backlog`: Memory used by replication backlog\n*   `mem_total_replication_buffers`: Total memory consumed for replication buffers - Added in Redis 7.0.\n*   `mem_allocator`: Memory allocator, chosen at compile time.\n*   `active_defrag_running`: When `activedefrag` is enabled, this indicates whether defragmentation is currently active, and the CPU percentage it intends to utilize.\n*   `lazyfree_pending_objects`: The number of objects waiting to be freed (as a\n     result of calling [`UNLINK`](./unlink), or [`FLUSHDB`](./flushdb) and [`FLUSHALL`](./flushall) with the **ASYNC**\n     option)\n\nIdeally, the `used_memory_rss` value should be only slightly higher than\n`used_memory`.\nWhen rss >> used, a large difference may mean there is (external) memory fragmentation, which can be evaluated by checking\n`allocator_frag_ratio`, `allocator_frag_bytes`.\nWhen used >> rss, it means part of Redis memory has been swapped off by the\noperating system: expect some significant latencies.\n\nBecause Redis does not have control over how its allocations are mapped to\nmemory pages, high `used_memory_rss` is often the result of a spike in memory\nusage.\n\nWhen Redis frees memory, the memory is given back to the allocator, and the\nallocator may or may not give the memory back to the system. There may be\na discrepancy between the `used_memory` value and memory consumption as\nreported by the operating system. It may be due to the fact memory has been\nused and released by Redis, but not given back to the system. The\n`used_memory_peak` value is generally useful to check this point.\n\nAdditional introspective information about the server's memory can be obtained\nby referring to the `MEMORY STATS` command and the `MEMORY DOCTOR`.\n\nHere is the meaning of all fields in the **persistence** section:\n\n*   `loading`: Flag indicating if the load of a dump file is on-going\n*   `current_cow_peak`: The peak size in bytes of copy-on-write memory\n     while a child fork is running\n*   `current_cow_size`: The size in bytes of copy-on-write memory\n     while a child fork is running\n*   `current_fork_perc`: The percentage of progress of the current fork process. For AOF and RDB forks it is the percentage of `current_save_keys_processed` out of `current_save_keys_total`.\n*   `current_save_keys_processed`: Number of keys processed by the current save operation\n*   `current_save_keys_total`: Number of keys at the beginning of the current save operation \n*   `rdb_changes_since_last_save`: Number of changes since the last dump\n*   `rdb_bgsave_in_progress`: Flag indicating a RDB save is on-going\n*   `rdb_last_save_time`: Epoch-based timestamp of last successful RDB save\n*   `rdb_last_bgsave_status`: Status of the last RDB save operation\n*   `rdb_last_bgsave_time_sec`: Duration of the last RDB save operation in\n     seconds\n*   `rdb_current_bgsave_time_sec`: Duration of the on-going RDB save operation\n     if any\n*   `rdb_last_cow_size`: The size in bytes of copy-on-write memory during\n     the last RDB save operation\n*   `aof_enabled`: Flag indicating AOF logging is activated\n*   `aof_rewrite_in_progress`: Flag indicating a AOF rewrite operation is\n     on-going\n*   `aof_rewrite_scheduled`: Flag indicating an AOF rewrite operation\n     will be scheduled once the on-going RDB save is complete.\n*   `aof_last_rewrite_time_sec`: Duration of the last AOF rewrite operation in\n     seconds\n*   `aof_current_rewrite_time_sec`: Duration of the on-going AOF rewrite\n     operation if any\n*   `aof_last_bgrewrite_status`: Status of the last AOF rewrite operation\n*   `aof_last_write_status`: Status of the last write operation to the AOF\n*   `aof_last_cow_size`: The size in bytes of copy-on-write memory during\n     the last AOF rewrite operation\n*   `module_fork_in_progress`: Flag indicating a module fork is on-going\n*   `module_fork_last_cow_size`: The size in bytes of copy-on-write memory\n     during the last module fork operation\n\n`rdb_changes_since_last_save` refers to the number of operations that produced\nsome kind of changes in the dataset since the last time either [`SAVE`](./save) or\n[`BGSAVE`](./bgsave) was called.\n\nIf AOF is activated, these additional fields will be added:\n\n*   `aof_current_size`: AOF current file size\n*   `aof_base_size`: AOF file size on latest startup or rewrite\n*   `aof_pending_rewrite`: Flag indicating an AOF rewrite operation\n     will be scheduled once the on-going RDB save is complete.\n*   `aof_buffer_length`: Size of the AOF buffer\n*   `aof_rewrite_buffer_length`: Size of the AOF rewrite buffer\n*   `aof_pending_bio_fsync`: Number of fsync pending jobs in background I/O\n     queue\n*   `aof_delayed_fsync`: Delayed fsync counter\n\nIf a load operation is on-going, these additional fields will be added:\n\n*   `loading_start_time`: Epoch-based timestamp of the start of the load\n     operation\n*   `loading_total_bytes`: Total file size\n*   `loading_rdb_used_mem`: The memory usage of the server that had generated\n    the RDB file at the time of the file's creation\n*   `loading_loaded_bytes`: Number of bytes already loaded\n*   `loading_loaded_perc`: Same value expressed as a percentage\n*   `loading_eta_seconds`: ETA in seconds for the load to be complete\n\nHere is the meaning of all fields in the **stats** section:\n\n*   `total_connections_received`: Total number of connections accepted by the\n     server\n*   `total_commands_processed`: Total number of commands processed by the server\n*   `instantaneous_ops_per_sec`: Number of commands processed per second\n*   `total_net_input_bytes`: The total number of bytes read from the network\n*   `total_net_output_bytes`: The total number of bytes written to the network\n*   `instantaneous_input_kbps`: The network's read rate per second in KB/sec\n*   `instantaneous_output_kbps`: The network's write rate per second in KB/sec\n*   `rejected_connections`: Number of connections rejected because of\n     `maxclients` limit\n*   `sync_full`: The number of full resyncs with replicas\n*   `sync_partial_ok`: The number of accepted partial resync requests\n*   `sync_partial_err`: The number of denied partial resync requests\n*   `expired_keys`: Total number of key expiration events\n*   `expired_stale_perc`: The percentage of keys probably expired\n*   `expired_time_cap_reached_count`: The count of times that active expiry cycles have stopped early\n*   `expire_cycle_cpu_milliseconds`: The cumulative amount of time spend on active expiry cycles\n*   `evicted_keys`: Number of evicted keys due to `maxmemory` limit\n*   `total_eviction_exceeded_time`:  Total time `used_memory` was greater than `maxmemory` since server startup, in milliseconds\n*   `current_eviction_exceeded_time`: The time passed since `used_memory` last rose above `maxmemory`, in milliseconds\n*   `keyspace_hits`: Number of successful lookup of keys in the main dictionary\n*   `keyspace_misses`: Number of failed lookup of keys in the main dictionary\n*   `pubsub_channels`: Global number of pub/sub channels with client\n     subscriptions\n*   `pubsub_patterns`: Global number of pub/sub pattern with client\n     subscriptions\n*   `latest_fork_usec`: Duration of the latest fork operation in microseconds\n*   `total_forks`: Total number of fork operations since the server start\n*   `migrate_cached_sockets`: The number of sockets open for [`MIGRATE`](./migrate) purposes\n*   `slave_expires_tracked_keys`: The number of keys tracked for expiry purposes\n     (applicable only to writable replicas)\n*   `active_defrag_hits`: Number of value reallocations performed by active the\n     defragmentation process\n*   `active_defrag_misses`: Number of aborted value reallocations started by the\n     active defragmentation process\n*   `active_defrag_key_hits`: Number of keys that were actively defragmented\n*   `active_defrag_key_misses`: Number of keys that were skipped by the active\n     defragmentation process\n*   `total_active_defrag_time`: Total time memory fragmentation was over the limit, in milliseconds\n*   `current_active_defrag_time`: The time passed since memory fragmentation last was over the limit, in milliseconds\n*   `tracking_total_keys`: Number of keys being tracked by the server\n*   `tracking_total_items`: Number of items, that is the sum of clients number for\n     each key, that are being tracked\n*   `tracking_total_prefixes`: Number of tracked prefixes in server's prefix table\n    (only applicable for broadcast mode)\n*   `unexpected_error_replies`: Number of unexpected error replies, that are types\n    of errors from an AOF load or replication\n*   `total_error_replies`: Total number of issued error replies, that is the sum of\n    rejected commands (errors prior command execution) and\n    failed commands (errors within the command execution)\n*    `total_reads_processed`: Total number of read events processed\n*    `total_writes_processed`: Total number of write events processed\n*    `io_threaded_reads_processed`: Number of read events processed by the main and I/O threads\n*    `io_threaded_writes_processed`: Number of write events processed by the main and I/O threads\n\nHere is the meaning of all fields in the **replication** section:\n\n*   `role`: Value is \"master\" if the instance is replica of no one, or \"slave\" if the instance is a replica of some master instance.\n     Note that a replica can be master of another replica (chained replication).\n*   `master_failover_state`: The state of an ongoing failover, if any.\n*   `master_replid`: The replication ID of the Redis server.\n*   `master_replid2`: The secondary replication ID, used for PSYNC after a failover.\n*   `master_repl_offset`: The server's current replication offset\n*   `second_repl_offset`: The offset up to which replication IDs are accepted\n*   `repl_backlog_active`: Flag indicating replication backlog is active\n*   `repl_backlog_size`: Total size in bytes of the replication backlog buffer\n*   `repl_backlog_first_byte_offset`: The master offset of the replication\n     backlog buffer\n*   `repl_backlog_histlen`: Size in bytes of the data in the replication backlog\n     buffer\n\nIf the instance is a replica, these additional fields are provided:\n\n*   `master_host`: Host or IP address of the master\n*   `master_port`: Master listening TCP port\n*   `master_link_status`: Status of the link (up/down)\n*   `master_last_io_seconds_ago`: Number of seconds since the last interaction\n     with master\n*   `master_sync_in_progress`: Indicate the master is syncing to the replica\n*   `slave_repl_offset`: The replication offset of the replica instance\n*   `slave_priority`: The priority of the instance as a candidate for failover\n*   `slave_read_only`: Flag indicating if the replica is read-only\n\nIf a SYNC operation is on-going, these additional fields are provided:\n\n*   `master_sync_total_bytes`: Total number of bytes that need to be \n    transferred. this may be 0 when the size is unknown (for example, when\n    the `repl-diskless-sync` configuration directive is used)\n*   `master_sync_read_bytes`: Number of bytes already transferred\n*   `master_sync_left_bytes`: Number of bytes left before syncing is complete\n    (may be negative when `master_sync_total_bytes` is 0)\n*   `master_sync_perc`: The percentage `master_sync_read_bytes` from \n    `master_sync_total_bytes`, or an approximation that uses\n    `loading_rdb_used_mem` when `master_sync_total_bytes` is 0\n*   `master_sync_last_io_seconds_ago`: Number of seconds since last transfer I/O\n     during a SYNC operation\n\nIf the link between master and replica is down, an additional field is provided:\n\n*   `master_link_down_since_seconds`: Number of seconds since the link is down\n\nThe following field is always provided:\n\n*   `connected_slaves`: Number of connected replicas\n\nIf the server is configured with the `min-slaves-to-write` (or starting with Redis 5 with the `min-replicas-to-write`) directive, an additional field is provided:\n\n*   `min_slaves_good_slaves`: Number of replicas currently considered good\n\nFor each replica, the following line is added:\n\n*   `slaveXXX`: id, IP address, port, state, offset, lag\n\nHere is the meaning of all fields in the **cpu** section:\n\n*   `used_cpu_sys`: System CPU consumed by the Redis server, which is the sum of system CPU consumed by all threads of the server process (main thread and background threads)\n*   `used_cpu_user`: User CPU consumed by the Redis server, which is the sum of user CPU consumed by all threads of the server process (main thread and background threads)\n*   `used_cpu_sys_children`: System CPU consumed by the background processes\n*   `used_cpu_user_children`: User CPU consumed by the background processes\n*   `used_cpu_sys_main_thread`: System CPU consumed by the Redis server main thread\n*   `used_cpu_user_main_thread`: User CPU consumed by the Redis server main thread\n\nThe **commandstats** section provides statistics based on the command type,\n including the number of calls that reached command execution (not rejected),\n the total CPU time consumed by these commands, the average CPU consumed\n per command execution, the number of rejected calls\n (errors prior command execution), and the number of failed calls\n (errors within the command execution).\n\nFor each command type, the following line is added:\n\n*   `cmdstat_XXX`: `calls=XXX,usec=XXX,usec_per_call=XXX,rejected_calls=XXX,failed_calls=XXX`\n\nThe **errorstats** section enables keeping track of the different errors that occurred within Redis, \n based upon the reply error prefix ( The first word after the \"-\", up to the first space. Example: `ERR` ).\n\nFor each error type, the following line is added:\n\n*   `errorstat_XXX`: `count=XXX`\n\nThe **cluster** section currently only contains a unique field:\n\n*   `cluster_enabled`: Indicate Redis cluster is enabled\n\nThe **modules** section contains additional information about loaded modules if the modules provide it. The field part of properties lines in this section is always prefixed with the module's name.\n\nThe **keyspace** section provides statistics on the main dictionary of each\ndatabase.\nThe statistics are the number of keys, and the number of keys with an expiration.\n\nFor each database, the following line is added:\n\n*   `dbXXX`: `keys=XXX,expires=XXX`\n\n[hcgcpgp]: http://code.google.com/p/google-perftools/\n\n**A note about the word slave used in this man page**: Starting with Redis 5, if not for backward compatibility, the Redis project no longer uses the word slave. Unfortunately in this command the word slave is part of the protocol, so we'll be able to remove such occurrences only when this API will be naturally deprecated.\n\n**Modules generated sections**: Starting with Redis 6, modules can inject their info into the `INFO` command, these are excluded by default even when the `all` argument is provided (it will include a list of loaded modules but not their generated info fields). To get these you must use either the `modules` argument or `everything`.,\n\n",
            "deprecated": true,
            "": "",
            "return_types": [
                {
                    "description": "as a collection of text lines.",
                    "type": "bulk-string"
                }
            ],
            "summary": "Get information and statistics about the server",
            "arguments": [
                {
                    "optional": true,
                    "name": "section",
                    "type": "string",
                    "value": "section"
                }
            ],
            "since": "1.0.0",
            "group": "server",
            "arity": -1,
            "command_flags": [
                "random",
                "loading",
                "stale"
            ],
            "acl_categories": [
                "slow",
                "dangerous"
            ],
            "function": "infoCommand"
        }
    },
    {
        "HOST:": {
            "arity": -1,
            "command_flags": [
                "readonly",
                "loading",
                "stale"
            ],
            "acl_categories": [
                "read",
                "slow"
            ],
            "function": "securityWarningCommand",
            "group": "server",
            "internal": true
        }
    },
    {
        "PFSELFTEST": {
            "arity": 1,
            "command_flags": [
                "admin"
            ],
            "acl_categories": [
                "hyperloglog",
                "admin",
                "slow",
                "dangerous"
            ],
            "function": "pfselftestCommand",
            "group": "hyperloglog",
            "internal": true
        }
    },
    {
        "SLAVEOF": {
            "body": "**A note about the word slave used in this man page and command name**: Starting with Redis 5 this command: starting with Redis version 5, if not for backward compatibility, the Redis project no longer uses the word slave. Please use the new command [`REPLICAOF`](./replicaof). The command `SLAVEOF` will continue to work for backward compatibility.\n\nThe `SLAVEOF` command can change the replication settings of a replica on the fly.\nIf a Redis server is already acting as replica, the command `SLAVEOF` NO ONE will\nturn off the replication, turning the Redis server into a MASTER.\nIn the proper form `SLAVEOF` hostname port will make the server a replica of\nanother server listening at the specified hostname and port.\n\nIf a server is already a replica of some master, `SLAVEOF` hostname port will stop\nthe replication against the old server and start the synchronization against the\nnew one, discarding the old dataset.\n\nThe form `SLAVEOF` NO ONE will stop replication, turning the server into a\nMASTER, but will not discard the replication.\nSo, if the old master stops working, it is possible to turn the replica into a\nmaster and set the application to use this new master in read/write.\nLater when the other Redis server is fixed, it can be reconfigured to work as a\nreplica.\n\n",
            "": "",
            "return_types": [
                {
                    "type": "simple-string"
                }
            ],
            "summary": "Make the server a replica of another instance, or promote it as master. Deprecated starting with Redis 5. Use REPLICAOF instead.",
            "arguments": [
                {
                    "name": "host",
                    "type": "string",
                    "value": "host"
                },
                {
                    "name": "port",
                    "type": "string",
                    "value": "port"
                }
            ],
            "since": "1.0.0",
            "group": "server",
            "arity": 3,
            "command_flags": [
                "admin",
                "noscript",
                "stale"
            ],
            "acl_categories": [
                "admin",
                "slow",
                "dangerous"
            ],
            "function": "replicaofCommand"
        }
    },
    {
        "HLEN": {
            "body": "Returns the number of fields contained in the hash stored at `key`.\n\n@examples\n\n```cli\nHSET myhash field1 \"Hello\"\nHSET myhash field2 \"World\"\nHLEN myhash\n```\n\n",
            "": "",
            "return_types": [
                {
                    "description": "number of fields in the hash, or `0` when `key` does not exist.",
                    "type": "integer"
                }
            ],
            "summary": "Get the number of fields in a hash",
            "complexity": "O(1)",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                }
            ],
            "since": "2.0.0",
            "group": "hash",
            "arity": 2,
            "command_flags": [
                "readonly",
                "fast"
            ],
            "acl_categories": [
                "read",
                "hash",
                "fast"
            ],
            "key_specs": [
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "hlenCommand"
        }
    },
    {
        "EVAL": {
            "body": "## Introduction to EVAL\n\n`EVAL` and [`EVALSHA`](./evalsha) are used to evaluate scripts using the Lua interpreter\nbuilt into Redis starting from version 2.6.0.\n\nThe first argument of `EVAL` is a Lua 5.1 script.\nThe script does not need to define a Lua function (and should not).\nIt is just a Lua program that will run in the context of the Redis server.\n\nThe second argument of `EVAL` is the number of arguments that follows the script\n(starting from the third argument) that represent Redis key names.\nThe arguments can be accessed by Lua using the `KEYS` global variable in the\nform of a one-based array (so `KEYS[1]`, `KEYS[2]`, ...).\n\nAll the additional arguments should not represent key names and can be accessed\nby Lua using the `ARGV` global variable, very similarly to what happens with\nkeys (so `ARGV[1]`, `ARGV[2]`, ...).\n\nThe following example should clarify what stated above:\n\n```\n> eval \"return {KEYS[1],KEYS[2],ARGV[1],ARGV[2], ARGV[3]}\" 2 key1 key2 first second third\n1) \"key1\"\n2) \"key2\"\n3) \"first\"\n4) \"second\"\n5) \"third\"\n```\n\nNote: as you can see Lua arrays are returned as Redis multi bulk replies, that\nis a Redis return type that your client library will likely convert into an\nArray type in your programming language.\n\nIt is possible to call Redis commands from a Lua script using two different Lua\nfunctions:\n\n* `redis.call()`\n* `redis.pcall()`\n\n`redis.call()` is similar to `redis.pcall()`, the only difference is that if a\nRedis command call will result in an error, `redis.call()` will raise a Lua\nerror that in turn will force `EVAL` to return an error to the command caller,\nwhile `redis.pcall` will trap the error and return a Lua table representing the\nerror.\n\nThe arguments of the `redis.call()` and `redis.pcall()` functions are all\nthe arguments of a well formed Redis command:\n\n```\n> eval \"return redis.call('set','foo','bar')\" 0\nOK\n```\n\nThe above script sets the key `foo` to the string `bar`.\nHowever it violates the `EVAL` command semantics as all the keys that the script\nuses should be passed using the `KEYS` array:\n\n```\n> eval \"return redis.call('set',KEYS[1],'bar')\" 1 foo\nOK\n```\n\nAll Redis commands must be analyzed before execution to determine which\nkeys the command will operate on.  In order for this to be true for `EVAL`, keys must be passed explicitly.\nThis is useful in many ways, but especially to make sure Redis Cluster\ncan forward your request to the appropriate cluster node.\n\nNote this rule is not enforced in order to provide the user with\nopportunities to abuse the Redis single instance configuration, at the cost of\nwriting scripts not compatible with Redis Cluster.\n\nLua scripts can return a value that is converted from the Lua type to the Redis\nprotocol using a set of conversion rules.\n\n## Conversion between Lua and Redis data types\n\nRedis return values are converted into Lua data types when Lua calls a Redis\ncommand using `call()` or `pcall()`.\nSimilarly, Lua data types are converted into the Redis protocol when calling\na Redis command and when a Lua script returns a value, so that scripts can\ncontrol what `EVAL` will return to the client.\n\nThis conversion between data types is designed in a way that if a Redis type is\nconverted into a Lua type, and then the result is converted back into a Redis\ntype, the result is the same as the initial value.\n\nIn other words there is a one-to-one conversion between Lua and Redis types.\nThe following table shows you all the conversions rules:\n\n**Redis to Lua** conversion table.\n\n* Redis integer reply -> Lua number\n* Redis bulk reply -> Lua string\n* Redis multi bulk reply -> Lua table (may have other Redis data types nested)\n* Redis status reply -> Lua table with a single `ok` field containing the status\n* Redis error reply -> Lua table with a single `err` field containing the error\n* Redis Nil bulk reply and Nil multi bulk reply -> Lua false boolean type\n\n**Lua to Redis** conversion table.\n\n* Lua number -> Redis integer reply (the number is converted into an integer)\n* Lua string -> Redis bulk reply\n* Lua table (array) -> Redis multi bulk reply (truncated to the first nil inside the Lua array if any)\n* Lua table with a single `ok` field -> Redis status reply\n* Lua table with a single `err` field -> Redis error reply\n* Lua boolean false -> Redis Nil bulk reply.\n\nThere is an additional Lua-to-Redis conversion rule that has no corresponding\nRedis to Lua conversion rule:\n\n* Lua boolean true -> Redis integer reply with value of 1.\n\nLastly, there are three important rules to note:\n\n* Lua has a single numerical type, Lua numbers. There is no distinction between integers and floats. So we always convert Lua numbers into integer replies, removing the decimal part of the number if any. **If you want to return a float from Lua you should return it as a string**, exactly like Redis itself does (see for instance the [`ZSCORE`](./zscore) command).\n* There is [no simple way to have nils inside Lua arrays](http://www.lua.org/pil/19.1.html), this is a result of Lua table semantics, so when Redis converts a Lua array into Redis protocol the conversion is stopped if a nil is encountered.\n* When a Lua table contains keys (and their values), the converted Redis reply will **not** include them.\n\n**RESP3 mode conversion rules**: note that the Lua engine can work in RESP3 mode using the new Redis 6 protocol. In this case there are additional conversion rules, and certain conversions are also modified compared to the RESP2 mode. Please refer to the RESP3 section of this document for more information.\n\nHere are a few conversion examples:\n\n```\n> eval \"return 10\" 0\n(integer) 10\n\n> eval \"return {1,2,{3,'Hello World!'}}\" 0\n1) (integer) 1\n2) (integer) 2\n3) 1) (integer) 3\n   2) \"Hello World!\"\n\n> eval \"return redis.call('get','foo')\" 0\n\"bar\"\n```\nThe last example shows how it is possible to receive the exact return value of\n`redis.call()` or `redis.pcall()` from Lua that would be returned if the command\nwas called directly.\n\nIn the following example we can see how floats and arrays containing nils and keys are handled:\n\n```\n> eval \"return {1,2,3.3333,somekey='somevalue','foo',nil,'bar'}\" 0\n1) (integer) 1\n2) (integer) 2\n3) (integer) 3\n4) \"foo\"\n```\n\nAs you can see 3.333 is converted into 3, *somekey* is excluded, and the *bar* string is never returned as there is a nil before.\n\n## Helper functions to return Redis types\n\nThere are two helper functions to return Redis types from Lua.\n\n* `redis.error_reply(error_string)` returns an error reply. This function simply returns a single field table with the `err` field set to the specified string for you.\n* `redis.status_reply(status_string)` returns a status reply. This function simply returns a single field table with the `ok` field set to the specified string for you.\n\nThere is no difference between using the helper functions or directly returning the table with the specified format, so the following two forms are equivalent:\n\n    return {err=\"My Error\"}\n    return redis.error_reply(\"My Error\")\n\n## Atomicity of scripts\n\nRedis uses the same Lua interpreter to run all the commands.\nAlso Redis guarantees that a script is executed in an atomic way: no other\nscript or Redis command will be executed while a script is being executed.\nThis semantic is similar to the one of [`MULTI`](./multi) / [`EXEC`](./exec).\nFrom the point of view of all the other clients the effects of a script are\neither still not visible or already completed.\n\nHowever this also means that executing slow scripts is not a good idea.\nIt is not hard to create fast scripts, as the script overhead is very low, but\nif you are going to use slow scripts you should be aware that while the script\nis running no other client can execute commands.\n\n## Error handling\n\nAs already stated, calls to `redis.call()` resulting in a Redis command error\nwill stop the execution of the script and return an error, in a way that\nmakes it obvious that the error was generated by a script:\n\n```\n> del foo\n(integer) 1\n> lpush foo a\n(integer) 1\n> eval \"return redis.call('get','foo')\" 0\n(error) ERR Error running script (call to f_6b1bf486c81ceb7edf3c093f4c48582e38c0e791): ERR Operation against a key holding the wrong kind of value\n```\n\nUsing `redis.pcall()` no error is raised, but an error object is\nreturned in the format specified above (as a Lua table with an `err` field).\nThe script can pass the exact error to the user by returning the error object\nreturned by `redis.pcall()`.\n\n## Running Lua under low memory conditions\n\nWhen the memory usage in Redis exceeds the `maxmemory` limit, the first write command encountered in the Lua script that uses additional memory will cause the script to abort (unless `redis.pcall` was used).\nHowever, one thing to caution here is that if the first write command does not use additional memory such as DEL, LREM, or SREM, etc, Redis will allow it to run and all subsequent commands in the Lua script will execute to completion for atomicity.\nIf the subsequent writes in the script generate additional memory, the Redis memory usage can go over `maxmemory`.\n\nAnother possible way for Lua script to cause Redis memory usage to go above `maxmemory` happens when the script execution starts when Redis is slightly below `maxmemory` so the first write command in the script is allowed.\nAs the script executes, subsequent write commands continue to generate memory and causes the Redis server to go above `maxmemory`.\n\nIn those scenarios, it is recommended to configure the `maxmemory-policy` not to use `noeviction`.\nAlso Lua scripts should be short so that evictions of items can happen in between Lua scripts.\n\n## Bandwidth and EVALSHA\n\nThe `EVAL` command forces you to send the script body again and again.\nRedis does not need to recompile the script every time as it uses an internal\ncaching mechanism, however paying the cost of the additional bandwidth may not\nbe optimal in many contexts.\n\nOn the other hand, defining commands using a special command or via `redis.conf`\nwould be a problem for a few reasons:\n\n*   Different instances may have different implementations of a command.\n\n*   Deployment is hard if we have to make sure all instances contain a\n    given command, especially in a distributed environment.\n\n*   Reading application code, the complete semantics might not be clear since the\n    application calls commands defined server side.\n\nIn order to avoid these problems while avoiding the bandwidth penalty, Redis\nimplements the [`EVALSHA`](./evalsha) command.\n\n[`EVALSHA`](./evalsha) works exactly like `EVAL`, but instead of having a script as the first\nargument it has the SHA1 digest of a script.\nThe behavior is the following:\n\n*   If the server still remembers a script with a matching SHA1 digest, the\n    script is executed.\n\n*   If the server does not remember a script with this SHA1 digest, a special\n    error is returned telling the client to use `EVAL` instead.\n\nExample:\n\n```\n> set foo bar\nOK\n> eval \"return redis.call('get','foo')\" 0\n\"bar\"\n> evalsha 6b1bf486c81ceb7edf3c093f4c48582e38c0e791 0\n\"bar\"\n> evalsha ffffffffffffffffffffffffffffffffffffffff 0\n(error) NOSCRIPT No matching script. Please use EVAL.\n```\n\nThe client library implementation can always optimistically send [`EVALSHA`](./evalsha) under\nthe hood even when the client actually calls `EVAL`, in the hope the script was\nalready seen by the server.\nIf the `NOSCRIPT` error is returned `EVAL` will be used instead.\n\nPassing keys and arguments as additional `EVAL` arguments is also very useful in\nthis context as the script string remains constant and can be efficiently cached\nby Redis.\n\n## Script cache semantics\n\nExecuted scripts are guaranteed to be in the script cache of a given execution\nof a Redis instance forever. This means that if an `EVAL` is performed against a Redis instance all the subsequent [`EVALSHA`](./evalsha) calls will succeed.\n\nThe reason why scripts can be cached for long time is that it is unlikely for\na well written application to have enough different scripts to cause memory\nproblems. Every script is conceptually like the implementation of a new command, and even a large application will likely have just a few hundred of them.\nEven if the application is modified many times and scripts will change, the\nmemory used is negligible.\n\nThe only way to flush the script cache is by explicitly calling the `SCRIPT FLUSH` command, which will _completely flush_ the scripts cache removing all the\nscripts executed so far.\n\nThis is usually needed only when the instance is going to be instantiated for\nanother customer or application in a cloud environment.\n\nAlso, as already mentioned, restarting a Redis instance flushes the\nscript cache, which is not persistent. However from the point of view of the\nclient there are only two ways to make sure a Redis instance was not restarted\nbetween two different commands.\n\n* The connection we have with the server is persistent and was never closed so far.\n* The client explicitly checks the `runid` field in the [`INFO`](./info) command in order to make sure the server was not restarted and is still the same process.\n\nPractically speaking, for the client it is much better to simply assume that in the context of a given connection, cached scripts are guaranteed to be there\nunless an administrator explicitly called the `SCRIPT FLUSH` command.\n\nThe fact that the user can count on Redis not removing scripts is semantically\nuseful in the context of pipelining.\n\nFor instance an application with a persistent connection to Redis can be sure\nthat if a script was sent once it is still in memory, so EVALSHA can be used\nagainst those scripts in a pipeline without the chance of an error being\ngenerated due to an unknown script (we'll see this problem in detail later).\n\nA common pattern is to call `SCRIPT LOAD` to load all the scripts that will\nappear in a pipeline, then use [`EVALSHA`](./evalsha) directly inside the pipeline without\nany need to check for errors resulting from the script hash not being\nrecognized.\n\n## The SCRIPT command\n\nRedis offers a SCRIPT command that can be used in order to control the scripting\nsubsystem.\nSCRIPT currently accepts three different commands:\n\n*   `SCRIPT FLUSH`\n\n    This command is the only way to force Redis to flush the scripts cache.\n    It is most useful in a cloud environment where the same instance can be\n    reassigned to a different user.\n    It is also useful for testing client libraries' implementations of the\n    scripting feature.\n\n*   `SCRIPT EXISTS sha1 sha2 ... shaN`\n\n    Given a list of SHA1 digests as arguments this command returns an array of\n    1 or 0, where 1 means the specific SHA1 is recognized as a script already\n    present in the scripting cache, while 0 means that a script with this SHA1\n    was never seen before (or at least never seen after the latest SCRIPT FLUSH\n    command).\n\n*   `SCRIPT LOAD script`\n\n    This command registers the specified script in the Redis script cache.\n    The command is useful in all the contexts where we want to make sure that\n    [`EVALSHA`](./evalsha) will not fail (for instance during a pipeline or MULTI/EXEC\n    operation), without the need to actually execute the script.\n\n*   `SCRIPT KILL`\n\n    This command is the only way to interrupt a long-running script that reaches\n    the configured maximum execution time for scripts.\n    The SCRIPT KILL command can only be used with scripts that did not modify\n    the dataset during their execution (since stopping a read-only script does\n    not violate the scripting engine's guaranteed atomicity).\n    See the next sections for more information about long running scripts.\n\n## Scripts with deterministic writes\n\n*Note: starting with Redis 5, scripts are always replicated as effects and not sending the script verbatim. So the following section is mostly applicable to Redis version 4 or older.*\n\nA very important part of scripting is writing scripts that only change the database in a deterministic way.\nScripts executed in a Redis instance are, by default, propagated to replicas\nand to the AOF file by sending the script itself -- not the resulting\ncommands.\nSince the script will be re-run on the remote host (or when reloading the AOF file), the changes it makes to the database must be reproducible.\n\nThe reason for sending the script is that it is often much faster than sending the multiple commands that the script generates.\nIf the client is sending many scripts to the master, converting the scripts into\nindividual commands for the replica / AOF would result in too much bandwidth\nfor the replication link or the Append Only File (and also too much CPU since\ndispatching a command received via network is a lot more work for Redis compared\nto dispatching a command invoked by Lua scripts).\n\nNormally replicating scripts instead of the effects of the scripts makes sense,\nhowever not in all the cases. So starting with Redis 3.2,\nthe scripting engine is able to, alternatively, replicate the sequence of write\ncommands resulting from the script execution, instead of replication the\nscript itself. See the next section for more information.\n\nIn this section we'll assume that scripts are replicated by sending the whole\nscript. Let's call this replication mode **whole scripts replication**.\n\nThe main drawback with the *whole scripts replication* approach is that scripts are required to have the following property:\n\n* The script must always execute the same Redis _write_ commands with the\n  same arguments given the same input data set.\n  Operations performed by the script cannot depend on any hidden (non-explicit)\n  information or state that may change as script execution proceeds or between\n  different executions of the script, nor can it depend on any external input\n  from I/O devices.\n\nThings like using the system time, calling Redis random commands like\n[`RANDOMKEY`](./randomkey), or using Lua's random number generator, could result in scripts\nthat will not always evaluate in the same way.\n\nIn order to enforce this behavior in scripts Redis does the following:\n\n* Lua does not export commands to access the system time or other external\n  state.\n* Redis will block the script with an error if a script calls a Redis\n  command able to alter the data set **after** a Redis _random_ command like\n  [`RANDOMKEY`](./randomkey), [`SRANDMEMBER`](./srandmember), [`TIME`](./time).\n  This means that if a script is read-only and does not modify the data set it\n  is free to call those commands.\n  Note that a _random command_ does not necessarily mean a command that uses\n  random numbers: any non-deterministic command is considered a random command\n  (the best example in this regard is the [`TIME`](./time) command).\n* In Redis version 4, commands that may return elements in random order, like\n  [`SMEMBERS`](./smembers) (because Redis Sets are _unordered_) have a different behavior\n  when called from Lua, and undergo a silent lexicographical sorting filter\n  before returning data to Lua scripts. So `redis.call(\"smembers\",KEYS[1])`\n  will always return the Set elements in the same order, while the same\n  command invoked from normal clients may return different results even if\n  the key contains exactly the same elements. However starting with Redis 5\n  there is no longer such ordering step, because Redis 5 replicates scripts\n  in a way that no longer needs non-deterministic commands to be converted\n  into deterministic ones. In general, even when developing for Redis 4, never\n  assume that certain commands in Lua will be ordered, but instead rely on\n  the documentation of the original command you call to see the properties\n  it provides.\n* Lua's pseudo-random number generation function `math.random` is\n  modified to always use the same seed every time a new script is executed.\n  This means that calling `math.random` will always generate the same sequence\n  of numbers every time a script is executed if `math.randomseed` is not used.\n\nHowever the user is still able to write commands with random behavior using the\nfollowing simple trick.\nImagine I want to write a Redis script that will populate a list with N random\nintegers.\n\nI can start with this small Ruby program:\n\n```\nrequire 'rubygems'\nrequire 'redis'\n\nr = Redis.new\n\nRandomPushScript = <<EOF\n    local i = tonumber(ARGV[1])\n    local res\n    while (i > 0) do\n        res = redis.call('lpush',KEYS[1],math.random())\n        i = i-1\n    end\n    return res\nEOF\n\nr.del(:mylist)\nputs r.eval(RandomPushScript,[:mylist],[10,rand(2**32)])\n```\n\nEvery time this script is executed the resulting list will have exactly the\nfollowing elements:\n\n```\n> lrange mylist 0 -1\n 1) \"0.74509509873814\"\n 2) \"0.87390407681181\"\n 3) \"0.36876626981831\"\n 4) \"0.6921941534114\"\n 5) \"0.7857992587545\"\n 6) \"0.57730350670279\"\n 7) \"0.87046522734243\"\n 8) \"0.09637165539729\"\n 9) \"0.74990198051087\"\n10) \"0.17082803611217\"\n```\n\nIn order to make it deterministic, but still be sure that every invocation\nof the script will result in different random elements, we can simply add an\nadditional argument to the script that will be used to seed the Lua\npseudo-random number generator.\nThe new script is as follows:\n\n```\nRandomPushScript = <<EOF\n    local i = tonumber(ARGV[1])\n    local res\n    math.randomseed(tonumber(ARGV[2]))\n    while (i > 0) do\n        res = redis.call('lpush',KEYS[1],math.random())\n        i = i-1\n    end\n    return res\nEOF\n\nr.del(:mylist)\nputs r.eval(RandomPushScript,1,:mylist,10,rand(2**32))\n```\n\nWhat we are doing here is sending the seed of the PRNG as one of the arguments.\nThe script output will always be the same given the same arguments (our requirement)\nbut we are changing one of the arguments at every invocation, generating the random seed client-side.\nThe seed will be propagated as one of the arguments both in the replication\nlink and in the Append Only File, guaranteeing that the same changes will be\ngenerated when the AOF is reloaded or when the replica processes the script.\n\nNote: an important part of this behavior is that the PRNG that Redis implements\nas `math.random` and `math.randomseed` is guaranteed to have the same output\nregardless of the architecture of the system running Redis.\n32-bit, 64-bit, big-endian and little-endian systems will all produce the same\noutput.\n\n## Replicating commands instead of scripts\n\n*Note: starting with Redis 5, the replication method described in this section (scripts effects replication) is the default and does not need to be explicitly enabled.*\n\nStarting with Redis 3.2, it is possible to select an\nalternative replication method. Instead of replicating whole scripts, we\ncan just replicate single write commands generated by the script.\nWe call this **script effects replication**.\n\nIn this replication mode, while Lua scripts are executed, Redis collects\nall the commands executed by the Lua scripting engine that actually modify\nthe dataset. When the script execution finishes, the sequence of commands\nthat the script generated are wrapped into a MULTI / EXEC transaction and\nare sent to the replicas and AOF.\n\nThis is useful in several ways depending on the use case:\n\n* When the script is slow to compute, but the effects can be summarized by a few write commands, it is a shame to re-compute the script on the replicas or when reloading the AOF.\n  In this case it is much better to replicate just the effects of the script.\n* When script effects replication is enabled, the restrictions on non-deterministic functions are removed.\n  You can, for example, use the [`TIME`](./time) or [`SRANDMEMBER`](./srandmember) commands inside your scripts freely at any place.\n* The Lua PRNG in this mode is seeded randomly on every call.\n\nTo enable script effects replication you need to issue the\nfollowing Lua command before the script performs a write:\n\n    redis.replicate_commands()\n\nThe function returns true if script effects replication was enabled;\notherwise, if the function was called after the script already called\na write command, it returns false, and normal whole script replication\nis used.\n\n## Selective replication of commands\n\nWhen script effects replication is selected (see the previous section), it\nis possible to have more control over the way commands are propagated to replicas and the AOF.\nThis is a very advanced feature since **a misuse can do damage** by breaking the contract that the master, replicas, and AOF must all contain the\nsame logical content.\n\nHowever this is a useful feature since, sometimes, we need to execute certain\ncommands only in the master in order to create, for example, intermediate\nvalues.\n\nThink of a Lua script where we perform an intersection between two sets.\nWe then pick five random elements from the intersection and create a new set\ncontaining them.\nFinally, we delete the temporary key representing the intersection\nbetween the two original sets. What we want to replicate is only the creation\nof the new set with the five elements. It's not useful to also replicate the\ncommands creating the temporary key.\n\nFor this reason, Redis 3.2 introduces a new command that only works when\nscript effects replication is enabled, and is able to control the scripting\nreplication engine. The command is called `redis.set_repl()` and fails raising\nan error if called when script effects replication is disabled.\n\nThe command can be called with four different arguments:\n\n    redis.set_repl(redis.REPL_ALL) -- Replicate to the AOF and replicas.\n    redis.set_repl(redis.REPL_AOF) -- Replicate only to the AOF.\n    redis.set_repl(redis.REPL_REPLICA) -- Replicate only to replicas (Redis >= 5)\n    redis.set_repl(redis.REPL_SLAVE) -- Used for backward compatibility, the same as REPL_REPLICA.\n    redis.set_repl(redis.REPL_NONE) -- Don't replicate at all.\n\nBy default the scripting engine is set to `REPL_ALL`.\nBy calling this function the user can switch the replication mode on or off at any time.\n\nA simple example follows:\n\n    redis.replicate_commands() -- Enable effects replication.\n    redis.call('set','A','1')\n    redis.set_repl(redis.REPL_NONE)\n    redis.call('set','B','2')\n    redis.set_repl(redis.REPL_ALL)\n    redis.call('set','C','3')\n\nAfter running the above script, the result is that only the keys A and C will be created on the replicas and AOF.\n\n## Global variables protection\n\nRedis scripts are not allowed to create global variables, in order to avoid\nleaking data into the Lua state.\nIf a script needs to maintain state between calls (a pretty uncommon need) it\nshould use Redis keys instead.\n\nWhen global variable access is attempted the script is terminated and EVAL\nreturns with an error:\n\n```\nredis 127.0.0.1:6379> eval 'a=10' 0\n(error) ERR Error running script (call to f_933044db579a2f8fd45d8065f04a8d0249383e57): user_script:1: Script attempted to create global variable 'a'\n```\n\nAccessing a _non existing_ global variable generates a similar error.\n\nUsing Lua debugging functionality or other approaches like altering the meta\ntable used to implement global protections in order to circumvent globals\nprotection is not hard.\nHowever it is difficult to do it accidentally.\nIf the user messes with the Lua global state, the consistency of AOF and\nreplication is not guaranteed: don't do it.\n\nNote for Lua newbies: in order to avoid using global variables in your scripts\nsimply declare every variable you are going to use using the _local_ keyword.\n\n## Using SELECT inside scripts\n\nIt is possible to call [`SELECT`](./select) inside Lua scripts like with normal clients,\nHowever one subtle aspect of the behavior changes between Redis 2.8.11 and\nRedis 2.8.12. Before the 2.8.12 release the database selected by the Lua\nscript was *transferred* to the calling script as current database.\nStarting from Redis 2.8.12 the database selected by the Lua script only\naffects the execution of the script itself, but does not modify the database\nselected by the client calling the script.\n\nThe semantic change between patch level releases was needed since the old\nbehavior was inherently incompatible with the Redis replication layer and\nwas the cause of bugs.\n\n## Using Lua scripting in RESP3 mode\n\nStarting with Redis version 6, the server supports two different protocols.\nOne is called RESP2, and is the old protocol: all the new connections to\nthe server start in this mode. However clients are able to negotiate the\nnew protocol using the [`HELLO`](./hello) command: this way the connection is put\nin RESP3 mode. In this mode certain commands, like for instance [`HGETALL`](./hgetall),\nreply with a new data type (the Map data type in this specific case). The\nRESP3 protocol is semantically more powerful, however most scripts are OK\nwith using just RESP2.\n\nThe Lua engine always assumes to run in RESP2 mode when talking with Redis,\nso whatever the connection that is invoking the `EVAL` or [`EVALSHA`](./evalsha) command\nis in RESP2 or RESP3 mode, Lua scripts will, by default, still see the\nsame kind of replies they used to see in the past from Redis, when calling\ncommands using the `redis.call()` built-in function.\n\nHowever Lua scripts running in Redis 6 or greater, are able to switch to\nRESP3 mode, and get the replies using the new available types. Similarly\nLua scripts are able to reply to clients using the new types. Please make\nsure to understand\n[the capabilities for RESP3](https://github.com/antirez/resp3)\nbefore continuing reading this section.\n\nIn order to switch to RESP3 a script should call this function:\n\n    redis.setresp(3)\n\nNote that a script can switch back and forth from RESP3 and RESP2 by\ncalling the function with the argument '3' or '2'.\n\nAt this point the new conversions are available, specifically:\n\n**Redis to Lua** conversion table specific to RESP3:\n\n* Redis map reply -> Lua table with a single `map` field containing a Lua table representing the fields and values of the map.\n* Redis set reply -> Lua table with a single `set` field containing a Lua table representing the elements of the set as fields, having as value just `true`.\n* Redis new RESP3 single null value -> Lua nil.\n* Redis true reply -> Lua true boolean value.\n* Redis false reply -> Lua false boolean value.\n* Redis double reply -> Lua table with a single `score` field containing a Lua number representing the double value.\n* Redis big number reply -> Lua table with a single `big_number` field containing a Lua string representing the big number value.\n* Redis verbatim string reply -> Lua table with a single `verbatim_string` field containing a Lua table with two fields, `string` and `format`, representing the verbatim string and verbatim format respectively.\n* All the RESP2 old conversions still apply.\n\nNote: the big number and verbatim replies are only available in Redis 7 or greater. Also, presently RESP3 attributes are not supported in Lua.\n\n**Lua to Redis** conversion table specific for RESP3.\n\n* Lua boolean -> Redis boolean true or false. **Note that this is a change compared to the RESP2 mode**, where returning true from Lua returned the number 1 to the Redis client, and returning false used to return NULL.\n* Lua table with a single `map` field set to a field-value Lua table -> Redis map reply.\n* Lua table with a single `set` field set to a field-value Lua table -> Redis set reply, the values are discarded and can be anything.\n* Lua table with a single `double` field set to a field-value Lua table -> Redis double reply.\n* Lua null -> Redis RESP3 new null reply (protocol `\"_\\r\\n\"`).\n* All the RESP2 old conversions still apply unless specified above.\n\nThere is one key thing to understand: in case Lua replies with RESP3 types, but the connection calling Lua is in RESP2 mode, Redis will automatically convert the RESP3 protocol to RESP2 compatible protocol, as it happens for normal commands. For instance returning a map type to a connection in RESP2 mode will have the effect of returning a flat array of fields and values.\n\n## Available libraries\n\nThe Redis Lua interpreter loads the following Lua libraries:\n\n* `base` lib.\n* `table` lib.\n* `string` lib.\n* `math` lib.\n* `struct` lib.\n* `cjson` lib.\n* `cmsgpack` lib.\n* `bitop` lib.\n* `redis.sha1hex` function.\n* `redis.breakpoint and redis.debug` function in the context of the [Redis Lua debugger](/topics/ldb).\n\nEvery Redis instance is _guaranteed_ to have all the above libraries so you can\nbe sure that the environment for your Redis scripts is always the same.\n\nstruct, CJSON and cmsgpack are external libraries, all the other libraries are standard\nLua libraries.\n\n### struct\n\nstruct is a library for packing/unpacking structures within Lua.\n\n```\nValid formats:\n> - big endian\n< - little endian\n![num] - alignment\nx - pading\nb/B - signed/unsigned byte\nh/H - signed/unsigned short\nl/L - signed/unsigned long\nT   - size_t\ni/In - signed/unsigned integer with size `n' (default is size of int)\ncn - sequence of `n' chars (from/to a string); when packing, n==0 means\n     the whole string; when unpacking, n==0 means use the previous\n     read number as the string length\ns - zero-terminated string\nf - float\nd - double\n' ' - ignored\n```\n\n\nExample:\n\n```\n127.0.0.1:6379> eval 'return struct.pack(\"HH\", 1, 2)' 0\n\"\\x01\\x00\\x02\\x00\"\n127.0.0.1:6379> eval 'return {struct.unpack(\"HH\", ARGV[1])}' 0 \"\\x01\\x00\\x02\\x00\"\n1) (integer) 1\n2) (integer) 2\n3) (integer) 5\n127.0.0.1:6379> eval 'return struct.size(\"HH\")' 0\n(integer) 4\n```\n\n### CJSON\n\nThe CJSON library provides extremely fast JSON manipulation within Lua.\n\nExample:\n\n```\nredis 127.0.0.1:6379> eval 'return cjson.encode({[\"foo\"]= \"bar\"})' 0\n\"{\\\"foo\\\":\\\"bar\\\"}\"\nredis 127.0.0.1:6379> eval 'return cjson.decode(ARGV[1])[\"foo\"]' 0 \"{\\\"foo\\\":\\\"bar\\\"}\"\n\"bar\"\n```\n\n### cmsgpack\n\nThe cmsgpack library provides simple and fast MessagePack manipulation within Lua.\n\nExample:\n\n```\n127.0.0.1:6379> eval 'return cmsgpack.pack({\"foo\", \"bar\", \"baz\"})' 0\n\"\\x93\\xa3foo\\xa3bar\\xa3baz\"\n127.0.0.1:6379> eval 'return cmsgpack.unpack(ARGV[1])' 0 \"\\x93\\xa3foo\\xa3bar\\xa3baz\"\n1) \"foo\"\n2) \"bar\"\n3) \"baz\"\n```\n\n### bitop\n\nThe Lua Bit Operations Module adds bitwise operations on numbers.\nIt is available for scripting in Redis since version 2.8.18.\n\nExample:\n\n```\n127.0.0.1:6379> eval 'return bit.tobit(1)' 0\n(integer) 1\n127.0.0.1:6379> eval 'return bit.bor(1,2,4,8,16,32,64,128)' 0\n(integer) 255\n127.0.0.1:6379> eval 'return bit.tohex(422342)' 0\n\"000671c6\"\n```\n\nIt supports several other functions:\n`bit.tobit`, `bit.tohex`, `bit.bnot`, `bit.band`, `bit.bor`, `bit.bxor`,\n`bit.lshift`, `bit.rshift`, `bit.arshift`, `bit.rol`, `bit.ror`, `bit.bswap`.\nAll available functions are documented in the [Lua BitOp documentation](http://bitop.luajit.org/api.html)\n\n### `redis.sha1hex`\n\nPerform the SHA1 of the input string.\n\nExample:\n\n```\n127.0.0.1:6379> eval 'return redis.sha1hex(ARGV[1])' 0 \"foo\"\n\"0beec7b5ea3f0fdbc95d0dd47f3c5bc275da8a33\"\n```\n\n## Emitting Redis logs from scripts\n\nIt is possible to write to the Redis log file from Lua scripts using the\n`redis.log` function.\n\n```\nredis.log(loglevel,message)\n```\n\n`loglevel` is one of:\n\n* `redis.LOG_DEBUG`\n* `redis.LOG_VERBOSE`\n* `redis.LOG_NOTICE`\n* `redis.LOG_WARNING`\n\nThey correspond directly to the normal Redis log levels.\nOnly logs emitted by scripting using a log level that is equal or greater than\nthe currently configured Redis instance log level will be emitted.\n\nThe `message` argument is simply a string.\nExample:\n\n```\nredis.log(redis.LOG_WARNING,\"Something is wrong with this script.\")\n```\n\nWill generate the following:\n\n```\n[32343] 22 Mar 15:21:39 # Something is wrong with this script.\n```\n\n## Sandbox and maximum execution time\n\nScripts should never try to access the external system, like the file system or\nany other system call.\nA script should only operate on Redis data and passed arguments.\n\nScripts are also subject to a maximum execution time (five seconds by default).\nThis default timeout is huge since a script should usually run in under a\nmillisecond.\nThe limit is mostly to handle accidental infinite loops created during\ndevelopment.\n\nIt is possible to modify the maximum time a script can be executed with\nmillisecond precision, either via `redis.conf` or using the CONFIG GET / CONFIG\nSET command.\nThe configuration parameter affecting max execution time is called\n`lua-time-limit`.\n\nWhen a script reaches the timeout it is not automatically terminated by Redis\nsince this violates the contract Redis has with the scripting engine to ensure\nthat scripts are atomic.\nInterrupting a script means potentially leaving the dataset with half-written\ndata.\nFor this reasons when a script executes for more than the specified time the\nfollowing happens:\n\n* Redis logs that a script is running too long.\n* It starts accepting commands again from other clients, but will reply with a\n  BUSY error to all the clients sending normal commands.\n  The only allowed commands in this status are `SCRIPT KILL` and `SHUTDOWN\n  NOSAVE`.\n* It is possible to terminate a script that executes only read-only commands\n  using the `SCRIPT KILL` command.\n  This does not violate the scripting semantic as no data was yet written to the\n  dataset by the script.\n* If the script already called write commands the only allowed command becomes\n  `SHUTDOWN NOSAVE` that stops the server without saving the current data set on\n  disk (basically the server is aborted).\n\n## EVALSHA in the context of pipelining\n\nCare should be taken when executing [`EVALSHA`](./evalsha) in the context of a pipelined\nrequest, since even in a pipeline the order of execution of commands must be\nguaranteed.\nIf [`EVALSHA`](./evalsha) will return a `NOSCRIPT` error the command can not be reissued\nlater otherwise the order of execution is violated.\n\nThe client library implementation should take one of the following approaches:\n\n*   Always use plain `EVAL` when in the context of a pipeline.\n\n*   Accumulate all the commands to send into the pipeline, then check for `EVAL`\n    commands and use the `SCRIPT EXISTS` command to check if all the scripts are\n    already defined.\n    If not, add `SCRIPT LOAD` commands on top of the pipeline as required, and\n    use [`EVALSHA`](./evalsha) for all the `EVAL` calls.\n\n## Debugging Lua scripts\n\nStarting with Redis 3.2, Redis has support for native\nLua debugging. The Redis Lua debugger is a remote debugger consisting of\na server, which is Redis itself, and a client, which is by default `redis-cli`.\n\nThe Lua debugger is described in the [Lua scripts debugging](/topics/ldb) section of the Redis documentation.\n\n",
            "return_summary": "",
            "summary": "Execute a Lua script server side",
            "complexity": "Depends on the script that is executed.",
            "arguments": [
                {
                    "name": "script",
                    "type": "string",
                    "value": "script"
                },
                {
                    "name": "numkeys",
                    "type": "integer",
                    "value": "numkeys"
                },
                {
                    "optional": true,
                    "multiple": true,
                    "multiple_token": true,
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "optional": true,
                    "multiple": true,
                    "multiple_token": true,
                    "name": "arg",
                    "type": "string",
                    "value": "arg"
                }
            ],
            "since": "2.6.0",
            "group": "scripting",
            "arity": -3,
            "command_flags": [
                "noscript",
                "skip_monitor",
                "may_replicate"
            ],
            "acl_categories": [
                "slow",
                "scripting"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write",
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 2
                        }
                    },
                    "find_keys": {
                        "keynum": {
                            "keynumidx": 0,
                            "firstkey": 1,
                            "step": 1
                        }
                    }
                }
            ],
            "function": "evalCommand",
            "get_keys_function": "evalGetKeys"
        }
    },
    {
        "BGREWRITEAOF": {
            "body": "Instruct Redis to start an [Append Only File][tpaof] rewrite process.\nThe rewrite will create a small optimized version of the current Append Only\nFile.\n\n[tpaof]: /topics/persistence#append-only-file\n\nIf `BGREWRITEAOF` fails, no data gets lost as the old AOF will be untouched.\n\nThe rewrite will be only triggered by Redis if there is not already a background\nprocess doing persistence.\n\nSpecifically:\n\n* If a Redis child is creating a snapshot on disk, the AOF rewrite is _scheduled_ but not started until the saving child producing the RDB file terminates. In this case the `BGREWRITEAOF` will still return an positive status reply, but with an appropriate message.  You can check if an AOF rewrite is scheduled looking at the [`INFO`](./info) command as of Redis 2.6 or successive versions.\n* If an AOF rewrite is already in progress the command returns an error and no\n  AOF rewrite will be scheduled for a later time.\n* If the AOF rewrite could start, but the attempt at starting it fails (for instance because of an error in creating the child process), an error is returned to the caller.\n\nSince Redis 2.4 the AOF rewrite is automatically triggered by Redis, however the\n`BGREWRITEAOF` command can be used to trigger a rewrite at any time.\n\nPlease refer to the [persistence documentation][tp] for detailed information.\n\n[tp]: /topics/persistence\n\n",
            "": "",
            "return_types": [
                {
                    "description": "A simple string reply indicating that the rewriting started or is about to start ASAP, when the call is executed with success.",
                    "type": "simple-string"
                }
            ],
            "summary": "Asynchronously rewrite the append-only file",
            "since": "1.0.0",
            "group": "server",
            "arity": 1,
            "command_flags": [
                "admin",
                "noscript"
            ],
            "acl_categories": [
                "admin",
                "slow",
                "dangerous"
            ],
            "function": "bgrewriteaofCommand"
        }
    },
    {
        "ZRANGEBYSCORE": {
            "body": "Returns all the elements in the sorted set at `key` with a score between `min`\nand `max` (including elements with score equal to `min` or `max`).\nThe elements are considered to be ordered from low to high scores.\n\nThe elements having the same score are returned in lexicographical order (this\nfollows from a property of the sorted set implementation in Redis and does not\ninvolve further computation).\n\nAs per Redis 6.2.0, this command is considered deprecated. Please prefer using the [`ZRANGE`](./zrange) command with the `BYSCORE` argument in new code.\n\nThe optional `LIMIT` argument can be used to only get a range of the matching\nelements (similar to _SELECT LIMIT offset, count_ in SQL). A negative `count`\nreturns all elements from the `offset`.\nKeep in mind that if `offset` is large, the sorted set needs to be traversed for\n`offset` elements before getting to the elements to return, which can add up to\nO(N) time complexity.\n\nThe optional `WITHSCORES` argument makes the command return both the element and\nits score, instead of the element alone.\nThis option is available since Redis 2.0.\n\n## Exclusive intervals and infinity\n\n`min` and `max` can be `-inf` and `+inf`, so that you are not required to know\nthe highest or lowest score in the sorted set to get all elements from or up to\na certain score.\n\nBy default, the interval specified by `min` and `max` is closed (inclusive).\nIt is possible to specify an open interval (exclusive) by prefixing the score\nwith the character `(`.\nFor example:\n\n```\nZRANGEBYSCORE zset (1 5\n```\n\nWill return all elements with `1 < score <= 5` while:\n\n```\nZRANGEBYSCORE zset (5 (10\n```\n\nWill return all the elements with `5 < score < 10` (5 and 10 excluded).\n\n@examples\n\n```cli\nZADD myzset 1 \"one\"\nZADD myzset 2 \"two\"\nZADD myzset 3 \"three\"\nZRANGEBYSCORE myzset -inf +inf\nZRANGEBYSCORE myzset 1 2\nZRANGEBYSCORE myzset (1 2\nZRANGEBYSCORE myzset (1 (2\n```\n\n## Pattern: weighted random selection of an element\n\nNormally `ZRANGEBYSCORE` is simply used in order to get range of items\nwhere the score is the indexed integer key, however it is possible to do less\nobvious things with the command.\n\nFor example a common problem when implementing Markov chains and other algorithms\nis to select an element at random from a set, but different elements may have\ndifferent weights that change how likely it is they are picked.\n\nThis is how we use this command in order to mount such an algorithm:\n\nImagine you have elements A, B and C with weights 1, 2 and 3.\nYou compute the sum of the weights, which is 1+2+3 = 6\n\nAt this point you add all the elements into a sorted set using this algorithm:\n\n```\nSUM = ELEMENTS.TOTAL_WEIGHT // 6 in this case.\nSCORE = 0\nFOREACH ELE in ELEMENTS\n    SCORE += ELE.weight / SUM\n    ZADD KEY SCORE ELE\nEND\n```\n\nThis means that you set:\n\n```\nA to score 0.16\nB to score .5\nC to score 1\n```\n\nSince this involves approximations, in order to avoid C is set to,\nlike, 0.998 instead of 1, we just modify the above algorithm to make sure\nthe last score is 1 (left as an exercise for the reader...).\n\nAt this point, each time you want to get a weighted random element,\njust compute a random number between 0 and 1 (which is like calling\n`rand()` in most languages), so you can just do:\n\n    RANDOM_ELE = ZRANGEBYSCORE key RAND() +inf LIMIT 0 1\n\n",
            "deprecated": true,
            "": "",
            "return_types": [
                {
                    "description": "list of elements in the specified score range (optionally",
                    "type": "array"
                }
            ],
            "summary": "Return a range of members in a sorted set, by score",
            "complexity": "O(log(N)+M) with N being the number of elements in the sorted set and M the number of elements being returned. If M is constant (e.g. always asking for the first 10 elements with LIMIT), you can consider it O(log(N)).",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "name": "min",
                    "type": "double",
                    "value": "min"
                },
                {
                    "name": "max",
                    "type": "double",
                    "value": "max"
                },
                {
                    "optional": true,
                    "name": "withscores",
                    "token": "WITHSCORES"
                },
                {
                    "token": "LIMIT",
                    "optional": true,
                    "name": "offset_count",
                    "type": "block",
                    "value": [
                        {
                            "name": "offset",
                            "type": "integer",
                            "value": "offset"
                        },
                        {
                            "name": "count",
                            "type": "integer",
                            "value": "count"
                        }
                    ]
                }
            ],
            "since": "1.0.5",
            "group": "sorted_set",
            "arity": -4,
            "command_flags": [
                "readonly"
            ],
            "acl_categories": [
                "read",
                "sortedset",
                "slow"
            ],
            "key_specs": [
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "zrangebyscoreCommand"
        }
    },
    {
        "BITOP": {
            "body": "Perform a bitwise operation between multiple keys (containing string values) and\nstore the result in the destination key.\n\nThe `BITOP` command supports four bitwise operations: **AND**, **OR**, **XOR**\nand **NOT**, thus the valid forms to call the command are:\n\n\n* `BITOP AND destkey srckey1 srckey2 srckey3 ... srckeyN`\n* `BITOP OR  destkey srckey1 srckey2 srckey3 ... srckeyN`\n* `BITOP XOR destkey srckey1 srckey2 srckey3 ... srckeyN`\n* `BITOP NOT destkey srckey`\n\nAs you can see **NOT** is special as it only takes an input key, because it\nperforms inversion of bits so it only makes sense as an unary operator.\n\nThe result of the operation is always stored at `destkey`.\n\n## Handling of strings with different lengths\n\nWhen an operation is performed between strings having different lengths, all the\nstrings shorter than the longest string in the set are treated as if they were\nzero-padded up to the length of the longest string.\n\nThe same holds true for non-existent keys, that are considered as a stream of\nzero bytes up to the length of the longest string.\n\n@examples\n\n```cli\nSET key1 \"foobar\"\nSET key2 \"abcdef\"\nBITOP AND dest key1 key2\nGET dest\n```\n\n## Pattern: real time metrics using bitmaps\n\n`BITOP` is a good complement to the pattern documented in the [`BITCOUNT`](./bitcount) command\ndocumentation.\nDifferent bitmaps can be combined in order to obtain a target bitmap where\nthe population counting operation is performed.\n\nSee the article called \"[Fast easy realtime metrics using Redis\nbitmaps][hbgc212fermurb]\" for a interesting use cases.\n\n[hbgc212fermurb]: http://blog.getspool.com/2011/11/29/fast-easy-realtime-metrics-using-redis-bitmaps\n\n## Performance considerations\n\n`BITOP` is a potentially slow command as it runs in O(N) time.\nCare should be taken when running it against long input strings.\n\nFor real-time metrics and statistics involving large inputs a good approach is\nto use a replica (with read-only option disabled) where the bit-wise\noperations are performed to avoid blocking the master instance.\n\n",
            "": "",
            "return_types": [
                {
                    "type": "integer"
                }
            ],
            "summary": "Perform bitwise operations between strings",
            "complexity": "O(N)",
            "arguments": [
                {
                    "name": "operation",
                    "type": "string",
                    "value": "operation"
                },
                {
                    "name": "destkey",
                    "type": "key",
                    "value": "destkey"
                },
                {
                    "multiple": true,
                    "multiple_token": true,
                    "name": "key",
                    "type": "key",
                    "value": "key"
                }
            ],
            "since": "2.6.0",
            "group": "bitmap",
            "arity": -4,
            "command_flags": [
                "write",
                "denyoom"
            ],
            "acl_categories": [
                "write",
                "bitmap",
                "slow"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 2
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                },
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 3
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": -1,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "bitopCommand"
        }
    },
    {
        "EVAL_RO": {
            "body": "This is a read-only variant of the [`EVAL`](./eval) command that isn't allowed to execute commands that modify data.\n\nUnlike [`EVAL`](./eval), scripts executed with this command can always be killed and never affect the replication stream.\nBecause it can only read data, this command can always be executed on a master or a replica.\n\n@examples\n\n```\n> SET mykey \"Hello\"\nOK\n\n> EVAL_RO \"return redis.call('GET', KEYS[1])\" 1 mykey\n\"Hello\"\n\n> EVAL_RO \"return redis.call('DEL', KEYS[1])\" 1 mykey\n(error) ERR Error running script (call to f_359f69785f876b7f3f60597d81534f3d6c403284): @user_script:1: @user_script: 1: Write commands are not allowed from read-only scripts\n```\n\n",
            "return_summary": "",
            "summary": "Execute a read-only Lua script server side",
            "complexity": "Depends on the script that is executed.",
            "arguments": [
                {
                    "name": "script",
                    "type": "string",
                    "value": "script"
                },
                {
                    "name": "numkeys",
                    "type": "integer",
                    "value": "numkeys"
                },
                {
                    "multiple": true,
                    "multiple_token": true,
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "multiple": true,
                    "multiple_token": true,
                    "name": "arg",
                    "type": "string",
                    "value": "arg"
                }
            ],
            "since": "7.0.0",
            "group": "scripting",
            "arity": -3,
            "command_flags": [
                "noscript",
                "skip_monitor"
            ],
            "acl_categories": [
                "slow",
                "scripting"
            ],
            "key_specs": [
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 2
                        }
                    },
                    "find_keys": {
                        "keynum": {
                            "keynumidx": 0,
                            "firstkey": 1,
                            "step": 1
                        }
                    }
                }
            ],
            "function": "evalRoCommand",
            "get_keys_function": "evalGetKeys"
        }
    },
    {
        "LPUSHX": {
            "body": "Inserts specified values at the head of the list stored at `key`, only if `key`\nalready exists and holds a list.\nIn contrary to [`LPUSH`](./lpush), no operation will be performed when `key` does not yet\nexist.\n\n@examples\n\n```cli\nLPUSH mylist \"World\"\nLPUSHX mylist \"Hello\"\nLPUSHX myotherlist \"Hello\"\nLRANGE mylist 0 -1\nLRANGE myotherlist 0 -1\n```\n\n",
            "history": [
                [
                    "4.0",
                    "Accepts multiple `element` arguments."
                ]
            ],
            "": "",
            "return_types": [
                {
                    "description": "the length of the list after the push operation.",
                    "type": "integer"
                }
            ],
            "summary": "Prepend an element to a list, only if the list exists",
            "complexity": "O(1) for each element added, so O(N) to add N elements when the command is called with multiple arguments.",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "multiple": true,
                    "multiple_token": true,
                    "name": "element",
                    "type": "string",
                    "value": "element"
                }
            ],
            "since": "2.2.0",
            "group": "list",
            "arity": -3,
            "command_flags": [
                "write",
                "denyoom",
                "fast"
            ],
            "acl_categories": [
                "write",
                "list",
                "fast"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "lpushxCommand"
        }
    },
    {
        "XSETID": {
            "arity": 3,
            "command_flags": [
                "write",
                "denyoom",
                "fast"
            ],
            "acl_categories": [
                "write",
                "stream",
                "fast"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "xsetidCommand",
            "group": "streams",
            "internal": true
        }
    },
    {
        "SMEMBERS": {
            "body": "Returns all the members of the set value stored at `key`.\n\nThis has the same effect as running [`SINTER`](./sinter) with one argument `key`.\n\n@examples\n\n```cli\nSADD myset \"Hello\"\nSADD myset \"World\"\nSMEMBERS myset\n```\n\n",
            "": "",
            "return_types": [
                {
                    "description": "all elements of the set.",
                    "type": "array"
                }
            ],
            "summary": "Get all the members in a set",
            "complexity": "O(N) where N is the set cardinality.",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                }
            ],
            "since": "1.0.0",
            "group": "set",
            "arity": 2,
            "command_flags": [
                "readonly",
                "sort_for_script"
            ],
            "acl_categories": [
                "read",
                "set",
                "slow"
            ],
            "key_specs": [
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "sinterCommand"
        }
    },
    {
        "GETBIT": {
            "body": "Returns the bit value at _offset_ in the string value stored at _key_.\n\nWhen _offset_ is beyond the string length, the string is assumed to be a\ncontiguous space with 0 bits.\nWhen _key_ does not exist it is assumed to be an empty string, so _offset_ is\nalways out of range and the value is also assumed to be a contiguous space with\n0 bits.\n\n@examples\n\n```cli\nSETBIT mykey 7 1\nGETBIT mykey 0\nGETBIT mykey 7\nGETBIT mykey 100\n```\n\n",
            "": "",
            "return_types": [
                {
                    "description": "the bit value stored at _offset_.",
                    "type": "integer"
                }
            ],
            "summary": "Returns the bit value at offset in the string value stored at key",
            "complexity": "O(1)",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "name": "offset",
                    "type": "integer",
                    "value": "offset"
                }
            ],
            "since": "2.2.0",
            "group": "bitmap",
            "arity": 3,
            "command_flags": [
                "readonly",
                "fast"
            ],
            "acl_categories": [
                "read",
                "bitmap",
                "fast"
            ],
            "key_specs": [
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "getbitCommand"
        }
    },
    {
        "TTL": {
            "body": "Returns the remaining time to live of a key that has a timeout.\nThis introspection capability allows a Redis client to check how many seconds a\ngiven key will continue to be part of the dataset.\n\nIn Redis 2.6 or older the command returns `-1` if the key does not exist or if the key exist but has no associated expire.\n\nStarting with Redis 2.8 the return value in case of error changed:\n\n* The command returns `-2` if the key does not exist.\n* The command returns `-1` if the key exists but has no associated expire.\n\nSee also the [`PTTL`](./pttl) command that returns the same information with milliseconds resolution (Only available in Redis 2.6 or greater).\n\n@examples\n\n```cli\nSET mykey \"Hello\"\nEXPIRE mykey 10\nTTL mykey\n```\n\n",
            "": "",
            "return_types": [
                {
                    "description": "TTL in seconds, or a negative value in order to signal an error (see the description above).",
                    "type": "integer"
                }
            ],
            "summary": "Get the time to live for a key in seconds",
            "complexity": "O(1)",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                }
            ],
            "since": "1.0.0",
            "group": "generic",
            "arity": 2,
            "command_flags": [
                "readonly",
                "random",
                "fast"
            ],
            "acl_categories": [
                "keyspace",
                "read",
                "fast"
            ],
            "key_specs": [
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "ttlCommand"
        }
    },
    {
        "DECR": {
            "body": "Decrements the number stored at `key` by one.\nIf the key does not exist, it is set to `0` before performing the operation.\nAn error is returned if the key contains a value of the wrong type or contains a\nstring that can not be represented as integer.\nThis operation is limited to **64 bit signed integers**.\n\nSee [`INCR`](./incr) for extra information on increment/decrement operations.\n\n@examples\n\n```cli\nSET mykey \"10\"\nDECR mykey\nSET mykey \"234293482390480948029348230948\"\nDECR mykey\n```\n\n",
            "": "",
            "return_types": [
                {
                    "description": "the value of `key` after the decrement",
                    "type": "integer"
                }
            ],
            "summary": "Decrement the integer value of a key by one",
            "complexity": "O(1)",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                }
            ],
            "since": "1.0.0",
            "group": "string",
            "arity": 2,
            "command_flags": [
                "write",
                "denyoom",
                "fast"
            ],
            "acl_categories": [
                "write",
                "string",
                "fast"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "decrCommand"
        }
    },
    {
        "DISCARD": {
            "body": "Flushes all previously queued commands in a [transaction][tt] and restores the\nconnection state to normal.\n\n[tt]: /topics/transactions\n\nIf [`WATCH`](./watch) was used, `DISCARD` unwatches all keys watched by the connection.\n\n",
            "": "",
            "return_types": [
                {
                    "description": "always `OK`.",
                    "type": "simple-string"
                }
            ],
            "summary": "Discard all commands issued after MULTI",
            "since": "2.0.0",
            "group": "transactions",
            "arity": 1,
            "command_flags": [
                "noscript",
                "loading",
                "stale",
                "fast"
            ],
            "acl_categories": [
                "fast",
                "transaction"
            ],
            "function": "discardCommand"
        }
    },
    {
        "AUTH": {
            "body": "The AUTH command authenticates the current connection in two cases:\n\n1. If the Redis server is password protected via the `requirepass` option.\n2. If a Redis 6.0 instance, or greater, is using the [Redis ACL system](/topics/acl).\n\nRedis versions prior of Redis 6 were only able to understand the one argument\nversion of the command:\n\n    AUTH <password>\n\nThis form just authenticates against the password set with `requirepass`.\nIn this configuration Redis will deny any command executed by the just\nconnected clients, unless the connection gets authenticated via `AUTH`.\n\nIf the password provided via AUTH matches the password in the configuration file, the server replies with the `OK` status code and starts accepting commands.\nOtherwise, an error is returned and the clients needs to try a new password.\n\nWhen Redis ACLs are used, the command should be given in an extended way:\n\n    AUTH <username> <password>\n\nIn order to authenticate the current connection with one of the connections\ndefined in the ACL list (see `ACL SETUSER`) and the official [ACL guide](/topics/acl) for more information.\n\nWhen ACLs are used, the single argument form of the command, where only the password is specified, assumes that the implicit username is \"default\".\n\n## Security notice\n\nBecause of the high performance nature of Redis, it is possible to try\na lot of passwords in parallel in very short time, so make sure to generate a\nstrong and very long password so that this attack is infeasible.\nA good way to generate strong passwords is via the `ACL GENPASS` command.\n\n",
            "history": [
                [
                    "6.0.0",
                    "Added ACL style (username and password)."
                ]
            ],
            "return_summary": "@simple-string-reply or an error if the password, or username/password pair, is invalid.",
            "": "",
            "summary": "Authenticate to the server",
            "arguments": [
                {
                    "optional": true,
                    "name": "username",
                    "type": "string",
                    "value": "username"
                },
                {
                    "name": "password",
                    "type": "string",
                    "value": "password"
                }
            ],
            "since": "1.0.0",
            "group": "connection",
            "arity": -2,
            "command_flags": [
                "noscript",
                "loading",
                "stale",
                "fast",
                "no_auth"
            ],
            "acl_categories": [
                "fast",
                "connection"
            ],
            "function": "authCommand"
        }
    },
    {
        "ZMPOP": {
            "body": "Pops one or more elements, that are member-score pairs, from the first non-empty sorted set in the provided list of key names.\n\n`ZMPOP` and [`BZMPOP`](./bzmpop) are similar to the following, more limited, commands:\n\n- [`ZPOPMIN`](./zpopmin) or [`ZPOPMAX`](./zpopmax) which take only one key, and can return multiple elements.\n- [`BZPOPMIN`](./bzpopmin) or [`BZPOPMAX`](./bzpopmax) which take multiple keys, but return only one element from just one key.\n\nSee [`BZMPOP`](./bzmpop) for the blocking variant of this command.\n\nWhen the `MIN` modifier is used, the elements popped are those with the lowest scores from the first non-empty sorted set. The `MAX` modifier causes elements with the highest scores to be popped.\nThe optional `COUNT` can be used to specify the number of elements to pop, and is set to 1 by default.\n\nThe number of popped elements is the minimum from the sorted set's cardinality and `COUNT`'s value.\n\n@examples\n\n```cli\nZMPOP 1 notsuchkey MIN\nZADD myzset 1 \"one\" 2 \"two\" 3 \"three\"\nZMPOP 1 myzset MIN\nZRANGE myzset 0 -1 WITHSCORES\nZMPOP 1 myzset MAX COUNT 10\nZADD myzset2 4 \"four\" 5 \"five\" 6 \"six\"\nZMPOP 2 myzset myzset2 MIN COUNT 10\nZRANGE myzset 0 -1 WITHSCORES\nZMPOP 2 myzset myzset2 MAX COUNT 10\nZRANGE myzset2 0 -1 WITHSCORES\nEXISTS myzset myzset2\n```\n\n",
            "": "",
            "return_types": [
                {
                    "description": "specifically:",
                    "type": "array"
                }
            ],
            "summary": "Remove and return members with scores in a sorted set",
            "complexity": "O(K) + O(N*log(M)) where K is the number of provided keys, N being the number of elements in the sorted set, and M being the number of elements popped.",
            "arguments": [
                {
                    "name": "numkeys",
                    "type": "integer",
                    "value": "numkeys"
                },
                {
                    "multiple": true,
                    "multiple_token": true,
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "name": "min_max",
                    "type": "oneof",
                    "value": [
                        {
                            "name": "__TBD__115__",
                            "token": "MIN"
                        },
                        {
                            "name": "__TBD__116__",
                            "token": "MAX"
                        }
                    ]
                },
                {
                    "token": "COUNT",
                    "optional": true,
                    "name": "count",
                    "type": "integer",
                    "value": "count"
                }
            ],
            "since": "7.0.0",
            "group": "sorted_set",
            "arity": -4,
            "command_flags": [
                "write"
            ],
            "acl_categories": [
                "write",
                "sortedset",
                "slow"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "keynum": {
                            "keynumidx": 0,
                            "firstkey": 1,
                            "step": 1
                        }
                    }
                }
            ],
            "function": "zmpopCommand",
            "get_keys_function": "zmpopGetKeys"
        }
    },
    {
        "HGETALL": {
            "body": "Returns all fields and values of the hash stored at `key`.\nIn the returned value, every field name is followed by its value, so the length\nof the reply is twice the size of the hash.\n\n@examples\n\n```cli\nHSET myhash field1 \"Hello\"\nHSET myhash field2 \"World\"\nHGETALL myhash\n```\n\n",
            "": "",
            "return_types": [
                {
                    "description": "list of fields and their values stored in the hash, or an",
                    "type": "array"
                }
            ],
            "summary": "Get all the fields and values in a hash",
            "complexity": "O(N) where N is the size of the hash.",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                }
            ],
            "since": "2.0.0",
            "group": "hash",
            "arity": 2,
            "command_flags": [
                "readonly",
                "random"
            ],
            "acl_categories": [
                "read",
                "hash",
                "slow"
            ],
            "key_specs": [
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "hgetallCommand"
        }
    },
    {
        "BITCOUNT": {
            "body": "Count the number of set bits (population counting) in a string.\n\nBy default all the bytes contained in the string are examined.\nIt is possible to specify the counting operation only in an interval passing the\nadditional arguments _start_ and _end_.\n\nLike for the [`GETRANGE`](./getrange) command start and end can contain negative values in\norder to index bytes starting from the end of the string, where -1 is the last\nbyte, -2 is the penultimate, and so forth.\n\nNon-existent keys are treated as empty strings, so the command will return zero.\n\nBy default, the additional arguments _start_ and _end_ specify a byte index.\nWe can use an additional argument `BIT` to specify a bit index.\nSo 0 is the first bit, 1 is the second bit, and so forth.\nFor negative values, -1 is the last bit, -2 is the penultimate, and so forth.\n\n@examples\n\n```cli\nSET mykey \"foobar\"\nBITCOUNT mykey\nBITCOUNT mykey 0 0\nBITCOUNT mykey 1 1\nBITCOUNT mykey 1 1 BYTE\nBITCOUNT mykey 5 30 BIT\n```\n\n## Pattern: real-time metrics using bitmaps\n\nBitmaps are a very space-efficient representation of certain kinds of\ninformation.\nOne example is a Web application that needs the history of user visits, so that\nfor instance it is possible to determine what users are good targets of beta\nfeatures.\n\nUsing the [`SETBIT`](./setbit) command this is trivial to accomplish, identifying every day\nwith a small progressive integer.\nFor instance day 0 is the first day the application was put online, day 1 the\nnext day, and so forth.\n\nEvery time a user performs a page view, the application can register that in\nthe current day the user visited the web site using the [`SETBIT`](./setbit) command setting\nthe bit corresponding to the current day.\n\nLater it will be trivial to know the number of single days the user visited the\nweb site simply calling the `BITCOUNT` command against the bitmap.\n\nA similar pattern where user IDs are used instead of days is described\nin the article called \"[Fast easy realtime metrics using Redis\nbitmaps][hbgc212fermurb]\".\n\n[hbgc212fermurb]: http://blog.getspool.com/2011/11/29/fast-easy-realtime-metrics-using-redis-bitmaps\n\n## Performance considerations\n\nIn the above example of counting days, even after 10 years the application is\nonline we still have just `365*10` bits of data per user, that is just 456 bytes\nper user.\nWith this amount of data `BITCOUNT` is still as fast as any other O(1) Redis\ncommand like [`GET`](./get) or [`INCR`](./incr).\n\nWhen the bitmap is big, there are two alternatives:\n\n* Taking a separated key that is incremented every time the bitmap is modified.\n  This can be very efficient and atomic using a small Redis Lua script.\n* Running the bitmap incrementally using the `BITCOUNT` _start_ and _end_\n  optional parameters, accumulating the results client-side, and optionally\n  caching the result into a key.\n\n",
            "history": [
                [
                    "7.0",
                    "Added the `BYTE|BIT` option."
                ]
            ],
            "": "",
            "return_types": [
                {
                    "type": "integer"
                }
            ],
            "summary": "Count set bits in a string",
            "complexity": "O(N)",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "optional": true,
                    "name": "index",
                    "type": "block",
                    "value": [
                        {
                            "name": "start",
                            "type": "integer",
                            "value": "start"
                        },
                        {
                            "name": "end",
                            "type": "integer",
                            "value": "end"
                        },
                        {
                            "optional": true,
                            "name": "byte_bit",
                            "type": "oneof",
                            "value": [
                                {
                                    "name": "__TBD__117__",
                                    "token": "BYTE"
                                },
                                {
                                    "name": "__TBD__118__",
                                    "token": "BIT"
                                }
                            ]
                        }
                    ]
                }
            ],
            "since": "2.6.0",
            "group": "bitmap",
            "arity": -2,
            "command_flags": [
                "readonly"
            ],
            "acl_categories": [
                "read",
                "bitmap",
                "slow"
            ],
            "key_specs": [
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "bitcountCommand"
        }
    },
    {
        "BZMPOP": {
            "body": "`BZMPOP` is the blocking variant of [`ZMPOP`](./zmpop).\n\nWhen any of the sorted sets contains elements, this command behaves exactly like [`ZMPOP`](./zmpop).\nWhen used inside a [`MULTI`](./multi)/[`EXEC`](./exec) block, this command behaves exactly like [`ZMPOP`](./zmpop).\nWhen all sorted sets are empty, Redis will block the connection until another client adds members to one of the keys or until the `timeout` (a double value specifying the maximum number of seconds to block) elapses.\nA `timeout` of zero can be used to block indefinitely.\n\nSee [`ZMPOP`](./zmpop) for more information.\n\n",
            "": "",
            "return_types": [
                {
                    "description": "specifically:",
                    "type": "array"
                }
            ],
            "summary": "Remove and return members with scores in a sorted set or block until one is available",
            "complexity": "O(K) + O(N*log(M)) where K is the number of provided keys, N being the number of elements in the sorted set, and M being the number of elements popped.",
            "arguments": [
                {
                    "name": "timeout",
                    "type": "double",
                    "value": "timeout"
                },
                {
                    "name": "numkeys",
                    "type": "integer",
                    "value": "numkeys"
                },
                {
                    "multiple": true,
                    "multiple_token": true,
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "name": "min_max",
                    "type": "oneof",
                    "value": [
                        {
                            "name": "__TBD__119__",
                            "token": "MIN"
                        },
                        {
                            "name": "__TBD__120__",
                            "token": "MAX"
                        }
                    ]
                },
                {
                    "token": "COUNT",
                    "optional": true,
                    "name": "count",
                    "type": "integer",
                    "value": "count"
                }
            ],
            "since": "7.0.0",
            "group": "sorted_set",
            "arity": -5,
            "command_flags": [
                "write"
            ],
            "acl_categories": [
                "write",
                "sortedset",
                "slow",
                "blocking"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 2
                        }
                    },
                    "find_keys": {
                        "keynum": {
                            "keynumidx": 0,
                            "firstkey": 1,
                            "step": 1
                        }
                    }
                }
            ],
            "function": "bzmpopCommand",
            "get_keys_function": "blmpopGetKeys"
        }
    },
    {
        "PTTL": {
            "body": "Like [`TTL`](./ttl) this command returns the remaining time to live of a key that has an\nexpire set, with the sole difference that [`TTL`](./ttl) returns the amount of remaining\ntime in seconds while `PTTL` returns it in milliseconds.\n\nIn Redis 2.6 or older the command returns `-1` if the key does not exist or if the key exist but has no associated expire.\n\nStarting with Redis 2.8 the return value in case of error changed:\n\n* The command returns `-2` if the key does not exist.\n* The command returns `-1` if the key exists but has no associated expire.\n\n@examples\n\n```cli\nSET mykey \"Hello\"\nEXPIRE mykey 1\nPTTL mykey\n```\n\n",
            "": "",
            "return_types": [
                {
                    "description": "TTL in milliseconds, or a negative value in order to signal an error (see the description above).",
                    "type": "integer"
                }
            ],
            "summary": "Get the time to live for a key in milliseconds",
            "complexity": "O(1)",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                }
            ],
            "since": "2.6.0",
            "group": "generic",
            "arity": 2,
            "command_flags": [
                "readonly",
                "random",
                "fast"
            ],
            "acl_categories": [
                "keyspace",
                "read",
                "fast"
            ],
            "key_specs": [
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "pttlCommand"
        }
    },
    {
        "ZRANK": {
            "body": "Returns the rank of `member` in the sorted set stored at `key`, with the scores\nordered from low to high.\nThe rank (or index) is 0-based, which means that the member with the lowest\nscore has rank `0`.\n\nUse [`ZREVRANK`](./zrevrank) to get the rank of an element with the scores ordered from high\nto low.\n\n@examples\n\n```cli\nZADD myzset 1 \"one\"\nZADD myzset 2 \"two\"\nZADD myzset 3 \"three\"\nZRANK myzset \"three\"\nZRANK myzset \"four\"\n```\n\n",
            "return_summary": "* If `member` exists in the sorted set, @integer-reply: the rank of `member`.\n* If `member` does not exist in the sorted set or `key` does not exist,\n  @bulk-string-reply: `nil`.",
            "": "",
            "summary": "Determine the index of a member in a sorted set",
            "complexity": "O(log(N))",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "name": "member",
                    "type": "string",
                    "value": "member"
                }
            ],
            "since": "2.0.0",
            "group": "sorted_set",
            "arity": 3,
            "command_flags": [
                "readonly",
                "fast"
            ],
            "acl_categories": [
                "read",
                "sortedset",
                "fast"
            ],
            "key_specs": [
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "zrankCommand"
        }
    },
    {
        "BRPOPLPUSH": {
            "body": "`BRPOPLPUSH` is the blocking variant of [`RPOPLPUSH`](./rpoplpush).\nWhen `source` contains elements, this command behaves exactly like [`RPOPLPUSH`](./rpoplpush).\nWhen used inside a [`MULTI`](./multi)/[`EXEC`](./exec) block, this command behaves exactly like [`RPOPLPUSH`](./rpoplpush).\nWhen `source` is empty, Redis will block the connection until another client\npushes to it or until `timeout` is reached.\nA `timeout` of zero can be used to block indefinitely.\n\nAs per Redis 6.2.0, BRPOPLPUSH is considered deprecated. Please prefer [`BLMOVE`](./blmove) in\nnew code.\n\nSee [`RPOPLPUSH`](./rpoplpush) for more information.\n\n## Pattern: Reliable queue\n\nPlease see the pattern description in the [`RPOPLPUSH`](./rpoplpush) documentation.\n\n## Pattern: Circular list\n\nPlease see the pattern description in the [`RPOPLPUSH`](./rpoplpush) documentation.\n\n",
            "history": [
                [
                    "6.0",
                    "`timeout` is interpreted as a double instead of an integer."
                ]
            ],
            "return_summary": "@bulk-string-reply: the element being popped from `source` and pushed to `destination`.\nIf `timeout` is reached, a @nil-reply is returned.",
            "deprecated": true,
            "": "",
            "summary": "Pop an element from a list, push it to another list and return it; or block until one is available",
            "complexity": "O(1)",
            "arguments": [
                {
                    "name": "source",
                    "type": "key",
                    "value": "source"
                },
                {
                    "name": "destination",
                    "type": "key",
                    "value": "destination"
                },
                {
                    "name": "timeout",
                    "type": "double",
                    "value": "timeout"
                }
            ],
            "since": "2.2.0",
            "group": "list",
            "arity": 4,
            "command_flags": [
                "write",
                "denyoom",
                "noscript"
            ],
            "acl_categories": [
                "write",
                "list",
                "slow",
                "blocking"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write",
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                },
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 2
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "brpoplpushCommand"
        }
    },
    {
        "ZDIFF": {
            "body": "This command is similar to [`ZDIFFSTORE`](./zdiffstore), but instead of storing the resulting\nsorted set, it is returned to the client.\n\n@examples\n\n```cli\nZADD zset1 1 \"one\"\nZADD zset1 2 \"two\"\nZADD zset1 3 \"three\"\nZADD zset2 1 \"one\"\nZADD zset2 2 \"two\"\nZDIFF 2 zset1 zset2\nZDIFF 2 zset1 zset2 WITHSCORES\n```\n\n",
            "": "",
            "return_types": [
                {
                    "description": "the result of the difference (optionally with their scores, in case",
                    "type": "array"
                }
            ],
            "summary": "Subtract multiple sorted sets",
            "complexity": "O(L + (N-K)log(N)) worst case where L is the total number of elements in all the sets, N is the size of the first set, and K is the size of the result set.",
            "arguments": [
                {
                    "name": "numkeys",
                    "type": "integer",
                    "value": "numkeys"
                },
                {
                    "multiple": true,
                    "multiple_token": true,
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "optional": true,
                    "name": "withscores",
                    "token": "WITHSCORES"
                }
            ],
            "since": "6.2.0",
            "group": "sorted_set",
            "arity": -3,
            "command_flags": [
                "readonly"
            ],
            "acl_categories": [
                "read",
                "sortedset",
                "slow"
            ],
            "key_specs": [
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "keynum": {
                            "keynumidx": 0,
                            "firstkey": 1,
                            "step": 1
                        }
                    }
                }
            ],
            "function": "zdiffCommand",
            "get_keys_function": "zunionInterDiffGetKeys"
        }
    },
    {
        "HSTRLEN": {
            "body": "Returns the string length of the value associated with `field` in the hash stored at `key`. If the `key` or the `field` do not exist, 0 is returned.\n\n@examples\n\n```cli\nHMSET myhash f1 HelloWorld f2 99 f3 -256\nHSTRLEN myhash f1\nHSTRLEN myhash f2\nHSTRLEN myhash f3\n```\n\n",
            "": "",
            "return_types": [
                {
                    "description": "the string length of the value associated with `field`, or zero when `field` is not present in the hash or `key` does not exist at all.",
                    "type": "integer"
                }
            ],
            "summary": "Get the length of the value of a hash field",
            "complexity": "O(1)",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "name": "field",
                    "type": "string",
                    "value": "field"
                }
            ],
            "since": "3.2.0",
            "group": "hash",
            "arity": 3,
            "command_flags": [
                "readonly",
                "fast"
            ],
            "acl_categories": [
                "read",
                "hash",
                "fast"
            ],
            "key_specs": [
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "hstrlenCommand"
        }
    },
    {
        "SHUTDOWN": {
            "body": "The command behavior is the following:\n\n* Stop all the clients.\n* Perform a blocking SAVE if at least one **save point** is configured.\n* Flush the Append Only File if AOF is enabled.\n* Quit the server.\n\nIf persistence is enabled this commands makes sure that Redis is switched off\nwithout the lost of any data.\nThis is not guaranteed if the client uses simply [`SAVE`](./save) and then `QUIT` because\nother clients may alter the DB data between the two commands.\n\nNote: A Redis instance that is configured for not persisting on disk (no AOF\nconfigured, nor \"save\" directive) will not dump the RDB file on `SHUTDOWN`, as\nusually you don't want Redis instances used only for caching to block on when\nshutting down.\n\n## SAVE and NOSAVE modifiers\n\nIt is possible to specify an optional modifier to alter the behavior of the\ncommand.\nSpecifically:\n\n* **SHUTDOWN SAVE** will force a DB saving operation even if no save points are\n  configured.\n* **SHUTDOWN NOSAVE** will prevent a DB saving operation even if one or more\n  save points are configured.\n  (You can think of this variant as an hypothetical **ABORT** command that just\n  stops the server).\n\n## Conditions where a SHUTDOWN fails\n\nWhen the Append Only File is enabled the shutdown may fail because the\nsystem is in a state that does not allow to safely immediately persist\non disk.\n\nNormally if there is an AOF child process performing an AOF rewrite, Redis\nwill simply kill it and exit. However there are two conditions where it is\nunsafe to do so, and the **SHUTDOWN** command will be refused with an error\ninstead. This happens when:\n\n* The user just turned on AOF, and the server triggered the first AOF rewrite in order to create the initial AOF file. In this context, stopping will result in losing the dataset at all: once restarted, the server will potentially have AOF enabled without having any AOF file at all.\n* A replica with AOF enabled, reconnected with its master, performed a full resynchronization, and restarted the AOF file, triggering the initial AOF creation process. In this case not completing the AOF rewrite is dangerous because the latest dataset received from the master would be lost. The new master can actually be even a different instance (if the **REPLICAOF** or **SLAVEOF** command was used in order to reconfigure the replica), so it is important to finish the AOF rewrite and start with the correct data set representing the data set in memory when the server was terminated.\n\nThere are conditions when we want just to terminate a Redis instance ASAP, regardless of what its content is. In such a case, the right combination of commands is to send a **CONFIG appendonly no** followed by a **SHUTDOWN NOSAVE**. The first command will turn off the AOF if needed, and will terminate the AOF rewriting child if there is one active. The second command will not have any problem to execute since the AOF is no longer enabled.\n\n",
            "return_summary": "@simple-string-reply on error.\nOn success nothing is returned since the server quits and the connection is\nclosed.",
            "": "",
            "summary": "Synchronously save the dataset to disk and then shut down the server",
            "arguments": [
                {
                    "optional": true,
                    "name": "nosave_save",
                    "type": "oneof",
                    "value": [
                        {
                            "name": "__TBD__121__",
                            "token": "NOSAVE"
                        },
                        {
                            "name": "__TBD__122__",
                            "token": "SAVE"
                        }
                    ]
                }
            ],
            "since": "1.0.0",
            "group": "server",
            "arity": -1,
            "command_flags": [
                "admin",
                "noscript",
                "loading",
                "stale"
            ],
            "acl_categories": [
                "admin",
                "slow",
                "dangerous"
            ],
            "function": "shutdownCommand"
        }
    },
    {
        "BLMPOP": {
            "body": "`BLMPOP` is the blocking variant of [`LMPOP`](./lmpop).\n\nWhen any of the lists contains elements, this command behaves exactly like [`LMPOP`](./lmpop).\nWhen used inside a [`MULTI`](./multi)/[`EXEC`](./exec) block, this command behaves exactly like [`LMPOP`](./lmpop).\nWhen all lists are empty, Redis will block the connection until another client pushes to it or until the `timeout` (a double value specifying the maximum number of seconds to block) elapses.\nA `timeout` of zero can be used to block indefinitely.\n\nSee [`LMPOP`](./lmpop) for more information.\n\n",
            "": "",
            "return_types": [
                {
                    "description": "specifically:",
                    "type": "array"
                }
            ],
            "summary": "Pop elements from a list, or block until one is available",
            "complexity": "O(N+M) where N is the number of provided keys and M is the number of elements returned.",
            "arguments": [
                {
                    "name": "timeout",
                    "type": "double",
                    "value": "timeout"
                },
                {
                    "name": "numkeys",
                    "type": "integer",
                    "value": "numkeys"
                },
                {
                    "multiple": true,
                    "multiple_token": true,
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "name": "left_right",
                    "type": "oneof",
                    "value": [
                        {
                            "name": "__TBD__123__",
                            "token": "LEFT"
                        },
                        {
                            "name": "__TBD__124__",
                            "token": "RIGHT"
                        }
                    ]
                },
                {
                    "token": "COUNT",
                    "optional": true,
                    "name": "count",
                    "type": "integer",
                    "value": "count"
                }
            ],
            "since": "7.0.0",
            "group": "list",
            "arity": -5,
            "command_flags": [
                "write"
            ],
            "acl_categories": [
                "write",
                "list",
                "slow",
                "blocking"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 2
                        }
                    },
                    "find_keys": {
                        "keynum": {
                            "keynumidx": 0,
                            "firstkey": 1,
                            "step": 1
                        }
                    }
                }
            ],
            "function": "blmpopCommand",
            "get_keys_function": "blmpopGetKeys"
        }
    },
    {
        "FLUSHDB": {
            "body": "Delete all the keys of the currently selected DB.\nThis command never fails.\n\nBy default, `FLUSHDB` will synchronously flush all keys from the database.\nStarting with Redis 6.2, setting the **lazyfree-lazy-user-flush** configuration directive to \"yes\" changes the default flush mode to asynchronous.\n\nIt is possible to use one of the following modifiers to dictate the flushing mode explicitly:\n\n* `ASYNC`: flushes the database asynchronously\n* `SYNC`: flushes the database synchronously\n\nNote: an asynchronous `FLUSHDB` command only deletes keys that were present at the time the command was invoked. Keys created during an asynchronous flush will be unaffected.\n\n",
            "": "",
            "return_types": [
                {
                    "type": "simple-string"
                }
            ],
            "summary": "Remove all keys from the current database",
            "complexity": "O(N) where N is the number of keys in the selected database",
            "arguments": [
                {
                    "optional": true,
                    "name": "async_sync",
                    "type": "oneof",
                    "value": [
                        {
                            "name": "__TBD__125__",
                            "token": "ASYNC"
                        },
                        {
                            "name": "__TBD__126__",
                            "token": "SYNC"
                        }
                    ]
                }
            ],
            "since": "1.0.0",
            "group": "server",
            "arity": -1,
            "command_flags": [
                "write"
            ],
            "acl_categories": [
                "keyspace",
                "write",
                "slow",
                "dangerous"
            ],
            "function": "flushdbCommand"
        }
    },
    {
        "HINCRBY": {
            "body": "Increments the number stored at `field` in the hash stored at `key` by\n`increment`.\nIf `key` does not exist, a new key holding a hash is created.\nIf `field` does not exist the value is set to `0` before the operation is\nperformed.\n\nThe range of values supported by `HINCRBY` is limited to 64 bit signed integers.\n\n@examples\n\nSince the `increment` argument is signed, both increment and decrement\noperations can be performed:\n\n```cli\nHSET myhash field 5\nHINCRBY myhash field 1\nHINCRBY myhash field -1\nHINCRBY myhash field -10\n```\n\n",
            "": "",
            "return_types": [
                {
                    "description": "the value at `field` after the increment operation.",
                    "type": "integer"
                }
            ],
            "summary": "Increment the integer value of a hash field by the given number",
            "complexity": "O(1)",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "name": "field",
                    "type": "string",
                    "value": "field"
                },
                {
                    "name": "increment",
                    "type": "integer",
                    "value": "increment"
                }
            ],
            "since": "2.0.0",
            "group": "hash",
            "arity": 4,
            "command_flags": [
                "write",
                "denyoom",
                "fast"
            ],
            "acl_categories": [
                "write",
                "hash",
                "fast"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "hincrbyCommand"
        }
    },
    {
        "RPOP": {
            "body": "Removes and returns the last elements of the list stored at `key`.\n\nBy default, the command pops a single element from the end of the list.\nWhen provided with the optional `count` argument, the reply will consist of up\nto `count` elements, depending on the list's length.\n\n@examples\n\n```cli\nRPUSH mylist \"one\" \"two\" \"three\" \"four\" \"five\"\nRPOP mylist\nRPOP mylist 2\nLRANGE mylist 0 -1\n```\n\n",
            "history": [
                [
                    "6.2",
                    "Added the `count` argument."
                ]
            ],
            "return_summary": "When called without the `count` argument:\n\n@bulk-string-reply: the value of the last element, or `nil` when `key` does not exist.\n\nWhen called with the `count` argument:\n\n@array-reply: list of popped elements, or `nil` when `key` does not exist.",
            "": "",
            "summary": "Remove and get the last elements in a list",
            "complexity": "O(N) where N is the number of elements returned",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "optional": true,
                    "name": "count",
                    "type": "integer",
                    "value": "count"
                }
            ],
            "since": "1.0.0",
            "group": "list",
            "arity": -2,
            "command_flags": [
                "write",
                "fast"
            ],
            "acl_categories": [
                "write",
                "list",
                "fast"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "rpopCommand"
        }
    },
    {
        "MONITOR": {
            "body": "`MONITOR` is a debugging command that streams back every command processed by\nthe Redis server.\nIt can help in understanding what is happening to the database.\nThis command can both be used via `redis-cli` and via `telnet`.\n\nThe ability to see all the requests processed by the server is useful in order\nto spot bugs in an application both when using Redis as a database and as a\ndistributed caching system.\n\n```\n$ redis-cli monitor\n1339518083.107412 [0 127.0.0.1:60866] \"keys\" \"*\"\n1339518087.877697 [0 127.0.0.1:60866] \"dbsize\"\n1339518090.420270 [0 127.0.0.1:60866] \"set\" \"x\" \"6\"\n1339518096.506257 [0 127.0.0.1:60866] \"get\" \"x\"\n1339518099.363765 [0 127.0.0.1:60866] \"eval\" \"return redis.call('set','x','7')\" \"0\"\n1339518100.363799 [0 lua] \"set\" \"x\" \"7\"\n1339518100.544926 [0 127.0.0.1:60866] \"del\" \"x\"\n```\n\nUse `SIGINT` (Ctrl-C) to stop a `MONITOR` stream running via `redis-cli`.\n\n```\n$ telnet localhost 6379\nTrying 127.0.0.1...\nConnected to localhost.\nEscape character is '^]'.\nMONITOR\n+OK\n+1339518083.107412 [0 127.0.0.1:60866] \"keys\" \"*\"\n+1339518087.877697 [0 127.0.0.1:60866] \"dbsize\"\n+1339518090.420270 [0 127.0.0.1:60866] \"set\" \"x\" \"6\"\n+1339518096.506257 [0 127.0.0.1:60866] \"get\" \"x\"\n+1339518099.363765 [0 127.0.0.1:60866] \"del\" \"x\"\n+1339518100.544926 [0 127.0.0.1:60866] \"get\" \"x\"\nQUIT\n+OK\nConnection closed by foreign host.\n```\n\nManually issue the `QUIT` or [`RESET`](./reset) commands to stop a `MONITOR` stream running\nvia `telnet`.\n\n## Commands not logged by MONITOR\n\nBecause of security concerns, no administrative commands are logged\nby `MONITOR`'s output and sensitive data is redacted in the command [`AUTH`](./auth).\n\nFurthermore, the command `QUIT` is also not logged.\n\n## Cost of running MONITOR\n\nBecause `MONITOR` streams back **all** commands, its use comes at a cost.\nThe following (totally unscientific) benchmark numbers illustrate what the cost\nof running `MONITOR` can be.\n\nBenchmark result **without** `MONITOR` running:\n\n```\n$ src/redis-benchmark -c 10 -n 100000 -q\nPING_INLINE: 101936.80 requests per second\nPING_BULK: 102880.66 requests per second\nSET: 95419.85 requests per second\nGET: 104275.29 requests per second\nINCR: 93283.58 requests per second\n```\n\nBenchmark result **with** `MONITOR` running (`redis-cli monitor > /dev/null`):\n\n```\n$ src/redis-benchmark -c 10 -n 100000 -q\nPING_INLINE: 58479.53 requests per second\nPING_BULK: 59136.61 requests per second\nSET: 41823.50 requests per second\nGET: 45330.91 requests per second\nINCR: 41771.09 requests per second\n```\n\nIn this particular case, running a single `MONITOR` client can reduce the\nthroughput by more than 50%.\nRunning more `MONITOR` clients will reduce throughput even more.\n\n",
            "history": [
                [
                    "6.0",
                    "[`AUTH`](./auth) excluded from the command's output."
                ],
                [
                    "6.2",
                    "[`RESET`](./reset) can be called to exit monitor mode."
                ],
                [
                    "6.2.4",
                    "[`AUTH`](./auth), [`HELLO`](./hello), [`EVAL`](./eval), [`EVAL_RO`](./eval_ro), [`EVALSHA`](./evalsha) and [`EVALSHA_RO`](./evalsha_ro) included in the command's output."
                ]
            ],
            "return_summary": "**Non standard return value**, just dumps the received commands in an infinite\nflow.",
            "": "",
            "summary": "Listen for all requests received by the server in real time",
            "since": "1.0.0",
            "group": "server",
            "arity": 1,
            "command_flags": [
                "admin",
                "noscript",
                "loading",
                "stale"
            ],
            "acl_categories": [
                "admin",
                "slow",
                "dangerous"
            ],
            "function": "monitorCommand"
        }
    },
    {
        "ZREMRANGEBYLEX": {
            "body": "When all the elements in a sorted set are inserted with the same score, in order to force lexicographical ordering, this command removes all elements in the sorted set stored at `key` between the lexicographical range specified by `min` and `max`.\n\nThe meaning of `min` and `max` are the same of the [`ZRANGEBYLEX`](./zrangebylex) command. Similarly, this command actually removes the same elements that [`ZRANGEBYLEX`](./zrangebylex) would return if called with the same `min` and `max` arguments.\n\n@examples\n\n```cli\nZADD myzset 0 aaaa 0 b 0 c 0 d 0 e\nZADD myzset 0 foo 0 zap 0 zip 0 ALPHA 0 alpha\nZRANGE myzset 0 -1\nZREMRANGEBYLEX myzset [alpha [omega\nZRANGE myzset 0 -1\n```\n\n",
            "": "",
            "return_types": [
                {
                    "description": "the number of elements removed.",
                    "type": "integer"
                }
            ],
            "summary": "Remove all members in a sorted set between the given lexicographical range",
            "complexity": "O(log(N)+M) with N being the number of elements in the sorted set and M the number of elements removed by the operation.",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "name": "min",
                    "type": "string",
                    "value": "min"
                },
                {
                    "name": "max",
                    "type": "string",
                    "value": "max"
                }
            ],
            "since": "2.8.9",
            "group": "sorted_set",
            "arity": 4,
            "command_flags": [
                "write"
            ],
            "acl_categories": [
                "write",
                "sortedset",
                "slow"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "zremrangebylexCommand"
        }
    },
    {
        "SWAPDB": {
            "body": "This command swaps two Redis databases, so that immediately all the\nclients connected to a given database will see the data of the other database, and\nthe other way around. Example:\n\n    SWAPDB 0 1\n\nThis will swap database 0 with database 1. All the clients connected with database 0 will immediately see the new data, exactly like all the clients connected with database 1 will see the data that was formerly of database 0.\n\n@examples\n\n```\nSWAPDB 0 1\n```\n\n",
            "": "",
            "return_types": [
                {
                    "description": "`OK` if `SWAPDB` was executed correctly.",
                    "type": "simple-string"
                }
            ],
            "summary": "Swaps two Redis databases",
            "complexity": "O(N) where N is the count of clients watching or blocking on keys from both databases.",
            "arguments": [
                {
                    "name": "index1",
                    "type": "integer",
                    "value": "index1"
                },
                {
                    "name": "index2",
                    "type": "integer",
                    "value": "index2"
                }
            ],
            "since": "4.0.0",
            "group": "server",
            "arity": 3,
            "command_flags": [
                "write",
                "fast"
            ],
            "acl_categories": [
                "keyspace",
                "write",
                "fast",
                "dangerous"
            ],
            "function": "swapdbCommand"
        }
    },
    {
        "BZPOPMIN": {
            "body": "`BZPOPMIN` is the blocking variant of the sorted set [`ZPOPMIN`](./zpopmin) primitive.\n\nIt is the blocking version because it blocks the connection when there are no\nmembers to pop from any of the given sorted sets.\nA member with the lowest score is popped from first sorted set that is\nnon-empty, with the given keys being checked in the order that they are given.\n\nThe `timeout` argument is interpreted as an double value specifying the maximum\nnumber of seconds to block. A timeout of zero can be used to block indefinitely.\n\nSee the [BLPOP documentation][cl] for the exact semantics, since `BZPOPMIN` is\nidentical to [`BLPOP`](./blpop) with the only difference being the data structure being\npopped from.\n\n[cl]: /commands/blpop\n\n@examples\n\n```\nredis> DEL zset1 zset2\n(integer) 0\nredis> ZADD zset1 0 a 1 b 2 c\n(integer) 3\nredis> BZPOPMIN zset1 zset2 0\n1) \"zset1\"\n2) \"a\"\n3) \"0\"\n```\n\n",
            "history": [
                [
                    "6.0",
                    "`timeout` is interpreted as a double instead of an integer."
                ]
            ],
            "": "",
            "return_types": [
                {
                    "description": "specifically:",
                    "type": "array"
                }
            ],
            "summary": "Remove and return the member with the lowest score from one or more sorted sets, or block until one is available",
            "complexity": "O(log(N)) with N being the number of elements in the sorted set.",
            "arguments": [
                {
                    "multiple": true,
                    "multiple_token": true,
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "name": "timeout",
                    "type": "double",
                    "value": "timeout"
                }
            ],
            "since": "5.0.0",
            "group": "sorted_set",
            "arity": -3,
            "command_flags": [
                "write",
                "noscript",
                "fast"
            ],
            "acl_categories": [
                "write",
                "sortedset",
                "fast",
                "blocking"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": -2,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "bzpopminCommand"
        }
    },
    {
        "REPLCONF": {
            "arity": -1,
            "command_flags": [
                "admin",
                "noscript",
                "loading",
                "stale"
            ],
            "acl_categories": [
                "admin",
                "slow",
                "dangerous"
            ],
            "function": "replconfCommand",
            "group": "server",
            "internal": true
        }
    },
    {
        "XGROUP": {
            "arity": -2,
            "command_flags": [],
            "acl_categories": [
                "slow"
            ],
            "subcommands": [
                {
                    "DESTROY": {
                        "body": "The `XGROUP DESTROY` command completely destroys a consumer group.\n\nThe consumer group will be destroyed even if there are active consumers, and pending messages, so make sure to call this command only when really needed.\n\n",
                        "": "",
                        "return_types": [
                            {
                                "description": "the number of destroyed consumer groups (0 or 1)",
                                "type": "integer"
                            }
                        ],
                        "summary": "Destroy a consumer group.",
                        "complexity": "O(N) where N is the number of entries in the group's pending entries list (PEL).",
                        "arguments": [
                            {
                                "name": "key",
                                "type": "key",
                                "value": "key"
                            },
                            {
                                "name": "groupname",
                                "type": "string",
                                "value": "groupname"
                            }
                        ],
                        "since": "5.0.0",
                        "group": "stream",
                        "arity": 4,
                        "command_flags": [
                            "write"
                        ],
                        "acl_categories": [
                            "write",
                            "stream",
                            "slow"
                        ],
                        "key_specs": [
                            {
                                "flags": [
                                    "write"
                                ],
                                "begin_search": {
                                    "index": {
                                        "pos": 2
                                    }
                                },
                                "find_keys": {
                                    "range": {
                                        "lastkey": 0,
                                        "step": 1,
                                        "limit": 0
                                    }
                                }
                            }
                        ],
                        "function": "xgroupCommand",
                        "container": "XGROUP"
                    }
                },
                {
                    "SETID": {
                        "body": "Set the **last delivered ID** for a consumer group.\n\nNormally, a consumer group's last delivered ID is set when the group is created with `XGROUP CREATE`.\nThe `XGROUP SETID` command allows modifying the group's last delivered ID, without having to delete and recreate the group.\nFor instance if you want the consumers in a consumer group to re-process all the messages in a stream, you may want to set its next ID to 0:\n\n    XGROUP SETID mystream mygroup 0\n\n",
                        "": "",
                        "return_types": [
                            {
                                "description": "`OK` on success.",
                                "type": "simple-string"
                            }
                        ],
                        "summary": "Set a consumer group to an arbitrary last delivered ID value.",
                        "complexity": "O(1)",
                        "arguments": [
                            {
                                "name": "key",
                                "type": "key",
                                "value": "key"
                            },
                            {
                                "name": "groupname",
                                "type": "string",
                                "value": "groupname"
                            },
                            {
                                "name": "id",
                                "type": "string",
                                "value": "id"
                            }
                        ],
                        "since": "5.0.0",
                        "group": "stream",
                        "arity": 5,
                        "command_flags": [
                            "write"
                        ],
                        "acl_categories": [
                            "write",
                            "stream",
                            "slow"
                        ],
                        "key_specs": [
                            {
                                "flags": [
                                    "write"
                                ],
                                "begin_search": {
                                    "index": {
                                        "pos": 2
                                    }
                                },
                                "find_keys": {
                                    "range": {
                                        "lastkey": 0,
                                        "step": 1,
                                        "limit": 0
                                    }
                                }
                            }
                        ],
                        "function": "xgroupCommand",
                        "container": "XGROUP"
                    }
                },
                {
                    "CREATE": {
                        "body": "This command creates a new consumer group uniquely identified by `<groupname>` for the stream stored at `<key>`.\n\nEvery group has a unique name in a given stream. When a consumer group with the same name already exists, the command returns a `-BUSYGROUP` error.\n\nThe command's `<id>` argument specifies the last delivered entry in the stream from the new group's perspective.\nThe special ID `$` means the ID of the last entry in the stream, but you can provide any valid ID instead.\nFor example, if you want the group's consumers to fetch the entire stream from the beginning, use zero as the starting ID for the consumer group:\n\n    XGROUP CREATE mystream mygroup 0\n\nBy default, the `XGROUP CREATE` command insists that the target stream exists and returns an error when it doesn't.\nHowever, you can use the optional `MKSTREAM` subcommand as the last argument after the `<id>` to automatically create the stream (with length of 0) if it doesn't exist:\n\n    XGROUP CREATE mystream mygroup $ MKSTREAM\n\n",
                        "": "",
                        "return_types": [
                            {
                                "description": "`OK` on success.",
                                "type": "simple-string"
                            }
                        ],
                        "summary": "Create a consumer group.",
                        "complexity": "O(1)",
                        "arguments": [
                            {
                                "name": "key",
                                "type": "key",
                                "value": "key"
                            },
                            {
                                "name": "groupname",
                                "type": "string",
                                "value": "groupname"
                            },
                            {
                                "name": "id_$",
                                "type": "oneof",
                                "value": [
                                    {
                                        "name": "__TBD__127__",
                                        "token": "id"
                                    },
                                    {
                                        "name": "__TBD__128__",
                                        "token": "$"
                                    }
                                ]
                            },
                            {
                                "token": "MKSTREAM",
                                "optional": true,
                                "name": "mkstream"
                            }
                        ],
                        "since": "5.0.0",
                        "group": "stream",
                        "arity": -5,
                        "command_flags": [
                            "write",
                            "denyoom"
                        ],
                        "acl_categories": [
                            "write",
                            "stream",
                            "slow"
                        ],
                        "key_specs": [
                            {
                                "flags": [
                                    "write"
                                ],
                                "begin_search": {
                                    "index": {
                                        "pos": 2
                                    }
                                },
                                "find_keys": {
                                    "range": {
                                        "lastkey": 0,
                                        "step": 1,
                                        "limit": 0
                                    }
                                }
                            }
                        ],
                        "function": "xgroupCommand",
                        "container": "XGROUP"
                    }
                },
                {
                    "CREATECONSUMER": {
                        "body": "Create a consumer named `<consumername>` in the consumer group `<groupname>` of the stream that's stored at `<key>`.\n\nConsumers are also created automatically whenever an operation, such as [`XREADGROUP`](./xreadgroup), references a consumer that doesn't exist.\n\n",
                        "": "",
                        "return_types": [
                            {
                                "description": "the number of created consumers (0 or 1)",
                                "type": "integer"
                            }
                        ],
                        "summary": "Create a consumer in a consumer group.",
                        "complexity": "O(1)",
                        "arguments": [
                            {
                                "name": "key",
                                "type": "key",
                                "value": "key"
                            },
                            {
                                "name": "groupname",
                                "type": "string",
                                "value": "groupname"
                            },
                            {
                                "name": "consumername",
                                "type": "string",
                                "value": "consumername"
                            }
                        ],
                        "since": "6.2.0",
                        "group": "stream",
                        "arity": 5,
                        "command_flags": [
                            "write",
                            "denyoom"
                        ],
                        "acl_categories": [
                            "write",
                            "stream",
                            "slow"
                        ],
                        "key_specs": [
                            {
                                "flags": [
                                    "write"
                                ],
                                "begin_search": {
                                    "index": {
                                        "pos": 2
                                    }
                                },
                                "find_keys": {
                                    "range": {
                                        "lastkey": 0,
                                        "step": 1,
                                        "limit": 0
                                    }
                                }
                            }
                        ],
                        "function": "xgroupCommand",
                        "container": "XGROUP"
                    }
                },
                {
                    "HELP": {
                        "body": "The `XGROUP HELP` command returns a helpful text describing the different subcommands.\n\n",
                        "": "",
                        "return_types": [
                            {
                                "description": "a list of subcommands and their descriptions",
                                "type": "array"
                            }
                        ],
                        "summary": "Show helpful text about the different subcommands",
                        "complexity": "O(1)",
                        "since": "5.0.0",
                        "group": "stream",
                        "arity": 2,
                        "command_flags": [
                            "loading",
                            "stale"
                        ],
                        "acl_categories": [
                            "stream",
                            "slow"
                        ],
                        "function": "xgroupCommand",
                        "container": "XGROUP"
                    }
                },
                {
                    "DELCONSUMER": {
                        "body": "The `XGROUP DELCONSUMER` command deletes a consumer from the consumer group.\n\nSometimes it may be useful to remove old consumers since they are no longer used.\n\nNote, however, that any pending messages that the consumer had will become unclaimable after it was deleted.\nIt is strongly recommended, therefore, that any pending messages are claimed or acknowledged prior to deleting the consumer from the group.\n\n",
                        "": "",
                        "return_types": [
                            {
                                "description": "the number of pending messages that the consumer had before it was deleted",
                                "type": "integer"
                            }
                        ],
                        "summary": "Delete a consumer from a consumer group.",
                        "complexity": "O(1)",
                        "arguments": [
                            {
                                "name": "key",
                                "type": "key",
                                "value": "key"
                            },
                            {
                                "name": "groupname",
                                "type": "string",
                                "value": "groupname"
                            },
                            {
                                "name": "consumername",
                                "type": "string",
                                "value": "consumername"
                            }
                        ],
                        "since": "5.0.0",
                        "group": "stream",
                        "arity": 5,
                        "command_flags": [
                            "write"
                        ],
                        "acl_categories": [
                            "write",
                            "stream",
                            "slow"
                        ],
                        "key_specs": [
                            {
                                "flags": [
                                    "write"
                                ],
                                "begin_search": {
                                    "index": {
                                        "pos": 2
                                    }
                                },
                                "find_keys": {
                                    "range": {
                                        "lastkey": 0,
                                        "step": 1,
                                        "limit": 0
                                    }
                                }
                            }
                        ],
                        "function": "xgroupCommand",
                        "container": "XGROUP"
                    }
                }
            ],
            "group": "stream",
            "since": "5.0.0"
        }
    },
    {
        "SAVE": {
            "body": "The `SAVE` commands performs a **synchronous** save of the dataset producing a\n_point in time_ snapshot of all the data inside the Redis instance, in the form\nof an RDB file.\n\nYou almost never want to call `SAVE` in production environments where it will\nblock all the other clients.\nInstead usually [`BGSAVE`](./bgsave) is used.\nHowever in case of issues preventing Redis to create the background saving child\n(for instance errors in the fork(2) system call), the `SAVE` command can be a\ngood last resort to perform the dump of the latest dataset.\n\nPlease refer to the [persistence documentation][tp] for detailed information.\n\n[tp]: /topics/persistence\n\n",
            "": "",
            "return_types": [
                {
                    "description": "The commands returns OK on success.",
                    "type": "simple-string"
                }
            ],
            "summary": "Synchronously save the dataset to disk",
            "since": "1.0.0",
            "group": "server",
            "arity": 1,
            "command_flags": [
                "admin",
                "noscript"
            ],
            "acl_categories": [
                "admin",
                "slow",
                "dangerous"
            ],
            "function": "saveCommand"
        }
    },
    {
        "LPUSH": {
            "body": "Insert all the specified values at the head of the list stored at `key`.\nIf `key` does not exist, it is created as empty list before performing the push\noperations.\nWhen `key` holds a value that is not a list, an error is returned.\n\nIt is possible to push multiple elements using a single command call just\nspecifying multiple arguments at the end of the command.\nElements are inserted one after the other to the head of the list, from the\nleftmost element to the rightmost element.\nSo for instance the command `LPUSH mylist a b c` will result into a list\ncontaining `c` as first element, `b` as second element and `a` as third element.\n\n@examples\n\n```cli\nLPUSH mylist \"world\"\nLPUSH mylist \"hello\"\nLRANGE mylist 0 -1\n```\n\n",
            "history": [
                [
                    "2.4",
                    "Accepts multiple `element` arguments."
                ]
            ],
            "": "",
            "return_types": [
                {
                    "description": "the length of the list after the push operations.",
                    "type": "integer"
                }
            ],
            "summary": "Prepend one or multiple elements to a list",
            "complexity": "O(1) for each element added, so O(N) to add N elements when the command is called with multiple arguments.",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "multiple": true,
                    "multiple_token": true,
                    "name": "element",
                    "type": "string",
                    "value": "element"
                }
            ],
            "since": "1.0.0",
            "group": "list",
            "arity": -3,
            "command_flags": [
                "write",
                "denyoom",
                "fast"
            ],
            "acl_categories": [
                "write",
                "list",
                "fast"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "lpushCommand"
        }
    },
    {
        "SYNC": {
            "body": "Initiates a replication stream from the master.\n\nThe `SYNC` command is called by Redis replicas for initiating a replication\nstream from the master. It has been replaced in newer versions of Redis by\n [`PSYNC`](./psync).\n\nFor more information about replication in Redis please check the\n[replication page][tr].\n\n[tr]: /topics/replication\n\n",
            "return_summary": "**Non standard return value**, a bulk transfer of the data followed by [`PING`](./ping) and write requests from the master.",
            "": "",
            "summary": "Internal command used for replication",
            "since": "1.0.0",
            "group": "server",
            "arity": 1,
            "command_flags": [
                "admin",
                "noscript"
            ],
            "acl_categories": [
                "admin",
                "slow",
                "dangerous"
            ],
            "function": "syncCommand"
        }
    },
    {
        "LRANGE": {
            "body": "Returns the specified elements of the list stored at `key`.\nThe offsets `start` and `stop` are zero-based indexes, with `0` being the first\nelement of the list (the head of the list), `1` being the next element and so\non.\n\nThese offsets can also be negative numbers indicating offsets starting at the\nend of the list.\nFor example, `-1` is the last element of the list, `-2` the penultimate, and so\non.\n\n## Consistency with range functions in various programming languages\n\nNote that if you have a list of numbers from 0 to 100, `LRANGE list 0 10` will\nreturn 11 elements, that is, the rightmost item is included.\nThis **may or may not** be consistent with behavior of range-related functions\nin your programming language of choice (think Ruby's `Range.new`, `Array#slice`\nor Python's `range()` function).\n\n## Out-of-range indexes\n\nOut of range indexes will not produce an error.\nIf `start` is larger than the end of the list, an empty list is returned.\nIf `stop` is larger than the actual end of the list, Redis will treat it like\nthe last element of the list.\n\n@examples\n\n```cli\nRPUSH mylist \"one\"\nRPUSH mylist \"two\"\nRPUSH mylist \"three\"\nLRANGE mylist 0 0\nLRANGE mylist -3 2\nLRANGE mylist -100 100\nLRANGE mylist 5 10\n```\n\n",
            "": "",
            "return_types": [
                {
                    "description": "list of elements in the specified range.",
                    "type": "array"
                }
            ],
            "summary": "Get a range of elements from a list",
            "complexity": "O(S+N) where S is the distance of start offset from HEAD for small lists, from nearest end (HEAD or TAIL) for large lists; and N is the number of elements in the specified range.",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "name": "start",
                    "type": "integer",
                    "value": "start"
                },
                {
                    "name": "stop",
                    "type": "integer",
                    "value": "stop"
                }
            ],
            "since": "1.0.0",
            "group": "list",
            "arity": 4,
            "command_flags": [
                "readonly"
            ],
            "acl_categories": [
                "read",
                "list",
                "slow"
            ],
            "key_specs": [
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "lrangeCommand"
        }
    },
    {
        "RESET": {
            "body": "This command performs a full reset of the connection's server-side context, \nmimicking the effect of disconnecting and reconnecting again.\n\nWhen the command is called from a regular client connection, it does the\nfollowing:\n\n* Discards the current [`MULTI`](./multi) transaction block, if one exists.\n* Unwatches all keys [`WATCH`](./watch)ed by the connection.\n* Disables `CLIENT TRACKING`, if in use.\n* Sets the connection to [`READWRITE`](./readwrite) mode.\n* Cancels the connection's [`ASKING`](./asking) mode, if previously set.\n* Sets `CLIENT REPLY` to `ON`.\n* Sets the protocol version to RESP2.\n* [`SELECT`](./select)s database 0.\n* Exits [`MONITOR`](./monitor) mode, when applicable.\n* Aborts Pub/Sub's subscription state ([`SUBSCRIBE`](./subscribe) and [`PSUBSCRIBE`](./psubscribe)), when\n  appropriate.\n* Deauthenticates the connection, requiring a call [`AUTH`](./auth) to reauthenticate when\n  authentication is enabled.\n\n",
            "": "",
            "return_types": [
                {
                    "description": "always 'RESET'.",
                    "type": "simple-string"
                }
            ],
            "summary": "Reset the connection",
            "since": "6.2",
            "group": "connection",
            "arity": 1,
            "command_flags": [
                "noscript",
                "loading",
                "stale",
                "fast"
            ],
            "acl_categories": [
                "fast",
                "connection"
            ],
            "function": "resetCommand"
        }
    },
    {
        "HSCAN": {
            "body": "See [`SCAN`](./scan) for `HSCAN` documentation.\n\n",
            "return_summary": "",
            "summary": "Incrementally iterate hash fields and associated values",
            "complexity": "O(1) for every call. O(N) for a complete iteration, including enough command calls for the cursor to return back to 0. N is the number of elements inside the collection..",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "name": "cursor",
                    "type": "integer",
                    "value": "cursor"
                },
                {
                    "token": "MATCH",
                    "optional": true,
                    "name": "pattern",
                    "type": "pattern",
                    "value": "pattern"
                },
                {
                    "token": "COUNT",
                    "optional": true,
                    "name": "count",
                    "type": "integer",
                    "value": "count"
                }
            ],
            "since": "2.8.0",
            "group": "hash",
            "arity": -3,
            "command_flags": [
                "readonly",
                "random"
            ],
            "acl_categories": [
                "read",
                "hash",
                "slow"
            ],
            "key_specs": [
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "hscanCommand"
        }
    },
    {
        "SUNION": {
            "body": "Returns the members of the set resulting from the union of all the given sets.\n\nFor example:\n\n```\nkey1 = {a,b,c,d}\nkey2 = {c}\nkey3 = {a,c,e}\nSUNION key1 key2 key3 = {a,b,c,d,e}\n```\n\nKeys that do not exist are considered to be empty sets.\n\n@examples\n\n```cli\nSADD key1 \"a\"\nSADD key1 \"b\"\nSADD key1 \"c\"\nSADD key2 \"c\"\nSADD key2 \"d\"\nSADD key2 \"e\"\nSUNION key1 key2\n```\n\n",
            "": "",
            "return_types": [
                {
                    "description": "list with members of the resulting set.",
                    "type": "array"
                }
            ],
            "summary": "Add multiple sets",
            "complexity": "O(N) where N is the total number of elements in all given sets.",
            "arguments": [
                {
                    "multiple": true,
                    "multiple_token": true,
                    "name": "key",
                    "type": "key",
                    "value": "key"
                }
            ],
            "since": "1.0.0",
            "group": "set",
            "arity": -2,
            "command_flags": [
                "readonly",
                "sort_for_script"
            ],
            "acl_categories": [
                "read",
                "set",
                "slow"
            ],
            "key_specs": [
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": -1,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "sunionCommand"
        }
    },
    {
        "GEOSEARCHSTORE": {
            "body": "This command is like [`GEOSEARCH`](./geosearch), but stores the result in destination key.\n\nThis command comes in place of the now deprecated [`GEORADIUS`](./georadius) and [`GEORADIUSBYMEMBER`](./georadiusbymember).\n\nBy default, it stores the results in the `destination` sorted set with their geospatial information.\n\nWhen using the `STOREDIST` option, the command stores the items in a sorted set populated with their distance from the center of the circle or box, as a floating-point number, in the same unit specified for that shape.\n\n@examples\n\n```cli\nGEOADD Sicily 13.361389 38.115556 \"Palermo\" 15.087269 37.502669 \"Catania\"\nGEOADD Sicily 12.758489 38.788135 \"edge1\"   17.241510 38.788135 \"edge2\" \nGEOSEARCHSTORE key1 Sicily FROMLONLAT 15 37 BYBOX 400 400 km ASC COUNT 3\nGEOSEARCH key1 FROMLONLAT 15 37 BYBOX 400 400 km ASC WITHCOORD WITHDIST WITHHASH\nGEOSEARCHSTORE key2 Sicily FROMLONLAT 15 37 BYBOX 400 400 km ASC COUNT 3 STOREDIST\nZRANGE key2 0 -1 WITHSCORES\n```\n",
            "deprecated": true,
            "": "",
            "return_types": [
                {
                    "description": "the number of elements in the resulting set.",
                    "type": "integer"
                }
            ],
            "summary": "Query a sorted set representing a geospatial index to fetch members inside an area of a box or a circle, and store the result in another key.",
            "complexity": "O(N+log(M)) where N is the number of elements in the grid-aligned bounding box area around the shape provided as the filter and M is the number of items inside the shape",
            "arguments": [
                {
                    "name": "destination",
                    "type": "key",
                    "value": "destination"
                },
                {
                    "name": "source",
                    "type": "key",
                    "value": "source"
                },
                {
                    "token": "FROMMEMBER",
                    "optional": true,
                    "name": "member",
                    "type": "string",
                    "value": "member"
                },
                {
                    "token": "FROMLONLAT",
                    "optional": true,
                    "name": "longitude_latitude",
                    "type": "block",
                    "value": [
                        {
                            "name": "longitude",
                            "type": "double",
                            "value": "longitude"
                        },
                        {
                            "name": "latitude",
                            "type": "double",
                            "value": "latitude"
                        }
                    ]
                },
                {
                    "optional": true,
                    "name": "circle",
                    "type": "block",
                    "value": [
                        {
                            "token": "BYRADIUS",
                            "name": "radius",
                            "type": "double",
                            "value": "radius"
                        },
                        {
                            "name": "m_km_ft_mi",
                            "type": "oneof",
                            "value": [
                                {
                                    "name": "__TBD__129__",
                                    "token": "m"
                                },
                                {
                                    "name": "__TBD__130__",
                                    "token": "km"
                                },
                                {
                                    "name": "__TBD__131__",
                                    "token": "ft"
                                },
                                {
                                    "name": "__TBD__132__",
                                    "token": "mi"
                                }
                            ]
                        }
                    ]
                },
                {
                    "optional": true,
                    "name": "box",
                    "type": "block",
                    "value": [
                        {
                            "token": "BYBOX",
                            "name": "width",
                            "type": "double",
                            "value": "width"
                        },
                        {
                            "name": "height",
                            "type": "double",
                            "value": "height"
                        },
                        {
                            "name": "m_km_ft_mi",
                            "type": "oneof",
                            "value": [
                                {
                                    "name": "__TBD__133__",
                                    "token": "m"
                                },
                                {
                                    "name": "__TBD__134__",
                                    "token": "km"
                                },
                                {
                                    "name": "__TBD__135__",
                                    "token": "ft"
                                },
                                {
                                    "name": "__TBD__136__",
                                    "token": "mi"
                                }
                            ]
                        }
                    ]
                },
                {
                    "optional": true,
                    "name": "asc_desc",
                    "type": "oneof",
                    "value": [
                        {
                            "name": "__TBD__137__",
                            "token": "ASC"
                        },
                        {
                            "name": "__TBD__138__",
                            "token": "DESC"
                        }
                    ]
                },
                {
                    "optional": true,
                    "name": "count",
                    "type": "block",
                    "value": [
                        {
                            "token": "COUNT",
                            "name": "count",
                            "type": "integer",
                            "value": "count"
                        },
                        {
                            "optional": true,
                            "name": "any",
                            "token": "ANY"
                        }
                    ]
                },
                {
                    "optional": true,
                    "name": "storedist",
                    "token": "STOREDIST"
                }
            ],
            "since": "6.2",
            "group": "geo",
            "arity": -8,
            "command_flags": [
                "write",
                "denyoom"
            ],
            "acl_categories": [
                "write",
                "geo",
                "slow"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                },
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 2
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "geosearchstoreCommand"
        }
    },
    {
        "HVALS": {
            "body": "Returns all values in the hash stored at `key`.\n\n@examples\n\n```cli\nHSET myhash field1 \"Hello\"\nHSET myhash field2 \"World\"\nHVALS myhash\n```\n\n",
            "": "",
            "return_types": [
                {
                    "description": "list of values in the hash, or an empty list when `key` does",
                    "type": "array"
                }
            ],
            "summary": "Get all the values in a hash",
            "complexity": "O(N) where N is the size of the hash.",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                }
            ],
            "since": "2.0.0",
            "group": "hash",
            "arity": 2,
            "command_flags": [
                "readonly",
                "sort_for_script"
            ],
            "acl_categories": [
                "read",
                "hash",
                "slow"
            ],
            "key_specs": [
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "hvalsCommand"
        }
    },
    {
        "SUBSTR": {
            "arity": 4,
            "command_flags": [
                "readonly"
            ],
            "acl_categories": [
                "read",
                "string",
                "slow"
            ],
            "key_specs": [
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "getrangeCommand",
            "group": "string",
            "internal": true
        }
    },
    {
        "XREVRANGE": {
            "body": "This command is exactly like [`XRANGE`](./xrange), but with the notable difference of\nreturning the entries in reverse order, and also taking the start-end\nrange in reverse order: in `XREVRANGE` you need to state the *end* ID\nand later the *start* ID, and the command will produce all the element\nbetween (or exactly like) the two IDs, starting from the *end* side.\n\nSo for instance, to get all the elements from the higher ID to the lower\nID one could use:\n\n    XREVRANGE somestream + -\n\nSimilarly to get just the last element added into the stream it is\nenough to send:\n\n    XREVRANGE somestream + - COUNT 1\n\n@examples\n\n```cli\nXADD writers * name Virginia surname Woolf\nXADD writers * name Jane surname Austen\nXADD writers * name Toni surname Morrison\nXADD writers * name Agatha surname Christie\nXADD writers * name Ngozi surname Adichie\nXLEN writers\nXREVRANGE writers + - COUNT 1\n```\n\n",
            "return_summary": "@array-reply, specifically:\n\nThe command returns the entries with IDs matching the specified range,\nfrom the higher ID to the lower ID matching.\nThe returned entries are complete, that means that the ID and all the fields\nthey are composed are returned. Moreover the entries are returned with\ntheir fields and values in the exact same order as [`XADD`](./xadd) added them.",
            "": "",
            "summary": "Return a range of elements in a stream, with IDs matching the specified IDs interval, in reverse order (from greater to smaller IDs) compared to XRANGE",
            "complexity": "O(N) with N being the number of elements returned. If N is constant (e.g. always asking for the first 10 elements with COUNT), you can consider it O(1).",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "name": "end",
                    "type": "string",
                    "value": "end"
                },
                {
                    "name": "start",
                    "type": "string",
                    "value": "start"
                },
                {
                    "token": "COUNT",
                    "optional": true,
                    "name": "count",
                    "type": "integer",
                    "value": "count"
                }
            ],
            "since": "5.0.0",
            "group": "stream",
            "arity": -4,
            "command_flags": [
                "readonly"
            ],
            "acl_categories": [
                "read",
                "stream",
                "slow"
            ],
            "key_specs": [
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "xrevrangeCommand"
        }
    },
    {
        "ZINTERCARD": {
            "body": "This command is similar to [`ZINTER`](./zinter), but instead of returning the result set, it returns just the cardinality of the result.\n\nKeys that do not exist are considered to be empty sets.\nWith one of the keys being an empty set, the resulting set is also empty (since set intersection with an empty set always results in an empty set).\n\nBy default, the command calculates the cardinality of the intersection of all given sets.\nWhen provided with the optional `LIMIT` argument (which defaults to 0 and means unlimited), if the intersection cardinality reaches limit partway through the computation, the algorithm will exit and yield limit as the cardinality.\nSuch implementation ensures a significant speedup for queries where the limit is lower than the actual intersection cardinality.\n\n@examples\n\n```cli\nZADD zset1 1 \"one\"\nZADD zset1 2 \"two\"\nZADD zset2 1 \"one\"\nZADD zset2 2 \"two\"\nZADD zset2 3 \"three\"\nZINTER 2 zset1 zset2\nZINTERCARD 2 zset1 zset2\nZINTERCARD 2 zset1 zset2 LIMIT 1\n```\n\n",
            "": "",
            "return_types": [
                {
                    "description": "the number of elements in the resulting intersection.",
                    "type": "integer"
                }
            ],
            "summary": "Intersect multiple sorted sets and return the cardinality of the result",
            "complexity": "O(N*K) worst case with N being the smallest input sorted set, K being the number of input sorted sets.",
            "arguments": [
                {
                    "name": "numkeys",
                    "type": "integer",
                    "value": "numkeys"
                },
                {
                    "multiple": true,
                    "multiple_token": true,
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "token": "LIMIT",
                    "optional": true,
                    "name": "limit",
                    "type": "integer",
                    "value": "limit"
                }
            ],
            "since": "7.0.0",
            "group": "sorted_set",
            "arity": -3,
            "command_flags": [
                "readonly"
            ],
            "acl_categories": [
                "read",
                "sortedset",
                "slow"
            ],
            "key_specs": [
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "keynum": {
                            "keynumidx": 0,
                            "firstkey": 1,
                            "step": 1
                        }
                    }
                }
            ],
            "function": "zinterCardCommand",
            "get_keys_function": "zunionInterDiffGetKeys"
        }
    },
    {
        "ZINTERSTORE": {
            "body": "Computes the intersection of `numkeys` sorted sets given by the specified keys,\nand stores the result in `destination`.\nIt is mandatory to provide the number of input keys (`numkeys`) before passing\nthe input keys and the other (optional) arguments.\n\nBy default, the resulting score of an element is the sum of its scores in the\nsorted sets where it exists.\nBecause intersection requires an element to be a member of every given sorted\nset, this results in the score of every element in the resulting sorted set to\nbe equal to the number of input sorted sets.\n\nFor a description of the `WEIGHTS` and `AGGREGATE` options, see [`ZUNIONSTORE`](./zunionstore).\n\nIf `destination` already exists, it is overwritten.\n\n@examples\n\n```cli\nZADD zset1 1 \"one\"\nZADD zset1 2 \"two\"\nZADD zset2 1 \"one\"\nZADD zset2 2 \"two\"\nZADD zset2 3 \"three\"\nZINTERSTORE out 2 zset1 zset2 WEIGHTS 2 3\nZRANGE out 0 -1 WITHSCORES\n```\n\n",
            "": "",
            "return_types": [
                {
                    "description": "the number of elements in the resulting sorted set at",
                    "type": "integer"
                }
            ],
            "summary": "Intersect multiple sorted sets and store the resulting sorted set in a new key",
            "complexity": "O(N*K)+O(M*log(M)) worst case with N being the smallest input sorted set, K being the number of input sorted sets and M being the number of elements in the resulting sorted set.",
            "arguments": [
                {
                    "name": "destination",
                    "type": "key",
                    "value": "destination"
                },
                {
                    "name": "numkeys",
                    "type": "integer",
                    "value": "numkeys"
                },
                {
                    "multiple": true,
                    "multiple_token": true,
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "token": "WEIGHTS",
                    "optional": true,
                    "multiple": true,
                    "name": "weight",
                    "type": "integer",
                    "value": "weight"
                },
                {
                    "token": "AGGREGATE",
                    "optional": true,
                    "name": "sum_min_max",
                    "type": "oneof",
                    "value": [
                        {
                            "name": "__TBD__139__",
                            "token": "SUM"
                        },
                        {
                            "name": "__TBD__140__",
                            "token": "MIN"
                        },
                        {
                            "name": "__TBD__141__",
                            "token": "MAX"
                        }
                    ]
                }
            ],
            "since": "2.0.0",
            "group": "sorted_set",
            "arity": -4,
            "command_flags": [
                "write",
                "denyoom"
            ],
            "acl_categories": [
                "write",
                "sortedset",
                "slow"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                },
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 2
                        }
                    },
                    "find_keys": {
                        "keynum": {
                            "keynumidx": 0,
                            "firstkey": 1,
                            "step": 1
                        }
                    }
                }
            ],
            "function": "zinterstoreCommand",
            "get_keys_function": "zunionInterDiffStoreGetKeys"
        }
    },
    {
        "COMMAND": {
            "body": "Returns @array-reply of details about all Redis commands.\n\nCluster clients must be aware of key positions in commands so commands can go to matching instances,\nbut Redis commands vary between accepting one key,\nmultiple keys, or even multiple keys separated by other data.\n\nYou can use `COMMAND` to cache a mapping between commands and key positions for\neach command to enable exact routing of commands to cluster instances.\n\n## Nested Result Array\nEach top-level result contains six nested results.  Each nested result is:\n\n  - command name\n  - command arity specification\n  - nested @array-reply of command flags\n  - position of first key in argument list\n  - position of last key in argument list\n  - step count for locating repeating keys\n\n### Command Name\n\nCommand name is the command returned as a lowercase string.\n\n### Command Arity\n\n<table style=\"width:50%\">\n<tr><td>\n<pre>\n<code>1) 1) \"get\"\n   2) (integer) 2\n   3) 1) readonly\n   4) (integer) 1\n   5) (integer) 1\n   6) (integer) 1\n</code>\n</pre>\n</td>\n<td>\n<pre>\n<code>1) 1) \"mget\"\n   2) (integer) -2\n   3) 1) readonly\n   4) (integer) 1\n   5) (integer) -1\n   6) (integer) 1\n</code>\n</pre>\n</td></tr>\n</table>\n\nCommand arity follows a simple pattern:\n\n  - positive if command has fixed number of required arguments.\n  - negative if command has minimum number of required arguments, but may have more.\n\nCommand arity _includes_ counting the command name itself.\n\nExamples:\n\n  - [`GET`](./get) arity is 2 since the command only accepts one\nargument and always has the format `GET _key_`.\n  - [`MGET`](./mget) arity is -2 since the command accepts at a minimum\none argument, but up to an unlimited number: `MGET _key1_ [key2] [key3] ...`.\n\nAlso note with [`MGET`](./mget), the -1 value for \"last key position\" means the list\nof keys may have unlimited length.\n\n### Flags\nCommand flags is @array-reply containing one or more status replies:\n\n  - *write* - command may result in modifications\n  - *readonly* - command will never modify keys\n  - *denyoom* - reject command if currently out of memory\n  - *admin* - server admin command\n  - *pubsub* - pubsub-related command\n  - *noscript* - deny this command from scripts\n  - *random* - command has random results, dangerous for scripts\n  - *sort\\_for\\_script* - if called from script, sort output\n  - *loading* - allow command while database is loading\n  - *stale* - allow command while replica has stale data\n  - *skip_monitor* - do not show this command in MONITOR\n  - *asking* - cluster related - accept even if importing\n  - *fast* - command operates in constant or log(N) time.  Used for latency monitoring.\n  - *movablekeys* - keys have no pre-determined position.  You must discover keys yourself.\n\n\n### Movable Keys\n\n```\n1) 1) \"sort\"\n   2) (integer) -2\n   3) 1) write\n      2) denyoom\n      3) movablekeys\n   4) (integer) 1\n   5) (integer) 1\n   6) (integer) 1\n```\n\nSome Redis commands have no predetermined key locations.  For those commands,\nflag `movablekeys` is added to the command flags @array-reply.  Your Redis\nCluster client needs to parse commands marked `movablekeys` to locate all relevant key positions.\n\nComplete list of commands currently requiring key location parsing:\n\n  - [`SORT`](./sort) - optional `STORE` key, optional `BY` weights, optional [`GET`](./get) keys\n  - [`ZUNION`](./zunion) - keys stop when `WEIGHT` or `AGGREGATE` starts\n  - [`ZUNIONSTORE`](./zunionstore) - keys stop when `WEIGHT` or `AGGREGATE` starts\n  - [`ZINTER`](./zinter) - keys stop when `WEIGHT` or `AGGREGATE` starts\n  - [`ZINTERSTORE`](./zinterstore) - keys stop when `WEIGHT` or `AGGREGATE` starts\n  - [`ZDIFF`](./zdiff) - keys stop after `numkeys` count arguments\n  - [`ZDIFFSTORE`](./zdiffstore) - keys stop after `numkeys` count arguments\n  - [`EVAL`](./eval) - keys stop after `numkeys` count arguments\n  - [`EVALSHA`](./evalsha) - keys stop after `numkeys` count arguments\n\nAlso see `COMMAND GETKEYS` for getting your Redis server tell you where keys\nare in any given command.\n\n### First Key in Argument List\n\nFor most commands the first key is position 1.  Position 0 is\nalways the command name itself.\n\n\n### Last Key in Argument List\n\nRedis commands usually accept one key, two keys, or an unlimited number of keys.\n\nIf a command accepts one key, the first key and last key positions is 1.\n\nIf a command accepts two keys (e.g. [`BRPOPLPUSH`](./brpoplpush), [`SMOVE`](./smove), [`RENAME`](./rename), ...) then the\nlast key position is the location of the last key in the argument list.\n\nIf a command accepts an unlimited number of keys, the last key position is -1.\n\n\n### Step Count\n\n<table style=\"width:50%\">\n<tr><td>\n<pre>\n<code>1) 1) \"mset\"\n   2) (integer) -3\n   3) 1) write\n      2) denyoom\n   4) (integer) 1\n   5) (integer) -1\n   6) (integer) 2\n</code>\n</pre>\n</td>\n<td>\n<pre>\n<code>1) 1) \"mget\"\n   2) (integer) -2\n   3) 1) readonly\n   4) (integer) 1\n   5) (integer) -1\n   6) (integer) 1\n</code>\n</pre>\n</td></tr>\n</table>\n\nKey step count allows us to find key positions in commands\nlike [`MSET`](./mset) where the format is `MSET _key1_ _val1_ [key2] [val2] [key3] [val3]...`.\n\nIn the case of [`MSET`](./mset), keys are every other position so the step value is 2.  Compare\nwith [`MGET`](./mget) above where the step value is just 1.\n\n\n\n@examples\n\n```cli\nCOMMAND\n```\n\n",
            "": "",
            "return_types": [
                {
                    "description": "nested list of command details.  Commands are returned",
                    "type": "array"
                }
            ],
            "summary": "Get array of Redis command details",
            "complexity": "O(N) where N is the total number of Redis commands",
            "since": "2.8.13",
            "group": "server",
            "arity": -1,
            "command_flags": [
                "random",
                "loading",
                "stale"
            ],
            "acl_categories": [
                "slow",
                "connection"
            ],
            "subcommands": [
                {
                    "GETKEYS": {
                        "body": "Returns @array-reply of keys from a full Redis command.\n\n`COMMAND GETKEYS` is a helper command to let you find the keys\nfrom a full Redis command.\n\n[`COMMAND`](./command) shows some commands as having movablekeys meaning\nthe entire command must be parsed to discover storage or retrieval\nkeys.  You can use `COMMAND GETKEYS` to discover key positions\ndirectly from how Redis parses the commands.\n\n\n@examples\n\n```cli\nCOMMAND GETKEYS MSET a b c d e f\nCOMMAND GETKEYS EVAL \"not consulted\" 3 key1 key2 key3 arg1 arg2 arg3 argN\nCOMMAND GETKEYS SORT mylist ALPHA STORE outlist\n```\n\n",
                        "": "",
                        "return_types": [
                            {
                                "description": "list of keys from your command.",
                                "type": "array"
                            }
                        ],
                        "summary": "Extract keys given a full Redis command",
                        "complexity": "O(N) where N is the number of arguments to the command",
                        "since": "2.8.13",
                        "group": "server",
                        "arity": -4,
                        "command_flags": [
                            "loading",
                            "stale"
                        ],
                        "acl_categories": [
                            "slow",
                            "connection"
                        ],
                        "function": "commandGetKeysCommand",
                        "container": "COMMAND"
                    }
                },
                {
                    "COUNT": {
                        "body": "Returns @integer-reply of number of total commands in this Redis server.\n\n@examples\n\n```cli\nCOMMAND COUNT\n```\n\n",
                        "": "",
                        "return_types": [
                            {
                                "description": "number of commands returned by [`COMMAND`](./command)",
                                "type": "integer"
                            }
                        ],
                        "summary": "Get total number of Redis commands",
                        "complexity": "O(1)",
                        "since": "2.8.13",
                        "group": "server",
                        "arity": 2,
                        "command_flags": [
                            "loading",
                            "stale"
                        ],
                        "acl_categories": [
                            "slow",
                            "connection"
                        ],
                        "function": "commandCountCommand",
                        "container": "COMMAND"
                    }
                },
                {
                    "LIST": {
                        "arity": -2,
                        "command_flags": [
                            "loading",
                            "stale"
                        ],
                        "acl_categories": [
                            "slow",
                            "connection"
                        ],
                        "function": "commandListCommand",
                        "container": "COMMAND",
                        "group": "server"
                    }
                },
                {
                    "INFO": {
                        "body": "Returns @array-reply of details about multiple Redis commands.\n\nSame result format as [`COMMAND`](./command) except you can specify which commands\nget returned.\n\nIf you request details about non-existing commands, their return\nposition will be nil.\n\n\n@examples\n\n```cli\nCOMMAND INFO get set eval\nCOMMAND INFO foo evalsha config bar\n```\n\n",
                        "": "",
                        "return_types": [
                            {
                                "description": "nested list of command details.",
                                "type": "array"
                            }
                        ],
                        "summary": "Get array of specific Redis command details",
                        "complexity": "O(N) when N is number of commands to look up",
                        "since": "2.8.13",
                        "arguments": [
                            {
                                "multiple": true,
                                "multiple_token": true,
                                "name": "command-name",
                                "type": "string",
                                "value": "command-name"
                            }
                        ],
                        "group": "server",
                        "arity": -3,
                        "command_flags": [
                            "loading",
                            "stale"
                        ],
                        "acl_categories": [
                            "slow",
                            "connection"
                        ],
                        "function": "commandInfoCommand",
                        "container": "COMMAND"
                    }
                },
                {
                    "HELP": {
                        "arity": 2,
                        "command_flags": [
                            "loading",
                            "stale"
                        ],
                        "acl_categories": [
                            "slow",
                            "connection"
                        ],
                        "function": "commandHelpCommand",
                        "container": "COMMAND",
                        "group": "server"
                    }
                }
            ],
            "function": "commandCommand"
        }
    },
    {
        "READONLY": {
            "body": "Enables read queries for a connection to a Redis Cluster replica node. \n\nNormally replica nodes will redirect clients to the authoritative master for\nthe hash slot involved in a given command, however clients can use replicas\nin order to scale reads using the `READONLY` command.\n\n`READONLY` tells a Redis Cluster replica node that the client is willing to\nread possibly stale data and is not interested in running write queries.\n\nWhen the connection is in readonly mode, the cluster will send a redirection\nto the client only if the operation involves keys not served by the replica's\nmaster node. This may happen because:\n\n1. The client sent a command about hash slots never served by the master of this replica.\n2. The cluster was reconfigured (for example resharded) and the replica is no longer able to serve commands for a given hash slot.\n\n",
            "": "",
            "return_types": [
                {
                    "type": "simple-string"
                }
            ],
            "summary": "Enables read queries for a connection to a cluster replica node",
            "complexity": "O(1)",
            "since": "3.0.0",
            "group": "cluster",
            "arity": 1,
            "command_flags": [
                "fast"
            ],
            "acl_categories": [
                "fast",
                "connection"
            ],
            "function": "readonlyCommand"
        }
    },
    {
        "ZREVRANGE": {
            "body": "Returns the specified range of elements in the sorted set stored at `key`.\nThe elements are considered to be ordered from the highest to the lowest score.\nDescending lexicographical order is used for elements with equal score.\n\nApart from the reversed ordering, `ZREVRANGE` is similar to [`ZRANGE`](./zrange).\n\nAs per Redis 6.2.0, this command is considered deprecated. Please prefer using the [`ZRANGE`](./zrange) command with the `REV` argument in new code.\n\n@examples\n\n```cli\nZADD myzset 1 \"one\"\nZADD myzset 2 \"two\"\nZADD myzset 3 \"three\"\nZREVRANGE myzset 0 -1\nZREVRANGE myzset 2 3\nZREVRANGE myzset -2 -1\n```\n\n",
            "deprecated": true,
            "": "",
            "return_types": [
                {
                    "description": "list of elements in the specified range (optionally with",
                    "type": "array"
                }
            ],
            "summary": "Return a range of members in a sorted set, by index, with scores ordered from high to low",
            "complexity": "O(log(N)+M) with N being the number of elements in the sorted set and M the number of elements returned.",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "name": "start",
                    "type": "integer",
                    "value": "start"
                },
                {
                    "name": "stop",
                    "type": "integer",
                    "value": "stop"
                },
                {
                    "optional": true,
                    "name": "withscores",
                    "token": "WITHSCORES"
                }
            ],
            "since": "1.2.0",
            "group": "sorted_set",
            "arity": -4,
            "command_flags": [
                "readonly"
            ],
            "acl_categories": [
                "read",
                "sortedset",
                "slow"
            ],
            "key_specs": [
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "zrevrangeCommand"
        }
    },
    {
        "STRLEN": {
            "body": "Returns the length of the string value stored at `key`.\nAn error is returned when `key` holds a non-string value.\n\n@examples\n\n```cli\nSET mykey \"Hello world\"\nSTRLEN mykey\nSTRLEN nonexisting\n```\n\n",
            "": "",
            "return_types": [
                {
                    "description": "the length of the string at `key`, or `0` when `key` does not",
                    "type": "integer"
                }
            ],
            "summary": "Get the length of the value stored in a key",
            "complexity": "O(1)",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                }
            ],
            "since": "2.2.0",
            "group": "string",
            "arity": 2,
            "command_flags": [
                "readonly",
                "fast"
            ],
            "acl_categories": [
                "read",
                "string",
                "fast"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "strlenCommand"
        }
    },
    {
        "ZPOPMIN": {
            "body": "Removes and returns up to `count` members with the lowest scores in the sorted\nset stored at `key`.\n\nWhen left unspecified, the default value for `count` is 1. Specifying a `count`\nvalue that is higher than the sorted set's cardinality will not produce an\nerror. When returning multiple elements, the one with the lowest score will\nbe the first, followed by the elements with greater scores.\n\n@examples\n\n```cli\nZADD myzset 1 \"one\"\nZADD myzset 2 \"two\"\nZADD myzset 3 \"three\"\nZPOPMIN myzset\n```\n\n",
            "": "",
            "return_types": [
                {
                    "description": "list of popped elements and scores.",
                    "type": "array"
                }
            ],
            "summary": "Remove and return members with the lowest scores in a sorted set",
            "complexity": "O(log(N)*M) with N being the number of elements in the sorted set, and M being the number of elements popped.",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "optional": true,
                    "name": "count",
                    "type": "integer",
                    "value": "count"
                }
            ],
            "since": "5.0.0",
            "group": "sorted_set",
            "arity": -2,
            "command_flags": [
                "write",
                "fast"
            ],
            "acl_categories": [
                "write",
                "sortedset",
                "fast"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "zpopminCommand"
        }
    },
    {
        "GETEX": {
            "body": "Get the value of `key` and optionally set its expiration.\n`GETEX` is similar to [`GET`](./get), but is a write command with additional options.\n\n## Options\n\nThe `GETEX` command supports a set of options that modify its behavior:\n\n* `EX` *seconds* -- Set the specified expire time, in seconds.\n* `PX` *milliseconds* -- Set the specified expire time, in milliseconds.\n* `EXAT` *timestamp-seconds* -- Set the specified Unix time at which the key will expire, in seconds.\n* `PXAT` *timestamp-milliseconds* -- Set the specified Unix time at which the key will expire, in milliseconds.\n* [`PERSIST`](./persist) -- Remove the time to live associated with the key.\n\n@examples\n\n```cli\nSET mykey \"Hello\"\nGETEX mykey\nTTL mykey\nGETEX mykey EX 60\nTTL mykey\n```\n\n",
            "": "",
            "return_types": [
                {
                    "description": "the value of `key`, or `nil` when `key` does not exist.",
                    "type": "bulk-string"
                }
            ],
            "summary": "Get the value of a key and optionally set its expiration",
            "complexity": "O(1)",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "optional": true,
                    "name": "ex seconds_px milliseconds_exat timestamp_pxat milliseconds-timestamp_persist",
                    "type": "oneof",
                    "value": [
                        {
                            "name": "__TBD__142__",
                            "token": "EX seconds"
                        },
                        {
                            "name": "__TBD__143__",
                            "token": "PX milliseconds"
                        },
                        {
                            "name": "__TBD__144__",
                            "token": "EXAT timestamp"
                        },
                        {
                            "name": "__TBD__145__",
                            "token": "PXAT milliseconds-timestamp"
                        },
                        {
                            "name": "__TBD__146__",
                            "token": "PERSIST"
                        }
                    ]
                }
            ],
            "since": "6.2.0",
            "group": "string",
            "arity": -2,
            "command_flags": [
                "write",
                "fast"
            ],
            "acl_categories": [
                "write",
                "string",
                "fast"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "getexCommand"
        }
    },
    {
        "GEORADIUS": {
            "body": "Return the members of a sorted set populated with geospatial information using [`GEOADD`](./geoadd), which are within the borders of the area specified with the center location and the maximum distance from the center (the radius).\n\nAs per Redis 6.2.0, GEORADIUS command family are considered deprecated. Please prefer [`GEOSEARCH`](./geosearch) and [`GEOSEARCHSTORE`](./geosearchstore) in new code.\n\nThis manual page also covers the [`GEORADIUS_RO`](./georadius_ro) and [`GEORADIUSBYMEMBER_RO`](./georadiusbymember_ro) variants (see the section below for more information).\n\nThe common use case for this command is to retrieve geospatial items near a specified point not farther than a given amount of meters (or other units). This allows, for example, to suggest mobile users of an application nearby places.\n\nThe radius is specified in one of the following units:\n\n* **m** for meters.\n* **km** for kilometers.\n* **mi** for miles.\n* **ft** for feet.\n\nThe command optionally returns additional information using the following options:\n\n* `WITHDIST`: Also return the distance of the returned items from the specified center. The distance is returned in the same unit as the unit specified as the radius argument of the command.\n* `WITHCOORD`: Also return the longitude,latitude coordinates of the matching items.\n* `WITHHASH`: Also return the raw geohash-encoded sorted set score of the item, in the form of a 52 bit unsigned integer. This is only useful for low level hacks or debugging and is otherwise of little interest for the general user.\n\nThe command default is to return unsorted items. Two different sorting methods can be invoked using the following two options:\n\n* `ASC`: Sort returned items from the nearest to the farthest, relative to the center.\n* `DESC`: Sort returned items from the farthest to the nearest, relative to the center.\n\nBy default all the matching items are returned. It is possible to limit the results to the first N matching items by using the **COUNT `<count>`** option.\nWhen `ANY` is provided the command will return as soon as enough matches are found,\nso the results may not be the ones closest to the specified point, but on the other hand, the effort invested by the server is significantly lower.\nWhen `ANY` is not provided, the command will perform an effort that is proportional to the number of items matching the specified area and sort them,\nso to query very large areas with a very small `COUNT` option may be slow even if just a few results are returned.\n\nBy default the command returns the items to the client. It is possible to store the results with one of these options:\n\n* `STORE`: Store the items in a sorted set populated with their geospatial information.\n* `STOREDIST`: Store the items in a sorted set populated with their distance from the center as a floating point number, in the same unit specified in the radius.\n\n## Read-only variants\n\nSince `GEORADIUS` and [`GEORADIUSBYMEMBER`](./georadiusbymember) have a `STORE` and `STOREDIST` option they are technically flagged as writing commands in the Redis command table. For this reason read-only replicas will flag them, and Redis Cluster replicas will redirect them to the master instance even if the connection is in read-only mode (see the [`READONLY`](./readonly) command of Redis Cluster).\n\nBreaking the compatibility with the past was considered but rejected, at least for Redis 4.0, so instead two read-only variants of the commands were added. They are exactly like the original commands but refuse the `STORE` and `STOREDIST` options. The two variants are called [`GEORADIUS_RO`](./georadius_ro) and [`GEORADIUSBYMEMBER_RO`](./georadiusbymember_ro), and can safely be used in replicas.\n\nBoth commands were introduced in Redis 3.2.10 and Redis 4.0.0 respectively.\n\n@examples\n\n```cli\nGEOADD Sicily 13.361389 38.115556 \"Palermo\" 15.087269 37.502669 \"Catania\"\nGEORADIUS Sicily 15 37 200 km WITHDIST\nGEORADIUS Sicily 15 37 200 km WITHCOORD\nGEORADIUS Sicily 15 37 200 km WITHDIST WITHCOORD\n```\n\n",
            "history": [
                [
                    "6.2",
                    "Added the `ANY` option for `COUNT`."
                ]
            ],
            "return_summary": "@array-reply, specifically:\n\n* Without any `WITH` option specified, the command just returns a linear array like [\"New York\",\"Milan\",\"Paris\"].\n* If `WITHCOORD`, `WITHDIST` or `WITHHASH` options are specified, the command returns an array of arrays, where each sub-array represents a single item.\n\nWhen additional information is returned as an array of arrays for each item, the first item in the sub-array is always the name of the returned item. The other information is returned in the following order as successive elements of the sub-array.\n\n1. The distance from the center as a floating point number, in the same unit specified in the radius.\n2. The geohash integer.\n3. The coordinates as a two items x,y array (longitude,latitude).\n\nSo for example the command `GEORADIUS Sicily 15 37 200 km WITHCOORD WITHDIST` will return each item in the following way:\n\n    [\"Palermo\",\"190.4424\",[\"13.361389338970184\",\"38.115556395496299\"]]",
            "deprecated": true,
            "": "",
            "summary": "Query a sorted set representing a geospatial index to fetch members matching a given maximum distance from a point",
            "complexity": "O(N+log(M)) where N is the number of elements inside the bounding box of the circular area delimited by center and radius and M is the number of items inside the index.",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "name": "longitude",
                    "type": "double",
                    "value": "longitude"
                },
                {
                    "name": "latitude",
                    "type": "double",
                    "value": "latitude"
                },
                {
                    "name": "radius",
                    "type": "double",
                    "value": "radius"
                },
                {
                    "name": "m_km_ft_mi",
                    "type": "oneof",
                    "value": [
                        {
                            "name": "__TBD__147__",
                            "token": "m"
                        },
                        {
                            "name": "__TBD__148__",
                            "token": "km"
                        },
                        {
                            "name": "__TBD__149__",
                            "token": "ft"
                        },
                        {
                            "name": "__TBD__150__",
                            "token": "mi"
                        }
                    ]
                },
                {
                    "optional": true,
                    "name": "withcoord",
                    "token": "WITHCOORD"
                },
                {
                    "optional": true,
                    "name": "withdist",
                    "token": "WITHDIST"
                },
                {
                    "optional": true,
                    "name": "withhash",
                    "token": "WITHHASH"
                },
                {
                    "optional": true,
                    "name": "count",
                    "type": "block",
                    "value": [
                        {
                            "token": "COUNT",
                            "name": "count",
                            "type": "integer",
                            "value": "count"
                        },
                        {
                            "optional": true,
                            "name": "any",
                            "token": "ANY"
                        }
                    ]
                },
                {
                    "optional": true,
                    "name": "asc_desc",
                    "type": "oneof",
                    "value": [
                        {
                            "name": "__TBD__151__",
                            "token": "ASC"
                        },
                        {
                            "name": "__TBD__152__",
                            "token": "DESC"
                        }
                    ]
                },
                {
                    "token": "STORE",
                    "optional": true,
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "token": "STOREDIST",
                    "optional": true,
                    "name": "key",
                    "type": "key",
                    "value": "key"
                }
            ],
            "since": "3.2.0",
            "group": "geo",
            "arity": -6,
            "command_flags": [
                "write",
                "denyoom"
            ],
            "acl_categories": [
                "write",
                "geo",
                "slow"
            ],
            "key_specs": [
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                },
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "keyword": {
                            "keyword": "STORE",
                            "startfrom": 6
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                },
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "keyword": {
                            "keyword": "STOREDIST",
                            "startfrom": 6
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "georadiusCommand",
            "get_keys_function": "georadiusGetKeys"
        }
    },
    {
        "ZCOUNT": {
            "body": "Returns the number of elements in the sorted set at `key` with a score between\n`min` and `max`.\n\nThe `min` and `max` arguments have the same semantic as described for\n[`ZRANGEBYSCORE`](./zrangebyscore).\n\nNote: the command has a complexity of just O(log(N)) because it uses elements ranks (see [`ZRANK`](./zrank)) to get an idea of the range. Because of this there is no need to do a work proportional to the size of the range.\n\n@examples\n\n```cli\nZADD myzset 1 \"one\"\nZADD myzset 2 \"two\"\nZADD myzset 3 \"three\"\nZCOUNT myzset -inf +inf\nZCOUNT myzset (1 3\n```\n\n",
            "": "",
            "return_types": [
                {
                    "description": "the number of elements in the specified score range.",
                    "type": "integer"
                }
            ],
            "summary": "Count the members in a sorted set with scores within the given values",
            "complexity": "O(log(N)) with N being the number of elements in the sorted set.",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "name": "min",
                    "type": "double",
                    "value": "min"
                },
                {
                    "name": "max",
                    "type": "double",
                    "value": "max"
                }
            ],
            "since": "2.0.0",
            "group": "sorted_set",
            "arity": 4,
            "command_flags": [
                "readonly",
                "fast"
            ],
            "acl_categories": [
                "read",
                "sortedset",
                "fast"
            ],
            "key_specs": [
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "zcountCommand"
        }
    },
    {
        "SCARD": {
            "body": "Returns the set cardinality (number of elements) of the set stored at `key`.\n\n@examples\n\n```cli\nSADD myset \"Hello\"\nSADD myset \"World\"\nSCARD myset\n```\n\n",
            "": "",
            "return_types": [
                {
                    "description": "the cardinality (number of elements) of the set, or `0` if `key`",
                    "type": "integer"
                }
            ],
            "summary": "Get the number of members in a set",
            "complexity": "O(1)",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                }
            ],
            "since": "1.0.0",
            "group": "set",
            "arity": 2,
            "command_flags": [
                "readonly",
                "fast"
            ],
            "acl_categories": [
                "read",
                "set",
                "fast"
            ],
            "key_specs": [
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "scardCommand"
        }
    },
    {
        "ROLE": {
            "body": "Provide information on the role of a Redis instance in the context of replication, by returning if the instance is currently a `master`, `slave`, or `sentinel`. The command also returns additional information about the state of the replication (if the role is master or slave) or the list of monitored master names (if the role is sentinel).\n\n## Output format\n\nThe command returns an array of elements. The first element is the role of\nthe instance, as one of the following three strings:\n\n* \"master\"\n* \"slave\"\n* \"sentinel\"\n\nThe additional elements of the array depends on the role.\n\n## Master output\n\nAn example of output when `ROLE` is called in a master instance:\n\n```\n1) \"master\"\n2) (integer) 3129659\n3) 1) 1) \"127.0.0.1\"\n      2) \"9001\"\n      3) \"3129242\"\n   2) 1) \"127.0.0.1\"\n      2) \"9002\"\n      3) \"3129543\"\n```\n\nThe master output is composed of the following parts:\n\n1. The string `master`.\n2. The current master replication offset, which is an offset that masters and replicas share to understand, in partial resynchronizations, the part of the replication stream the replicas needs to fetch to continue.\n3. An array composed of three elements array representing the connected replicas. Every sub-array contains the replica IP, port, and the last acknowledged replication offset.\n\n## Output of the command on replicas\n\nAn example of output when `ROLE` is called in a replica instance:\n\n```\n1) \"slave\"\n2) \"127.0.0.1\"\n3) (integer) 9000\n4) \"connected\"\n5) (integer) 3167038\n```\n\nThe replica output is composed of the following parts:\n\n1. The string `slave`, because of backward compatibility (see note at the end of this page).\n2. The IP of the master.\n3. The port number of the master.\n4. The state of the replication from the point of view of the master, that can be `connect` (the instance needs to connect to its master), `connecting` (the master-replica connection is in progress), `sync` (the master and replica are trying to perform the synchronization), `connected` (the replica is online).\n5. The amount of data received from the replica so far in terms of master replication offset.\n\n## Sentinel output\n\nAn example of Sentinel output:\n\n```\n1) \"sentinel\"\n2) 1) \"resque-master\"\n   2) \"html-fragments-master\"\n   3) \"stats-master\"\n   4) \"metadata-master\"\n```\n\nThe sentinel output is composed of the following parts:\n\n1. The string `sentinel`.\n2. An array of master names monitored by this Sentinel instance.\n\n@examples\n\n```cli\nROLE\n```\n\n**A note about the word slave used in this man page**: Starting with Redis 5, if not for backward compatibility, the Redis project no longer uses the word slave. Unfortunately in this command the word slave is part of the protocol, so we'll be able to remove such occurrences only when this API will be naturally deprecated.\n\n",
            "deprecated": true,
            "": "",
            "return_types": [
                {
                    "description": "where the first element is one of `master`, `slave`, `sentinel` and the additional elements are role-specific as illustrated above.",
                    "type": "array"
                }
            ],
            "summary": "Return the role of the instance in the context of replication",
            "since": "2.8.12",
            "group": "server",
            "arity": 1,
            "command_flags": [
                "noscript",
                "loading",
                "stale",
                "fast"
            ],
            "acl_categories": [
                "admin",
                "fast",
                "dangerous"
            ],
            "function": "roleCommand"
        }
    },
    {
        "XCLAIM": {
            "body": "In the context of a stream consumer group, this command changes the ownership\nof a pending message, so that the new owner is the consumer specified as the\ncommand argument. Normally this is what happens:\n\n1. There is a stream with an associated consumer group.\n2. Some consumer A reads a message via [`XREADGROUP`](./xreadgroup) from a stream, in the context of that consumer group.\n3. As a side effect a pending message entry is created in the Pending Entries List (PEL) of the consumer group: it means the message was delivered to a given consumer, but it was not yet acknowledged via [`XACK`](./xack).\n4. Then suddenly that consumer fails forever.\n5. Other consumers may inspect the list of pending messages, that are stale for quite some time, using the [`XPENDING`](./xpending) command. In order to continue processing such messages, they use `XCLAIM` to acquire the ownership of the message and continue. As of Redis 6.2, consumers can use the [`XAUTOCLAIM`](./xautoclaim) command to automatically scan and claim stale pending messages.\n\nThis dynamic is clearly explained in the [Stream intro documentation](/topics/streams-intro).\n\nNote that the message is claimed only if its idle time is greater the minimum idle time we specify when calling `XCLAIM`. Because as a side effect `XCLAIM` will also reset the idle time (since this is a new attempt at processing the message), two consumers trying to claim a message at the same time will never both succeed: only one will successfully claim the message. This avoids that we process a given message multiple times in a trivial way (yet multiple processing is possible and unavoidable in the general case).\n\nMoreover, as a side effect, `XCLAIM` will increment the count of attempted deliveries of the message unless the `JUSTID` option has been specified (which only delivers the message ID, not the message itself). In this way messages that cannot be processed for some reason, for instance because the consumers crash attempting to process them, will start to have a larger counter and can be detected inside the system.\n\n## Command options\n\nThe command has multiple options, however most are mainly for internal use in\norder to transfer the effects of `XCLAIM` or other commands to the AOF file\nand to propagate the same effects to the replicas, and are unlikely to be\nuseful to normal users:\n\n1. `IDLE <ms>`: Set the idle time (last time it was delivered) of the message. If IDLE is not specified, an IDLE of 0 is assumed, that is, the time count is reset because the message has now a new owner trying to process it.\n2. `TIME <ms-unix-time>`: This is the same as IDLE but instead of a relative amount of milliseconds, it sets the idle time to a specific Unix time (in milliseconds). This is useful in order to rewrite the AOF file generating `XCLAIM` commands.\n3. `RETRYCOUNT <count>`: Set the retry counter to the specified value. This counter is incremented every time a message is delivered again. Normally `XCLAIM` does not alter this counter, which is just served to clients when the XPENDING command is called: this way clients can detect anomalies, like messages that are never processed for some reason after a big number of delivery attempts.\n4. `FORCE`: Creates the pending message entry in the PEL even if certain specified IDs are not already in the PEL assigned to a different client. However the message must be exist in the stream, otherwise the IDs of non existing messages are ignored.\n5. `JUSTID`: Return just an array of IDs of messages successfully claimed, without returning the actual message. Using this option means the retry counter is not incremented.\n\n@examples\n\n```\n> XCLAIM mystream mygroup Alice 3600000 1526569498055-0\n1) 1) 1526569498055-0\n   2) 1) \"message\"\n      2) \"orange\"\n```\n\nIn the above example we claim the message with ID `1526569498055-0`, only if the message is idle for at least one hour without the original consumer or some other consumer making progresses (acknowledging or claiming it), and assigns the ownership to the consumer `Alice`.\n\n",
            "return_summary": "@array-reply, specifically:\n\nThe command returns all the messages successfully claimed, in the same format\nas [`XRANGE`](./xrange). However if the `JUSTID` option was specified, only the message\nIDs are reported, without including the actual message.",
            "": "",
            "summary": "Changes (or acquires) ownership of a message in a consumer group, as if the message was delivered to the specified consumer.",
            "complexity": "O(log N) with N being the number of messages in the PEL of the consumer group.",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "name": "group",
                    "type": "string",
                    "value": "group"
                },
                {
                    "name": "consumer",
                    "type": "string",
                    "value": "consumer"
                },
                {
                    "name": "min-idle-time",
                    "type": "string",
                    "value": "min-idle-time"
                },
                {
                    "multiple": true,
                    "multiple_token": true,
                    "name": "ID",
                    "type": "string",
                    "value": "ID"
                },
                {
                    "token": "IDLE",
                    "optional": true,
                    "name": "ms",
                    "type": "integer",
                    "value": "ms"
                },
                {
                    "token": "TIME",
                    "optional": true,
                    "name": "ms-unix-time",
                    "type": "integer",
                    "value": "ms-unix-time"
                },
                {
                    "token": "RETRYCOUNT",
                    "optional": true,
                    "name": "count",
                    "type": "integer",
                    "value": "count"
                },
                {
                    "optional": true,
                    "name": "force",
                    "token": "FORCE"
                },
                {
                    "optional": true,
                    "name": "justid",
                    "token": "JUSTID"
                }
            ],
            "since": "5.0.0",
            "group": "stream",
            "arity": -6,
            "command_flags": [
                "write",
                "random",
                "fast"
            ],
            "acl_categories": [
                "write",
                "stream",
                "fast"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "xclaimCommand"
        }
    },
    {
        "SDIFF": {
            "body": "Returns the members of the set resulting from the difference between the first\nset and all the successive sets.\n\nFor example:\n\n```\nkey1 = {a,b,c,d}\nkey2 = {c}\nkey3 = {a,c,e}\nSDIFF key1 key2 key3 = {b,d}\n```\n\nKeys that do not exist are considered to be empty sets.\n\n@examples\n\n```cli\nSADD key1 \"a\"\nSADD key1 \"b\"\nSADD key1 \"c\"\nSADD key2 \"c\"\nSADD key2 \"d\"\nSADD key2 \"e\"\nSDIFF key1 key2\n```\n\n",
            "": "",
            "return_types": [
                {
                    "description": "list with members of the resulting set.",
                    "type": "array"
                }
            ],
            "summary": "Subtract multiple sets",
            "complexity": "O(N) where N is the total number of elements in all given sets.",
            "arguments": [
                {
                    "multiple": true,
                    "multiple_token": true,
                    "name": "key",
                    "type": "key",
                    "value": "key"
                }
            ],
            "since": "1.0.0",
            "group": "set",
            "arity": -2,
            "command_flags": [
                "readonly",
                "sort_for_script"
            ],
            "acl_categories": [
                "read",
                "set",
                "slow"
            ],
            "key_specs": [
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": -1,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "sdiffCommand"
        }
    },
    {
        "LREM": {
            "body": "Removes the first `count` occurrences of elements equal to `element` from the list\nstored at `key`.\nThe `count` argument influences the operation in the following ways:\n\n* `count > 0`: Remove elements equal to `element` moving from head to tail.\n* `count < 0`: Remove elements equal to `element` moving from tail to head.\n* `count = 0`: Remove all elements equal to `element`.\n\nFor example, `LREM list -2 \"hello\"` will remove the last two occurrences of\n`\"hello\"` in the list stored at `list`.\n\nNote that non-existing keys are treated like empty lists, so when `key` does not\nexist, the command will always return `0`.\n\n@examples\n\n```cli\nRPUSH mylist \"hello\"\nRPUSH mylist \"hello\"\nRPUSH mylist \"foo\"\nRPUSH mylist \"hello\"\nLREM mylist -2 \"hello\"\nLRANGE mylist 0 -1\n```\n\n",
            "": "",
            "return_types": [
                {
                    "description": "the number of removed elements.",
                    "type": "integer"
                }
            ],
            "summary": "Remove elements from a list",
            "complexity": "O(N+M) where N is the length of the list and M is the number of elements removed.",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "name": "count",
                    "type": "integer",
                    "value": "count"
                },
                {
                    "name": "element",
                    "type": "string",
                    "value": "element"
                }
            ],
            "since": "1.0.0",
            "group": "list",
            "arity": 4,
            "command_flags": [
                "write"
            ],
            "acl_categories": [
                "write",
                "list",
                "slow"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "lremCommand"
        }
    },
    {
        "TIME": {
            "body": "The `TIME` command returns the current server time as a two items lists: a Unix\ntimestamp and the amount of microseconds already elapsed in the current second.\nBasically the interface is very similar to the one of the `gettimeofday` system\ncall.\n\n@examples\n\n```cli\nTIME\nTIME\n```\n\n",
            "return_summary": "@array-reply, specifically:\n\nA multi bulk reply containing two elements:\n\n* unix time in seconds.\n* microseconds.",
            "": "",
            "summary": "Return the current server time",
            "complexity": "O(1)",
            "since": "2.6.0",
            "group": "server",
            "arity": 1,
            "command_flags": [
                "random",
                "loading",
                "stale",
                "fast"
            ],
            "acl_categories": [
                "fast"
            ],
            "function": "timeCommand"
        }
    },
    {
        "APPEND": {
            "body": "If `key` already exists and is a string, this command appends the `value` at the\nend of the string.\nIf `key` does not exist it is created and set as an empty string, so `APPEND`\nwill be similar to [`SET`](./set) in this special case.\n\n@examples\n\n```cli\nEXISTS mykey\nAPPEND mykey \"Hello\"\nAPPEND mykey \" World\"\nGET mykey\n```\n\n## Pattern: Time series\n\nThe `APPEND` command can be used to create a very compact representation of a\nlist of fixed-size samples, usually referred as _time series_.\nEvery time a new sample arrives we can store it using the command\n\n```\nAPPEND timeseries \"fixed-size sample\"\n```\n\nAccessing individual elements in the time series is not hard:\n\n* [`STRLEN`](./strlen) can be used in order to obtain the number of samples.\n* [`GETRANGE`](./getrange) allows for random access of elements.\n  If our time series have associated time information we can easily implement\n  a binary search to get range combining [`GETRANGE`](./getrange) with the Lua scripting\n  engine available in Redis 2.6.\n* [`SETRANGE`](./setrange) can be used to overwrite an existing time series.\n\nThe limitation of this pattern is that we are forced into an append-only mode\nof operation, there is no way to cut the time series to a given size easily\nbecause Redis currently lacks a command able to trim string objects.\nHowever the space efficiency of time series stored in this way is remarkable.\n\nHint: it is possible to switch to a different key based on the current Unix\ntime, in this way it is possible to have just a relatively small amount of\nsamples per key, to avoid dealing with very big keys, and to make this pattern\nmore friendly to be distributed across many Redis instances.\n\nAn example sampling the temperature of a sensor using fixed-size strings (using\na binary format is better in real implementations).\n\n```cli\nAPPEND ts \"0043\"\nAPPEND ts \"0035\"\nGETRANGE ts 0 3\nGETRANGE ts 4 7\n```\n\n",
            "": "",
            "return_types": [
                {
                    "description": "the length of the string after the append operation.",
                    "type": "integer"
                }
            ],
            "summary": "Append a value to a key",
            "complexity": "O(1). The amortized time complexity is O(1) assuming the appended value is small and the already present value is of any size, since the dynamic string library used by Redis will double the free space available on every reallocation.",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "name": "value",
                    "type": "string",
                    "value": "value"
                }
            ],
            "since": "2.0.0",
            "group": "string",
            "arity": 3,
            "command_flags": [
                "write",
                "denyoom",
                "fast"
            ],
            "acl_categories": [
                "write",
                "string",
                "fast"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "appendCommand"
        }
    },
    {
        "EXPIRE": {
            "body": "Set a timeout on `key`.\nAfter the timeout has expired, the key will automatically be deleted.\nA key with an associated timeout is often said to be _volatile_ in Redis\nterminology.\n\nThe timeout will only be cleared by commands that delete or overwrite the\ncontents of the key, including [`DEL`](./del), [`SET`](./set), [`GETSET`](./getset) and all the `*STORE`\ncommands.\nThis means that all the operations that conceptually _alter_ the value stored at\nthe key without replacing it with a new one will leave the timeout untouched.\nFor instance, incrementing the value of a key with [`INCR`](./incr), pushing a new value\ninto a list with [`LPUSH`](./lpush), or altering the field value of a hash with [`HSET`](./hset) are\nall operations that will leave the timeout untouched.\n\nThe timeout can also be cleared, turning the key back into a persistent key,\nusing the [`PERSIST`](./persist) command.\n\nIf a key is renamed with [`RENAME`](./rename), the associated time to live is transferred to\nthe new key name.\n\nIf a key is overwritten by [`RENAME`](./rename), like in the case of an existing key `Key_A`\nthat is overwritten by a call like `RENAME Key_B Key_A`, it does not matter if\nthe original `Key_A` had a timeout associated or not, the new key `Key_A` will\ninherit all the characteristics of `Key_B`.\n\nNote that calling `EXPIRE`/[`PEXPIRE`](./pexpire) with a non-positive timeout or\n[`EXPIREAT`](./expireat)/[`PEXPIREAT`](./pexpireat) with a time in the past will result in the key being\n[deleted][del] rather than expired (accordingly, the emitted [key event][ntf]\nwill be `del`, not `expired`).\n\n[del]: /commands/del\n[ntf]: /topics/notifications\n\n## Options\n\nThe `EXPIRE` command supports a set of options since Redis 7.0:\n\n* `NX` -- Set expiry only when the key has no expiry\n* `XX` -- Set expiry only when the key has an existing expiry\n* `GT` -- Set expiry only when the new expiry is greater than current one\n* `LT` -- Set expiry only when the new expiry is less than current one\n\nA non-volatile key is treated as an infinite TTL for the purpose of `GT` and `LT`.\nThe `GT`, `LT` and `NX` options are mutually exclusive.\n\n## Refreshing expires\n\nIt is possible to call `EXPIRE` using as argument a key that already has an\nexisting expire set.\nIn this case the time to live of a key is _updated_ to the new value.\nThere are many useful applications for this, an example is documented in the\n_Navigation session_ pattern section below.\n\n## Differences in Redis prior 2.1.3\n\nIn Redis versions prior **2.1.3** altering a key with an expire set using a\ncommand altering its value had the effect of removing the key entirely.\nThis semantics was needed because of limitations in the replication layer that\nare now fixed.\n\n`EXPIRE` would return 0 and not alter the timeout for a key with a timeout set.\n\n@examples\n\n```cli\nSET mykey \"Hello\"\nEXPIRE mykey 10\nTTL mykey\nSET mykey \"Hello World\"\nTTL mykey\nEXPIRE mykey 10 XX\nTTL mykey\nEXPIRE mykey 10 NX\nTTL mykey\n```\n\n## Pattern: Navigation session\n\nImagine you have a web service and you are interested in the latest N pages\n_recently_ visited by your users, such that each adjacent page view was not\nperformed more than 60 seconds after the previous.\nConceptually you may consider this set of page views as a _Navigation session_\nof your user, that may contain interesting information about what kind of\nproducts he or she is looking for currently, so that you can recommend related\nproducts.\n\nYou can easily model this pattern in Redis using the following strategy: every\ntime the user does a page view you call the following commands:\n\n```\nMULTI\nRPUSH pagewviews.user:<userid> http://.....\nEXPIRE pagewviews.user:<userid> 60\nEXEC\n```\n\nIf the user will be idle more than 60 seconds, the key will be deleted and only\nsubsequent page views that have less than 60 seconds of difference will be\nrecorded.\n\nThis pattern is easily modified to use counters using [`INCR`](./incr) instead of lists\nusing [`RPUSH`](./rpush).\n\n# Appendix: Redis expires\n\n## Keys with an expire\n\nNormally Redis keys are created without an associated time to live.\nThe key will simply live forever, unless it is removed by the user in an\nexplicit way, for instance using the [`DEL`](./del) command.\n\nThe `EXPIRE` family of commands is able to associate an expire to a given key,\nat the cost of some additional memory used by the key.\nWhen a key has an expire set, Redis will make sure to remove the key when the\nspecified amount of time elapsed.\n\nThe key time to live can be updated or entirely removed using the `EXPIRE` and\n[`PERSIST`](./persist) command (or other strictly related commands).\n\n## Expire accuracy\n\nIn Redis 2.4 the expire might not be pin-point accurate, and it could be between\nzero to one seconds out.\n\nSince Redis 2.6 the expire error is from 0 to 1 milliseconds.\n\n## Expires and persistence\n\nKeys expiring information is stored as absolute Unix timestamps (in milliseconds\nin case of Redis version 2.6 or greater).\nThis means that the time is flowing even when the Redis instance is not active.\n\nFor expires to work well, the computer time must be taken stable.\nIf you move an RDB file from two computers with a big desync in their clocks,\nfunny things may happen (like all the keys loaded to be expired at loading\ntime).\n\nEven running instances will always check the computer clock, so for instance if\nyou set a key with a time to live of 1000 seconds, and then set your computer\ntime 2000 seconds in the future, the key will be expired immediately, instead of\nlasting for 1000 seconds.\n\n## How Redis expires keys\n\nRedis keys are expired in two ways: a passive way, and an active way.\n\nA key is passively expired simply when some client tries to access it, and the\nkey is found to be timed out.\n\nOf course this is not enough as there are expired keys that will never be\naccessed again.\nThese keys should be expired anyway, so periodically Redis tests a few keys at\nrandom among keys with an expire set.\nAll the keys that are already expired are deleted from the keyspace.\n\nSpecifically this is what Redis does 10 times per second:\n\n1. Test 20 random keys from the set of keys with an associated expire.\n2. Delete all the keys found expired.\n3. If more than 25% of keys were expired, start again from step 1.\n\nThis is a trivial probabilistic algorithm, basically the assumption is that our\nsample is representative of the whole key space, and we continue to expire until\nthe percentage of keys that are likely to be expired is under 25%\n\nThis means that at any given moment the maximum amount of keys already expired\nthat are using memory is at max equal to max amount of write operations per\nsecond divided by 4.\n\n## How expires are handled in the replication link and AOF file\n\nIn order to obtain a correct behavior without sacrificing consistency, when a\nkey expires, a [`DEL`](./del) operation is synthesized in both the AOF file and gains all\nthe attached replicas nodes.\nThis way the expiration process is centralized in the master instance, and there\nis no chance of consistency errors.\n\nHowever while the replicas connected to a master will not expire keys\nindependently (but will wait for the [`DEL`](./del) coming from the master), they'll\nstill take the full state of the expires existing in the dataset, so when a\nreplica is elected to master it will be able to expire the keys independently,\nfully acting as a master.\n\n",
            "history": [
                [
                    "7.0",
                    "Added options: `NX`, `XX`, `GT` and `LT`."
                ]
            ],
            "return_summary": "@integer-reply, specifically:\n\n* `1` if the timeout was set.\n* `0` if the timeout was not set. e.g. key doesn't exist, or operation skipped due to the provided arguments.",
            "": "",
            "summary": "Set a key's time to live in seconds",
            "complexity": "O(1)",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "name": "seconds",
                    "type": "integer",
                    "value": "seconds"
                },
                {
                    "optional": true,
                    "name": "nx_xx_gt_lt",
                    "type": "oneof",
                    "value": [
                        {
                            "name": "__TBD__153__",
                            "token": "NX"
                        },
                        {
                            "name": "__TBD__154__",
                            "token": "XX"
                        },
                        {
                            "name": "__TBD__155__",
                            "token": "GT"
                        },
                        {
                            "name": "__TBD__156__",
                            "token": "LT"
                        }
                    ]
                }
            ],
            "since": "1.0.0",
            "group": "generic",
            "arity": -3,
            "command_flags": [
                "write",
                "fast"
            ],
            "acl_categories": [
                "keyspace",
                "write",
                "fast"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "expireCommand"
        }
    },
    {
        "ZPOPMAX": {
            "body": "Removes and returns up to `count` members with the highest scores in the sorted\nset stored at `key`.\n\nWhen left unspecified, the default value for `count` is 1. Specifying a `count`\nvalue that is higher than the sorted set's cardinality will not produce an\nerror. When returning multiple elements, the one with the highest score will\nbe the first, followed by the elements with lower scores.\n\n@examples\n\n```cli\nZADD myzset 1 \"one\"\nZADD myzset 2 \"two\"\nZADD myzset 3 \"three\"\nZPOPMAX myzset\n```\n\n",
            "": "",
            "return_types": [
                {
                    "description": "list of popped elements and scores.",
                    "type": "array"
                }
            ],
            "summary": "Remove and return members with the highest scores in a sorted set",
            "complexity": "O(log(N)*M) with N being the number of elements in the sorted set, and M being the number of elements popped.",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "optional": true,
                    "name": "count",
                    "type": "integer",
                    "value": "count"
                }
            ],
            "since": "5.0.0",
            "group": "sorted_set",
            "arity": -2,
            "command_flags": [
                "write",
                "fast"
            ],
            "acl_categories": [
                "write",
                "sortedset",
                "fast"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "zpopmaxCommand"
        }
    },
    {
        "ZADD": {
            "body": "Adds all the specified members with the specified scores to the sorted set\nstored at `key`.\nIt is possible to specify multiple score / member pairs.\nIf a specified member is already a member of the sorted set, the score is\nupdated and the element reinserted at the right position to ensure the correct\nordering.\n\nIf `key` does not exist, a new sorted set with the specified members as sole\nmembers is created, like if the sorted set was empty. If the key exists but does not hold a sorted set, an error is returned.\n\nThe score values should be the string representation of a double precision floating point number. `+inf` and `-inf` values are valid values as well.\n\nZADD options\n---\n\nZADD supports a list of options, specified after the name of the key and before\nthe first score argument. Options are:\n\n* **XX**: Only update elements that already exist. Don't add new elements.\n* **NX**: Only add new elements. Don't update already existing elements.\n* **LT**: Only update existing elements if the new score is **less than** the current score. This flag doesn't prevent adding new elements.\n* **GT**: Only update existing elements if the new score is **greater than** the current score. This flag doesn't prevent adding new elements.\n* **CH**: Modify the return value from the number of new elements added, to the total number of elements changed (CH is an abbreviation of *changed*). Changed elements are **new elements added** and elements already existing for which **the score was updated**. So elements specified in the command line having the same score as they had in the past are not counted. Note: normally the return value of `ZADD` only counts the number of new elements added.\n* **INCR**: When this option is specified `ZADD` acts like [`ZINCRBY`](./zincrby). Only one score-element pair can be specified in this mode.\n\nNote: The **GT**, **LT** and **NX** options are mutually exclusive.\n\nRange of integer scores that can be expressed precisely\n---\n\nRedis sorted sets use a *double 64-bit floating point number* to represent the score. In all the architectures we support, this is represented as an **IEEE 754 floating point number**, that is able to represent precisely integer numbers between `-(2^53)` and `+(2^53)` included. In more practical terms, all the integers between -9007199254740992 and 9007199254740992 are perfectly representable. Larger integers, or fractions, are internally represented in exponential form, so it is possible that you get only an approximation of the decimal number, or of the very big integer, that you set as score.\n\nSorted sets 101\n---\n\nSorted sets are sorted by their score in an ascending way.\nThe same element only exists a single time, no repeated elements are\npermitted. The score can be modified both by `ZADD` that will update the\nelement score, and as a side effect, its position on the sorted set, and\nby [`ZINCRBY`](./zincrby) that can be used in order to update the score relatively to its\nprevious value.\n\nThe current score of an element can be retrieved using the [`ZSCORE`](./zscore) command,\nthat can also be used to verify if an element already exists or not.\n\nFor an introduction to sorted sets, see the data types page on [sorted\nsets][tdtss].\n\n[tdtss]: /topics/data-types#sorted-sets\n\nElements with the same score\n---\n\nWhile the same element can't be repeated in a sorted set since every element\nis unique, it is possible to add multiple different elements *having the same score*. When multiple elements have the same score, they are *ordered lexicographically* (they are still ordered by score as a first key, however, locally, all the elements with the same score are relatively ordered lexicographically).\n\nThe lexicographic ordering used is binary, it compares strings as array of bytes.\n\nIf the user inserts all the elements in a sorted set with the same score (for example 0), all the elements of the sorted set are sorted lexicographically, and range queries on elements are possible using the command [`ZRANGEBYLEX`](./zrangebylex) (Note: it is also possible to query sorted sets by range of scores using [`ZRANGEBYSCORE`](./zrangebyscore)).\n\n@examples\n\n```cli\nZADD myzset 1 \"one\"\nZADD myzset 1 \"uno\"\nZADD myzset 2 \"two\" 3 \"three\"\nZRANGE myzset 0 -1 WITHSCORES\n```\n\n",
            "history": [
                [
                    "2.4",
                    "Accepts multiple elements."
                ],
                [
                    "3.0.2",
                    "Added the `XX`, `NX`, `CH` and [`INCR`](./incr) options."
                ],
                [
                    "6.2",
                    "Added the `GT` and `LT` options."
                ]
            ],
            "return_summary": "@integer-reply, specifically:\n\n* When used without optional arguments, the number of elements added to the sorted set (excluding score updates).\n* If the `CH` option is specified, the number of elements that were changed (added or updated).\n\nIf the [`INCR`](./incr) option is specified, the return value will be @bulk-string-reply:\n\n* The new score of `member` (a double precision floating point number) represented as string, or `nil` if the operation was aborted (when called with either the `XX` or the `NX` option).",
            "": "",
            "summary": "Add one or more members to a sorted set, or update its score if it already exists",
            "complexity": "O(log(N)) for each item added, where N is the number of elements in the sorted set.",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "optional": true,
                    "name": "nx_xx",
                    "type": "oneof",
                    "value": [
                        {
                            "name": "__TBD__157__",
                            "token": "NX"
                        },
                        {
                            "name": "__TBD__158__",
                            "token": "XX"
                        }
                    ]
                },
                {
                    "optional": true,
                    "name": "gt_lt",
                    "type": "oneof",
                    "value": [
                        {
                            "name": "__TBD__159__",
                            "token": "GT"
                        },
                        {
                            "name": "__TBD__160__",
                            "token": "LT"
                        }
                    ]
                },
                {
                    "optional": true,
                    "name": "change",
                    "token": "CH"
                },
                {
                    "optional": true,
                    "name": "increment",
                    "token": "INCR"
                },
                {
                    "multiple": true,
                    "multiple_token": true,
                    "name": "score_member",
                    "type": "block",
                    "value": [
                        {
                            "name": "score",
                            "type": "double",
                            "value": "score"
                        },
                        {
                            "name": "member",
                            "type": "string",
                            "value": "member"
                        }
                    ]
                }
            ],
            "since": "1.2.0",
            "group": "sorted_set",
            "arity": -4,
            "command_flags": [
                "write",
                "denyoom",
                "fast"
            ],
            "acl_categories": [
                "write",
                "sortedset",
                "fast"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "zaddCommand"
        }
    },
    {
        "SETEX": {
            "body": "Set `key` to hold the string `value` and set `key` to timeout after a given\nnumber of seconds.\nThis command is equivalent to executing the following commands:\n\n```\nSET mykey value\nEXPIRE mykey seconds\n```\n\n`SETEX` is atomic, and can be reproduced by using the previous two commands\ninside an [`MULTI`](./multi) / [`EXEC`](./exec) block.\nIt is provided as a faster alternative to the given sequence of operations,\nbecause this operation is very common when Redis is used as a cache.\n\nAn error is returned when `seconds` is invalid.\n\n@examples\n\n```cli\nSETEX mykey 10 \"Hello\"\nTTL mykey\nGET mykey\n```\n\n",
            "": "",
            "return_types": [
                {
                    "type": "simple-string"
                }
            ],
            "summary": "Set the value and expiration of a key",
            "complexity": "O(1)",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "name": "seconds",
                    "type": "integer",
                    "value": "seconds"
                },
                {
                    "name": "value",
                    "type": "string",
                    "value": "value"
                }
            ],
            "since": "2.0.0",
            "group": "string",
            "arity": 4,
            "command_flags": [
                "write",
                "denyoom"
            ],
            "acl_categories": [
                "write",
                "string",
                "slow"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "setexCommand"
        }
    },
    {
        "GEORADIUSBYMEMBER": {
            "body": "This command is exactly like [`GEORADIUS`](./georadius) with the sole difference that instead\nof taking, as the center of the area to query, a longitude and latitude value, it takes the name of a member already existing inside the geospatial index represented by the sorted set.\n\nAs per Redis 6.2.0, GEORADIUS command family are considered deprecated. Please prefer [`GEOSEARCH`](./geosearch) and [`GEOSEARCHSTORE`](./geosearchstore) in new code.\n\nThe position of the specified member is used as the center of the query.\n\nPlease check the example below and the [`GEORADIUS`](./georadius) documentation for more information about the command and its options.\n\nNote that [`GEORADIUSBYMEMBER_RO`](./georadiusbymember_ro) is also available since Redis 3.2.10 and Redis 4.0.0 in order to provide a read-only command that can be used in replicas. See the [`GEORADIUS`](./georadius) page for more information.\n\n@examples\n\n```cli\nGEOADD Sicily 13.583333 37.316667 \"Agrigento\"\nGEOADD Sicily 13.361389 38.115556 \"Palermo\" 15.087269 37.502669 \"Catania\"\nGEORADIUSBYMEMBER Sicily Agrigento 100 km\n```\n\n",
            "return_summary": "",
            "deprecated": true,
            "summary": "Query a sorted set representing a geospatial index to fetch members matching a given maximum distance from a member",
            "complexity": "O(N+log(M)) where N is the number of elements inside the bounding box of the circular area delimited by center and radius and M is the number of items inside the index.",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "name": "member",
                    "type": "string",
                    "value": "member"
                },
                {
                    "name": "radius",
                    "type": "double",
                    "value": "radius"
                },
                {
                    "name": "m_km_ft_mi",
                    "type": "oneof",
                    "value": [
                        {
                            "name": "__TBD__161__",
                            "token": "m"
                        },
                        {
                            "name": "__TBD__162__",
                            "token": "km"
                        },
                        {
                            "name": "__TBD__163__",
                            "token": "ft"
                        },
                        {
                            "name": "__TBD__164__",
                            "token": "mi"
                        }
                    ]
                },
                {
                    "optional": true,
                    "name": "withcoord",
                    "token": "WITHCOORD"
                },
                {
                    "optional": true,
                    "name": "withdist",
                    "token": "WITHDIST"
                },
                {
                    "optional": true,
                    "name": "withhash",
                    "token": "WITHHASH"
                },
                {
                    "optional": true,
                    "name": "count",
                    "type": "block",
                    "value": [
                        {
                            "token": "COUNT",
                            "name": "count",
                            "type": "integer",
                            "value": "count"
                        },
                        {
                            "optional": true,
                            "name": "any",
                            "token": "ANY"
                        }
                    ]
                },
                {
                    "optional": true,
                    "name": "asc_desc",
                    "type": "oneof",
                    "value": [
                        {
                            "name": "__TBD__165__",
                            "token": "ASC"
                        },
                        {
                            "name": "__TBD__166__",
                            "token": "DESC"
                        }
                    ]
                },
                {
                    "token": "STORE",
                    "optional": true,
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "token": "STOREDIST",
                    "optional": true,
                    "name": "key",
                    "type": "key",
                    "value": "key"
                }
            ],
            "since": "3.2.0",
            "group": "geo",
            "arity": -5,
            "command_flags": [
                "write",
                "denyoom"
            ],
            "acl_categories": [
                "write",
                "geo",
                "slow"
            ],
            "key_specs": [
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                },
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "keyword": {
                            "keyword": "STORE",
                            "startfrom": 5
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                },
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "keyword": {
                            "keyword": "STOREDIST",
                            "startfrom": 5
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "georadiusbymemberCommand",
            "get_keys_function": "georadiusGetKeys"
        }
    },
    {
        "DECRBY": {
            "body": "Decrements the number stored at `key` by `decrement`.\nIf the key does not exist, it is set to `0` before performing the operation.\nAn error is returned if the key contains a value of the wrong type or contains a\nstring that can not be represented as integer.\nThis operation is limited to 64 bit signed integers.\n\nSee [`INCR`](./incr) for extra information on increment/decrement operations.\n\n@examples\n\n```cli\nSET mykey \"10\"\nDECRBY mykey 3\n```\n\n",
            "": "",
            "return_types": [
                {
                    "description": "the value of `key` after the decrement",
                    "type": "integer"
                }
            ],
            "summary": "Decrement the integer value of a key by the given number",
            "complexity": "O(1)",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "name": "decrement",
                    "type": "integer",
                    "value": "decrement"
                }
            ],
            "since": "1.0.0",
            "group": "string",
            "arity": 3,
            "command_flags": [
                "write",
                "denyoom",
                "fast"
            ],
            "acl_categories": [
                "write",
                "string",
                "fast"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "decrbyCommand"
        }
    },
    {
        "ZUNION": {
            "body": "This command is similar to [`ZUNIONSTORE`](./zunionstore), but instead of storing the resulting\nsorted set, it is returned to the client.\n\nFor a description of the `WEIGHTS` and `AGGREGATE` options, see [`ZUNIONSTORE`](./zunionstore).\n\n@examples\n\n```cli\nZADD zset1 1 \"one\"\nZADD zset1 2 \"two\"\nZADD zset2 1 \"one\"\nZADD zset2 2 \"two\"\nZADD zset2 3 \"three\"\nZUNION 2 zset1 zset2\nZUNION 2 zset1 zset2 WITHSCORES\n```\n\n",
            "": "",
            "return_types": [
                {
                    "description": "the result of union (optionally with their scores, in case ",
                    "type": "array"
                }
            ],
            "summary": "Add multiple sorted sets",
            "complexity": "O(N)+O(M*log(M)) with N being the sum of the sizes of the input sorted sets, and M being the number of elements in the resulting sorted set.",
            "arguments": [
                {
                    "name": "numkeys",
                    "type": "integer",
                    "value": "numkeys"
                },
                {
                    "multiple": true,
                    "multiple_token": true,
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "token": "WEIGHTS",
                    "optional": true,
                    "multiple": true,
                    "name": "weight",
                    "type": "integer",
                    "value": "weight"
                },
                {
                    "token": "AGGREGATE",
                    "optional": true,
                    "name": "sum_min_max",
                    "type": "oneof",
                    "value": [
                        {
                            "name": "__TBD__167__",
                            "token": "SUM"
                        },
                        {
                            "name": "__TBD__168__",
                            "token": "MIN"
                        },
                        {
                            "name": "__TBD__169__",
                            "token": "MAX"
                        }
                    ]
                },
                {
                    "optional": true,
                    "name": "withscores",
                    "token": "WITHSCORES"
                }
            ],
            "since": "6.2.0",
            "group": "sorted_set",
            "arity": -3,
            "command_flags": [
                "readonly"
            ],
            "acl_categories": [
                "read",
                "sortedset",
                "slow"
            ],
            "key_specs": [
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "keynum": {
                            "keynumidx": 0,
                            "firstkey": 1,
                            "step": 1
                        }
                    }
                }
            ],
            "function": "zunionCommand",
            "get_keys_function": "zunionInterDiffGetKeys"
        }
    },
    {
        "SINTERCARD": {
            "body": "This command is similar to [`SINTER`](./sinter), but instead of returning the result set, it returns just the cardinality of the result.\nReturns the cardinality of the set which would result from the intersection of all the given sets.\n\nKeys that do not exist are considered to be empty sets.\nWith one of the keys being an empty set, the resulting set is also empty (since set intersection with an empty set always results in an empty set).\n\nBy default, the command calculates the cardinality of the intersection of all given sets.\nWhen provided with the optional `LIMIT` argument (which defaults to 0 and means unlimited), if the intersection cardinality reaches limit partway through the computation, the algorithm will exit and yield limit as the cardinality.\nSuch implementation ensures a significant speedup for queries where the limit is lower than the actual intersection cardinality.\n\n@examples\n\n```cli\nSADD key1 \"a\"\nSADD key1 \"b\"\nSADD key1 \"c\"\nSADD key1 \"d\"\nSADD key2 \"c\"\nSADD key2 \"d\"\nSADD key2 \"e\"\nSINTER key1 key2\nSINTERCARD 2 key1 key2\nSINTERCARD 2 key1 key2 LIMIT 1\n```\n\n",
            "": "",
            "return_types": [
                {
                    "description": "the number of elements in the resulting intersection.",
                    "type": "integer"
                }
            ],
            "summary": "Intersect multiple sets and return the cardinality of the result",
            "complexity": "O(N*M) worst case where N is the cardinality of the smallest set and M is the number of sets.",
            "arguments": [
                {
                    "name": "numkeys",
                    "type": "integer",
                    "value": "numkeys"
                },
                {
                    "multiple": true,
                    "multiple_token": true,
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "token": "LIMIT",
                    "optional": true,
                    "name": "limit",
                    "type": "integer",
                    "value": "limit"
                }
            ],
            "since": "7.0.0",
            "group": "set",
            "arity": -3,
            "command_flags": [
                "readonly"
            ],
            "acl_categories": [
                "read",
                "set",
                "slow"
            ],
            "key_specs": [
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "keynum": {
                            "keynumidx": 0,
                            "firstkey": 1,
                            "step": 1
                        }
                    }
                }
            ],
            "function": "sinterCardCommand",
            "get_keys_function": "sintercardGetKeys"
        }
    },
    {
        "GETDEL": {
            "body": "Get the value of `key` and delete the key.\nThis command is similar to [`GET`](./get), except for the fact that it also deletes the key on success (if and only if the key's value type is a string).\n\n@examples\n\n```cli\nSET mykey \"Hello\"\nGETDEL mykey\nGET mykey\n```\n\n",
            "": "",
            "return_types": [
                {
                    "description": "the value of `key`, `nil` when `key` does not exist, or an error if the key's value type isn't a string.",
                    "type": "bulk-string"
                }
            ],
            "summary": "Get the value of a key and delete the key",
            "complexity": "O(1)",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                }
            ],
            "since": "6.2.0",
            "group": "string",
            "arity": 2,
            "command_flags": [
                "write",
                "fast"
            ],
            "acl_categories": [
                "write",
                "string",
                "fast"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "getdelCommand"
        }
    },
    {
        "HEXISTS": {
            "body": "Returns if `field` is an existing field in the hash stored at `key`.\n\n@examples\n\n```cli\nHSET myhash field1 \"foo\"\nHEXISTS myhash field1\nHEXISTS myhash field2\n```\n\n",
            "return_summary": "@integer-reply, specifically:\n\n* `1` if the hash contains `field`.\n* `0` if the hash does not contain `field`, or `key` does not exist.",
            "": "",
            "summary": "Determine if a hash field exists",
            "complexity": "O(1)",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "name": "field",
                    "type": "string",
                    "value": "field"
                }
            ],
            "since": "2.0.0",
            "group": "hash",
            "arity": 3,
            "command_flags": [
                "readonly",
                "fast"
            ],
            "acl_categories": [
                "read",
                "hash",
                "fast"
            ],
            "key_specs": [
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "hexistsCommand"
        }
    },
    {
        "OBJECT": {
            "arity": -2,
            "command_flags": [],
            "acl_categories": [
                "slow"
            ],
            "subcommands": [
                {
                    "REFCOUNT": {
                        "body": "This command returns the reference count of the stored at `<key>`.\n\n",
                        "": "",
                        "return_types": [
                            {
                                "type": "integer"
                            }
                        ],
                        "summary": "Get the number of references to the value of the key",
                        "complexity": "O(1)",
                        "since": "2.2.3",
                        "group": "generic",
                        "arguments": [
                            {
                                "name": "key",
                                "type": "key",
                                "value": "key"
                            }
                        ],
                        "arity": 3,
                        "command_flags": [
                            "readonly"
                        ],
                        "acl_categories": [
                            "keyspace",
                            "read",
                            "slow"
                        ],
                        "key_specs": [
                            {
                                "flags": [
                                    "read"
                                ],
                                "begin_search": {
                                    "index": {
                                        "pos": 2
                                    }
                                },
                                "find_keys": {
                                    "range": {
                                        "lastkey": 0,
                                        "step": 1,
                                        "limit": 0
                                    }
                                }
                            }
                        ],
                        "function": "objectCommand",
                        "container": "OBJECT"
                    }
                },
                {
                    "IDLETIME": {
                        "body": "This command returns the time in milliseconds since the last access to the value stored at `<key>`.\n\nThe command is only available when the `maxmemory-policy` configuration directive is set to one of the LRU policies.\n\n",
                        "": "",
                        "return_types": [
                            {
                                "type": "integer"
                            }
                        ],
                        "summary": "Get the time since a Redis object was last accessed",
                        "complexity": "O(1)",
                        "since": "2.2.3",
                        "group": "generic",
                        "arguments": [
                            {
                                "name": "key",
                                "type": "key",
                                "value": "key"
                            }
                        ],
                        "arity": 3,
                        "command_flags": [
                            "readonly",
                            "random"
                        ],
                        "acl_categories": [
                            "keyspace",
                            "read",
                            "slow"
                        ],
                        "key_specs": [
                            {
                                "flags": [
                                    "read"
                                ],
                                "begin_search": {
                                    "index": {
                                        "pos": 2
                                    }
                                },
                                "find_keys": {
                                    "range": {
                                        "lastkey": 0,
                                        "step": 1,
                                        "limit": 0
                                    }
                                }
                            }
                        ],
                        "function": "objectCommand",
                        "container": "OBJECT"
                    }
                },
                {
                    "FREQ": {
                        "body": "This command returns the logarithmic access frequency counter of a Redis object stored at `<key>`.\n\nThe command is only available when the `maxmemory-policy` configuration directive is set to one of the LFU policies.\n\n",
                        "": "",
                        "return_types": [
                            {
                                "type": "integer"
                            }
                        ],
                        "summary": "Get the logarithmic access frequency counter of a Redis object",
                        "complexity": "O(1)",
                        "since": "4.0.0",
                        "group": "generic",
                        "arguments": [
                            {
                                "name": "key",
                                "type": "key",
                                "value": "key"
                            }
                        ],
                        "arity": 3,
                        "command_flags": [
                            "readonly",
                            "random"
                        ],
                        "acl_categories": [
                            "keyspace",
                            "read",
                            "slow"
                        ],
                        "key_specs": [
                            {
                                "flags": [
                                    "read"
                                ],
                                "begin_search": {
                                    "index": {
                                        "pos": 2
                                    }
                                },
                                "find_keys": {
                                    "range": {
                                        "lastkey": 0,
                                        "step": 1,
                                        "limit": 0
                                    }
                                }
                            }
                        ],
                        "function": "objectCommand",
                        "container": "OBJECT"
                    }
                },
                {
                    "ENCODING": {
                        "body": "Returns the internal encoding for the Redis object stored at `<key>`\n\nRedis objects can be encoded in different ways:\n\n* Strings can be encoded as `raw` (normal string encoding) or `int` (strings representing integers in a 64 bit signed interval are encoded in this way in order to save space).\n* Lists can be encoded as `ziplist` or `linkedlist`. The `ziplist` is the special representation that is used to save space for small lists.\n* Sets can be encoded as `intset` or `hashtable`. The `intset` is a special encoding used for small sets composed solely of integers.\n* Hashes can be encoded as `ziplist` or `hashtable`. The `ziplist` is a special encoding used for small hashes.\n* Sorted Sets can be encoded as `ziplist` or `skiplist` format. As for the List type small sorted sets can be specially encoded using `ziplist`, while the `skiplist` encoding is the one that works with sorted sets of any size.\n\nAll the specially encoded types are automatically converted to the general type once you perform an operation that makes it impossible for Redis to retain the space saving encoding.\n\n",
                        "": "",
                        "return_types": [
                            {
                                "description": "the encoding of the object, or `nil` if the key doesn't exist",
                                "type": "bulk-string"
                            }
                        ],
                        "summary": "Inspect the internal encoding of a Redis object",
                        "complexity": "O(1)",
                        "since": "2.2.3",
                        "group": "generic",
                        "arguments": [
                            {
                                "name": "key",
                                "type": "key",
                                "value": "key"
                            }
                        ],
                        "arity": 3,
                        "command_flags": [
                            "readonly"
                        ],
                        "acl_categories": [
                            "keyspace",
                            "read",
                            "slow"
                        ],
                        "key_specs": [
                            {
                                "flags": [
                                    "read"
                                ],
                                "begin_search": {
                                    "index": {
                                        "pos": 2
                                    }
                                },
                                "find_keys": {
                                    "range": {
                                        "lastkey": 0,
                                        "step": 1,
                                        "limit": 0
                                    }
                                }
                            }
                        ],
                        "function": "objectCommand",
                        "container": "OBJECT"
                    }
                },
                {
                    "HELP": {
                        "body": "The `OBJECT HELP` command returns a helpful text describing the different subcommands.\n\n",
                        "": "",
                        "return_types": [
                            {
                                "description": "a list of subcommands and their descriptions",
                                "type": "array"
                            }
                        ],
                        "summary": "Show helpful text about the different subcommands",
                        "complexity": "O(1)",
                        "since": "6.2.0",
                        "group": "generic",
                        "arity": 2,
                        "command_flags": [
                            "loading",
                            "stale"
                        ],
                        "acl_categories": [
                            "keyspace",
                            "slow"
                        ],
                        "function": "objectCommand",
                        "container": "OBJECT"
                    }
                }
            ],
            "group": "generic",
            "since": "2.2.3"
        }
    },
    {
        "SETRANGE": {
            "body": "Overwrites part of the string stored at _key_, starting at the specified offset,\nfor the entire length of _value_.\nIf the offset is larger than the current length of the string at _key_, the\nstring is padded with zero-bytes to make _offset_ fit.\nNon-existing keys are considered as empty strings, so this command will make\nsure it holds a string large enough to be able to set _value_ at _offset_.\n\nNote that the maximum offset that you can set is 2^29 -1 (536870911), as Redis\nStrings are limited to 512 megabytes.\nIf you need to grow beyond this size, you can use multiple keys.\n\n**Warning**: When setting the last possible byte and the string value stored at\n_key_ does not yet hold a string value, or holds a small string value, Redis\nneeds to allocate all intermediate memory which can block the server for some\ntime.\nOn a 2010 MacBook Pro, setting byte number 536870911 (512MB allocation) takes\n~300ms, setting byte number 134217728 (128MB allocation) takes ~80ms, setting\nbit number 33554432 (32MB allocation) takes ~30ms and setting bit number 8388608\n(8MB allocation) takes ~8ms.\nNote that once this first allocation is done, subsequent calls to `SETRANGE` for\nthe same _key_ will not have the allocation overhead.\n\n## Patterns\n\nThanks to `SETRANGE` and the analogous [`GETRANGE`](./getrange) commands, you can use Redis\nstrings as a linear array with O(1) random access.\nThis is a very fast and efficient storage in many real world use cases.\n\n@examples\n\nBasic usage:\n\n```cli\nSET key1 \"Hello World\"\nSETRANGE key1 6 \"Redis\"\nGET key1\n```\n\nExample of zero padding:\n\n```cli\nSETRANGE key2 6 \"Redis\"\nGET key2\n```\n\n",
            "": "",
            "return_types": [
                {
                    "description": "the length of the string after it was modified by the command.",
                    "type": "integer"
                }
            ],
            "summary": "Overwrite part of a string at key starting at the specified offset",
            "complexity": "O(1), not counting the time taken to copy the new string in place. Usually, this string is very small so the amortized complexity is O(1). Otherwise, complexity is O(M) with M being the length of the value argument.",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "name": "offset",
                    "type": "integer",
                    "value": "offset"
                },
                {
                    "name": "value",
                    "type": "string",
                    "value": "value"
                }
            ],
            "since": "2.2.0",
            "group": "string",
            "arity": 4,
            "command_flags": [
                "write",
                "denyoom"
            ],
            "acl_categories": [
                "write",
                "string",
                "slow"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "setrangeCommand"
        }
    },
    {
        "LTRIM": {
            "body": "Trim an existing list so that it will contain only the specified range of\nelements specified.\nBoth `start` and `stop` are zero-based indexes, where `0` is the first element\nof the list (the head), `1` the next element and so on.\n\nFor example: `LTRIM foobar 0 2` will modify the list stored at `foobar` so that\nonly the first three elements of the list will remain.\n\n`start` and `end` can also be negative numbers indicating offsets from the end\nof the list, where `-1` is the last element of the list, `-2` the penultimate\nelement and so on.\n\nOut of range indexes will not produce an error: if `start` is larger than the\nend of the list, or `start > end`, the result will be an empty list (which\ncauses `key` to be removed).\nIf `end` is larger than the end of the list, Redis will treat it like the last\nelement of the list.\n\nA common use of `LTRIM` is together with [`LPUSH`](./lpush) / [`RPUSH`](./rpush).\nFor example:\n\n```\nLPUSH mylist someelement\nLTRIM mylist 0 99\n```\n\nThis pair of commands will push a new element on the list, while making sure\nthat the list will not grow larger than 100 elements.\nThis is very useful when using Redis to store logs for example.\nIt is important to note that when used in this way `LTRIM` is an O(1) operation\nbecause in the average case just one element is removed from the tail of the\nlist.\n\n@examples\n\n```cli\nRPUSH mylist \"one\"\nRPUSH mylist \"two\"\nRPUSH mylist \"three\"\nLTRIM mylist 1 -1\nLRANGE mylist 0 -1\n```\n\n",
            "": "",
            "return_types": [
                {
                    "type": "simple-string"
                }
            ],
            "summary": "Trim a list to the specified range",
            "complexity": "O(N) where N is the number of elements to be removed by the operation.",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "name": "start",
                    "type": "integer",
                    "value": "start"
                },
                {
                    "name": "stop",
                    "type": "integer",
                    "value": "stop"
                }
            ],
            "since": "1.0.0",
            "group": "list",
            "arity": 4,
            "command_flags": [
                "write"
            ],
            "acl_categories": [
                "write",
                "list",
                "slow"
            ],
            "key_specs": [
                {
                    "flags": [
                        "write"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "ltrimCommand"
        }
    },
    {
        "ZRANGEBYLEX": {
            "body": "When all the elements in a sorted set are inserted with the same score, in order to force lexicographical ordering, this command returns all the elements in the sorted set at `key` with a value between `min` and `max`.\n\nIf the elements in the sorted set have different scores, the returned elements are unspecified.\n\nThe elements are considered to be ordered from lower to higher strings as compared byte-by-byte using the `memcmp()` C function. Longer strings are considered greater than shorter strings if the common part is identical.\n\nAs per Redis 6.2.0, this command is considered deprecated. Please prefer using the [`ZRANGE`](./zrange) command with the `BYLEX` argument in new code.\n\nThe optional `LIMIT` argument can be used to only get a range of the matching\nelements (similar to _SELECT LIMIT offset, count_ in SQL). A negative `count`\nreturns all elements from the `offset`.\nKeep in mind that if `offset` is large, the sorted set needs to be traversed for\n`offset` elements before getting to the elements to return, which can add up to\nO(N) time complexity.\n\n## How to specify intervals\n\nValid *start* and *stop* must start with `(` or `[`, in order to specify\nif the range item is respectively exclusive or inclusive.\nThe special values of `+` or `-` for *start* and *stop* have the special\nmeaning or positively infinite and negatively infinite strings, so for\ninstance the command **ZRANGEBYLEX myzset - +** is guaranteed to return\nall the elements in the sorted set, if all the elements have the same\nscore.\n\n## Details on strings comparison\n\nStrings are compared as binary array of bytes. Because of how the ASCII character\nset is specified, this means that usually this also have the effect of comparing\nnormal ASCII characters in an obvious dictionary way. However this is not true\nif non plain ASCII strings are used (for example utf8 strings).\n\nHowever the user can apply a transformation to the encoded string so that\nthe first part of the element inserted in the sorted set will compare as the\nuser requires for the specific application. For example if I want to\nadd strings that will be compared in a case-insensitive way, but I still\nwant to retrieve the real case when querying, I can add strings in the\nfollowing way:\n\n    ZADD autocomplete 0 foo:Foo 0 bar:BAR 0 zap:zap\n\nBecause of the first *normalized* part in every element (before the colon character), we are forcing a given comparison, however after the range is queries using `ZRANGEBYLEX` the application can display to the user the second part of the string, after the colon.\n\nThe binary nature of the comparison allows to use sorted sets as a general\npurpose index, for example the first part of the element can be a 64 bit\nbig endian number: since big endian numbers have the most significant bytes\nin the initial positions, the binary comparison will match the numerical\ncomparison of the numbers. This can be used in order to implement range\nqueries on 64 bit values. As in the example below, after the first 8 bytes\nwe can store the value of the element we are actually indexing.\n\n@examples\n\n```cli\nZADD myzset 0 a 0 b 0 c 0 d 0 e 0 f 0 g\nZRANGEBYLEX myzset - [c\nZRANGEBYLEX myzset - (c\nZRANGEBYLEX myzset [aaa (g\n```\n\n",
            "deprecated": true,
            "": "",
            "return_types": [
                {
                    "description": "list of elements in the specified score range.",
                    "type": "array"
                }
            ],
            "summary": "Return a range of members in a sorted set, by lexicographical range",
            "complexity": "O(log(N)+M) with N being the number of elements in the sorted set and M the number of elements being returned. If M is constant (e.g. always asking for the first 10 elements with LIMIT), you can consider it O(log(N)).",
            "arguments": [
                {
                    "name": "key",
                    "type": "key",
                    "value": "key"
                },
                {
                    "name": "min",
                    "type": "string",
                    "value": "min"
                },
                {
                    "name": "max",
                    "type": "string",
                    "value": "max"
                },
                {
                    "token": "LIMIT",
                    "optional": true,
                    "name": "offset_count",
                    "type": "block",
                    "value": [
                        {
                            "name": "offset",
                            "type": "integer",
                            "value": "offset"
                        },
                        {
                            "name": "count",
                            "type": "integer",
                            "value": "count"
                        }
                    ]
                }
            ],
            "since": "2.8.9",
            "group": "sorted_set",
            "arity": -4,
            "command_flags": [
                "readonly"
            ],
            "acl_categories": [
                "read",
                "sortedset",
                "slow"
            ],
            "key_specs": [
                {
                    "flags": [
                        "read"
                    ],
                    "begin_search": {
                        "index": {
                            "pos": 1
                        }
                    },
                    "find_keys": {
                        "range": {
                            "lastkey": 0,
                            "step": 1,
                            "limit": 0
                        }
                    }
                }
            ],
            "function": "zrangebylexCommand"
        }
    },
    {
        "PING": {
            "body": "Returns `PONG` if no argument is provided, otherwise return a copy of the\nargument as a bulk.\nThis command is often used to test if a connection is still alive, or to measure\nlatency.\n\nIf the client is subscribed to a channel or a pattern, it will instead return a\nmulti-bulk with a \"pong\" in the first position and an empty bulk in the second\nposition, unless an argument is provided in which case it returns a copy\nof the argument.\n\n@examples\n\n```cli\nPING\n\nPING \"hello world\"\n```\n\n",
            "": "",
            "return_types": [
                {
                    "type": "simple-string"
                }
            ],
            "summary": "Ping the server",
            "arguments": [
                {
                    "optional": true,
                    "name": "message",
                    "type": "string",
                    "value": "message"
                }
            ],
            "since": "1.0.0",
            "group": "connection",
            "arity": -1,
            "command_flags": [
                "stale",
                "fast"
            ],
            "acl_categories": [
                "fast",
                "connection"
            ],
            "function": "pingCommand"
        }
    }
]